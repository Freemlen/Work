{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97c82d55",
   "metadata": {},
   "source": [
    "# Вводные"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69bf992f",
   "metadata": {},
   "source": [
    "## Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "7dfb0da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import math\n",
    "from statsmodels.stats.power import NormalIndPower, TTestIndPower \n",
    "from collections import namedtuple\n",
    "import scipy.stats as sps\n",
    "\n",
    "ExperimentComparisonResults = namedtuple('ExperimentComparisonResults', \n",
    "                                        ['pvalue', 'effect', 'ci_length', 'left_bound', 'right_bound'])\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "import pyodbc\n",
    "import psycopg2\n",
    "import psycopg2.extras\n",
    "import os\n",
    "import gc\n",
    "import io\n",
    "import time\n",
    "import sys\n",
    "from tqdm.notebook import tqdm as tqdm_notebook\n",
    "import re\n",
    "\n",
    "# Для выгрузки отчёта\n",
    "import xlwings as xw\n",
    "import shutil\n",
    "import win32com.client as win32\n",
    "import datetime as dt\n",
    "\n",
    "# Графические настройки \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import logging\n",
    "from sqlalchemy.exc import OperationalError, ProgrammingError\n",
    "import functools\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da23fc6",
   "metadata": {},
   "source": [
    "## Подключение и параметры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "5f778edd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-15 14:55:26,383 - INFO - Успешно подключились к GreenPlum.\n",
      "2025-09-15 14:55:26,384 - INFO - Подключение к GreenPlum установлено.\n"
     ]
    }
   ],
   "source": [
    "# Consts\n",
    "os.chdir(r\"e:\\users\\meshchaninov_av\\Documents\\Расчёты эффектов_готовые\\Выгрузки Июнь 2025\")\n",
    "\n",
    "from Connector_package import GreenPlumConnector, teradata as teradata_query\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "\n",
    "with open(r'e:\\users\\meshchaninov_av\\Documents\\Python!подключение_к_greenplum.txt', 'r', encoding='utf-8') as f:\n",
    "    psw = f.read().strip()\n",
    "\n",
    "GP_PARAMS = {\n",
    "    \"dbname\": \"dwh\",\n",
    "    \"user\": \"meshchaninov_av\",\n",
    "    \"password\": psw,\n",
    "    \"host\": \"10.239.6.220\",\n",
    "    \"port\": \"5432\"\n",
    "}\n",
    "\n",
    "accaunt = GP_PARAMS[\"user\"]\n",
    "engine = create_engine(f'postgresql://{accaunt}:{psw}@10.239.6.220:5432/dwh')\n",
    "\n",
    "gp_connector = GreenPlumConnector(GP_PARAMS, engine=engine)\n",
    "logging.info(\"Подключение к GreenPlum установлено.\")\n",
    "\n",
    "odbc_td = 'DSN=teradata'\n",
    "odbc_gp = 'DSN=GreenPlum'\n",
    "\n",
    "# teradata connector\n",
    "connect_td = pyodbc.connect(odbc_td)\n",
    "connect_td.autocommit = True\n",
    "cursor_td = connect_td.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "badc85a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Декоратор для логирования\n",
    "def log_function_call(func):\n",
    "    \"\"\"\n",
    "    Декоратор для автоматического логирования вызова и завершения функций.\n",
    "    \"\"\"\n",
    "    @functools.wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        func.name = func.__name__\n",
    "        logging.info(f\"Начало выполнения функции {func.__name__} с args={args}, kwargs={kwargs}\")\n",
    "        try:\n",
    "            result = func(*args, **kwargs)\n",
    "            logging.info(f\"Функция {func.__name__} завершена успешно.\")\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Ошибка в функции {func.__name__}: {e}\", exc_info=True)\n",
    "            raise e\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6bd698",
   "metadata": {},
   "source": [
    "# Функции"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1817a3ab",
   "metadata": {},
   "source": [
    "## whs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "d716dea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@log_function_call\n",
    "def create_whs(gp_connector, mask):\n",
    "    gp_connector.execute_query(f\"\"\"drop table if exists ba.vt_{mask}_whs;\"\"\")\n",
    "    gp_connector.execute_query(f\"\"\" --sql\n",
    "    Create Table ba.vt_{mask}_whs (\n",
    "    orgunit_id INTEGER\n",
    "    )\n",
    "    ;\"\"\")\n",
    "\n",
    "    gp_connector.execute_query(f\"\"\"\n",
    "    INSERT INTO ba.vt_{mask}_whs\n",
    "    SELECT distinct orgunit_id\n",
    "    FROM dm.whs\n",
    "    WHERE working = '1'\n",
    "    ;\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112b1a95",
   "metadata": {},
   "source": [
    "## cus_ruls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "9d4dfd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@log_function_call\n",
    "def create_cus_ruls(gp_connector, mask, art_grp_lvl_2_name, type_art_group_level, promo_start_date_act, promo_end_date_act, actn_name, type, version, code_act, code_prev, promo_start_date_prev, promo_end_date_prev):\n",
    "    _ALLOWED = {'art_grp_lvl_1_name','art_grp_lvl_2_name','art_grp_lvl_3_name'}\n",
    "    _SYNONYM = {'lvl1':'art_grp_lvl_1_name','lvl2':'art_grp_lvl_2_name','lvl3':'art_grp_lvl_3_name'}\n",
    "\n",
    "    def resolve_group_column(type_art_group_level: str) -> str:\n",
    "        \"\"\"Из helper → одна из 3 колонок; неизвестное → lvl2 по умолчанию.\"\"\"\n",
    "        raw = (type_art_group_level or '').strip()\n",
    "        col = _SYNONYM.get(raw.lower(), raw)  # разрешаем lvl1/lvl2/lvl3 и прямые имена\n",
    "        if col not in _ALLOWED:\n",
    "            logging.warning(f\"[group-level] Unknown '{type_art_group_level}', fallback to art_grp_lvl_2_name\")\n",
    "            return 'art_grp_lvl_2_name'\n",
    "        return col\n",
    "\n",
    "    def values_to_in_clause(values) -> str:\n",
    "        \"\"\"'Пиво; Твердые сыры' → 'Пиво','Твердые сыры' (экранирует кавычки).\"\"\"\n",
    "        if isinstance(values, (list, tuple, set)):\n",
    "            parts = [str(x) for x in values]\n",
    "        else:\n",
    "            cleaned = str(values).strip().strip('\"').strip(\"'\")\n",
    "            parts = re.split(r'[;,]', cleaned)\n",
    "        parts = [p.strip() for p in parts if p]\n",
    "        return ','.join(\"'\" + p.replace(\"'\", \"''\") + \"'\" for p in parts)\n",
    "\n",
    "    # 1) ОБЩАЯ ЧАСТЬ (для всех версий): выбираем колонку и значения, строим список статей\n",
    "    col     = resolve_group_column(type_art_group_level)\n",
    "    vals_in = values_to_in_clause(art_grp_lvl_2_name)\n",
    "\n",
    "    gp_connector.execute_query(f\"DROP TABLE IF EXISTS ba.tmp_{mask}_{type}_articles;\")\n",
    "    gp_connector.execute_query(f\"\"\"\n",
    "        CREATE TABLE ba.tmp_{mask}_{type}_articles AS\n",
    "        SELECT DISTINCT article_id\n",
    "        FROM dm.art_ext\n",
    "        WHERE {col} IN ({vals_in});\n",
    "    \"\"\")\n",
    "\n",
    "    cnt = gp_connector.gp(f\"SELECT COUNT(*) FROM ba.tmp_{mask}_{type}_articles;\").iloc[0,0]\n",
    "    if cnt == 0 and col != 'art_grp_lvl_2_name':\n",
    "        logging.warning(f\"[group-level] 0 articles by '{col}'. Fallback to art_grp_lvl_2_name.\")\n",
    "        gp_connector.execute_query(f\"TRUNCATE TABLE ba.tmp_{mask}_{type}_articles;\")\n",
    "        gp_connector.execute_query(f\"\"\"\n",
    "            INSERT INTO ba.tmp_{mask}_{type}_articles\n",
    "            SELECT DISTINCT article_id\n",
    "            FROM dm.art_ext\n",
    "            WHERE art_grp_lvl_2_name IN ({vals_in});\n",
    "        \"\"\")\n",
    "\n",
    "    if version == 1:\n",
    "        # ──────────────────────────────────────────────────────────\n",
    "        # Покупатели товаров в promo_start_date_act\n",
    "        # ──────────────────────────────────────────────────────────\n",
    "        gp_connector.execute_query(f\"DROP TABLE IF EXISTS ba.tmp_{mask}_{type}_buyers_act;\")\n",
    "        gp_connector.execute_query(f\"\"\"\n",
    "        CREATE TABLE ba.tmp_{mask}_{type}_buyers_act AS\n",
    "        SELECT DISTINCT ch.contact_id\n",
    "        FROM   dm.cheque_item  ci\n",
    "        JOIN   ba.tmp_{mask}_{type}_articles a ON a.article_id = ci.article_id\n",
    "        JOIN   dm.cheque ch ON ch.cheque_pk = ci.cheque_pk\n",
    "        WHERE  ch.datetime BETWEEN '{promo_start_date_act}'::timestamp\n",
    "        AND '{promo_end_date_act}'::timestamp + INTERVAL '1 day' - INTERVAL '1 second'\n",
    "        ;\"\"\")\n",
    "\n",
    "        # ──────────────────────────────────────────────────────────\n",
    "        # Акцепты «Категории» в promo_start_date_act\n",
    "        # ──────────────────────────────────────────────────────────\n",
    "        gp_connector.execute_query(f\"DROP TABLE IF EXISTS ba.tmp_{mask}_{type}_offer_accept_act;\")\n",
    "        gp_connector.execute_query(f\"\"\"\n",
    "        CREATE TABLE ba.tmp_{mask}_{type}_offer_accept_act AS\n",
    "        SELECT DISTINCT oc.contact_id\n",
    "        FROM   dm.offer_contact oc\n",
    "        JOIN   dm.offer o ON o.offer_pk = oc.offer_pk\n",
    "        WHERE  o.code = '{code_act}'\n",
    "        AND  oc.created_on BETWEEN '{promo_start_date_act}'::timestamp\n",
    "        AND '{promo_end_date_act}'::timestamp + INTERVAL '1 day' - INTERVAL '1 second'\n",
    "        ;\"\"\")\n",
    "\n",
    "        # ──────────────────────────────────────────────────────────\n",
    "        # ЦА = покупали + акцептовали\n",
    "        # ──────────────────────────────────────────────────────────\n",
    "        gp_connector.execute_query(f\"DROP TABLE IF EXISTS ba.vt_{mask}_cus_ruls;\")\n",
    "        gp_connector.execute_query(f\"\"\"\n",
    "        CREATE TABLE ba.vt_{mask}_cus_ruls AS\n",
    "        SELECT contact_id\n",
    "        FROM ba.tmp_{mask}_{type}_buyers_act\n",
    "        INTERSECT\n",
    "        SELECT contact_id\n",
    "        FROM  ba.tmp_{mask}_{type}_offer_accept_act\n",
    "        ;\"\"\")\n",
    "\n",
    "    elif version == 2:\n",
    "        # ──────────────────────────────────────────────────────────\n",
    "        # Покупатели товаров в promo_start_date_prev + promo_start_date_act  (нужно ≥ 1 чек в обоих мес.)\n",
    "        # ──────────────────────────────────────────────────────────\n",
    "        gp_connector.execute_query(f\"DROP TABLE IF EXISTS ba.tmp_{mask}_{type}_buyers_act_prev;\")\n",
    "        gp_connector.execute_query(f\"\"\"\n",
    "        CREATE TABLE ba.tmp_{mask}_{type}_buyers_act_prev AS\n",
    "        SELECT contact_id\n",
    "        FROM   dm.cheque_item  ci\n",
    "        JOIN   ba.tmp_{mask}_{type}_articles a ON a.article_id = ci.article_id\n",
    "        JOIN   dm.cheque ch ON ch.cheque_pk = ci.cheque_pk\n",
    "        WHERE  ch.datetime BETWEEN '{promo_start_date_prev}'::timestamp      -- начало апреля\n",
    "        AND '{promo_end_date_act}'::timestamp -- конец мая\n",
    "        GROUP BY contact_id\n",
    "        HAVING COUNT(DISTINCT date_trunc('month', ch.datetime)) = 2   -- апр + май\n",
    "        ;\"\"\")\n",
    "\n",
    "        # ──────────────────────────────────────────────────────────\n",
    "        # Акцепты «Категории» в promo_start_date_act \n",
    "        # ──────────────────────────────────────────────────────────\n",
    "        gp_connector.execute_query(f\"DROP TABLE IF EXISTS ba.tmp_{mask}_{type}_offer_accept_act;\")\n",
    "        gp_connector.execute_query(f\"\"\"\n",
    "        CREATE TABLE ba.tmp_{mask}_{type}_offer_accept_act AS\n",
    "        SELECT DISTINCT oc.contact_id\n",
    "        FROM   dm.offer_contact oc\n",
    "        JOIN   dm.offer o ON o.offer_pk = oc.offer_pk\n",
    "        WHERE  o.code = '{code_act}'\n",
    "        AND  oc.created_on BETWEEN '{promo_start_date_act}'::timestamp\n",
    "        AND '{promo_end_date_act}'::timestamp + INTERVAL '1 day' - INTERVAL '1 second'\n",
    "        ;\"\"\")\n",
    "\n",
    "        # ──────────────────────────────────────────────────────────\n",
    "        # Акцепты «Категории» в promo_start_date_prev \n",
    "        # ──────────────────────────────────────────────────────────\n",
    "        gp_connector.execute_query(f\"DROP TABLE IF EXISTS ba.tmp_{mask}_{type}_offer_accept_prev;\")\n",
    "        gp_connector.execute_query(f\"\"\"\n",
    "        CREATE TABLE ba.tmp_{mask}_{type}_offer_accept_prev AS\n",
    "        SELECT DISTINCT oc.contact_id\n",
    "        FROM dm.offer_contact oc\n",
    "        JOIN dm.offer o ON o.offer_pk = oc.offer_pk\n",
    "        WHERE o.code = '{code_prev}'\n",
    "        AND oc.created_on BETWEEN '{promo_start_date_prev}'::timestamp\n",
    "        AND '{promo_end_date_prev}'::timestamp + INTERVAL '1 day' - INTERVAL '1 second'\n",
    "        ;\"\"\")\n",
    "\n",
    "        # ──────────────────────────────────────────────────────────\n",
    "        # ЦА = пересечение трех предыдущих таблиц\n",
    "        # ──────────────────────────────────────────────────────────\n",
    "        gp_connector.execute_query(f\"DROP TABLE IF EXISTS ba.vt_{mask}_cus_ruls;\")\n",
    "        gp_connector.execute_query(f\"\"\"\n",
    "        CREATE TABLE ba.vt_{mask}_cus_ruls AS\n",
    "        SELECT contact_id FROM ba.tmp_{mask}_{type}_buyers_act_prev\n",
    "        INTERSECT\n",
    "        SELECT contact_id FROM ba.tmp_{mask}_{type}_offer_accept_act\n",
    "        INTERSECT\n",
    "        SELECT contact_id FROM ba.tmp_{mask}_{type}_offer_accept_prev;\n",
    "        \"\"\")\n",
    "        \n",
    "    else:\n",
    "        # ──────────────────────────────────────────────────────────\n",
    "        # Покупатели товаров в promo_start_date_act\n",
    "        # ──────────────────────────────────────────────────────────\n",
    "        gp_connector.execute_query(f\"DROP TABLE IF EXISTS ba.tmp_{mask}_{type}_buyers_act;\")\n",
    "        gp_connector.execute_query(f\"\"\"\n",
    "        CREATE TABLE ba.tmp_{mask}_{type}_buyers_act AS\n",
    "        SELECT DISTINCT ch.contact_id\n",
    "        FROM   dm.cheque_item  ci\n",
    "        JOIN   ba.tmp_{mask}_{type}_articles a ON a.article_id = ci.article_id\n",
    "        JOIN   dm.cheque ch ON ch.cheque_pk = ci.cheque_pk\n",
    "        WHERE  ch.datetime BETWEEN '{promo_start_date_act}'::timestamp\n",
    "        AND '{promo_end_date_act}'::timestamp + INTERVAL '1 day' - INTERVAL '1 second'\n",
    "        ;\"\"\")\n",
    "\n",
    "        # ──────────────────────────────────────────────────────────\n",
    "        # Акцепты «Категории» в promo_start_date_act \n",
    "        # ──────────────────────────────────────────────────────────\n",
    "        gp_connector.execute_query(f\"DROP TABLE IF EXISTS ba.tmp_{mask}_{type}_offer_accept_act;\")\n",
    "        gp_connector.execute_query(f\"\"\"\n",
    "        CREATE TABLE ba.tmp_{mask}_{type}_offer_accept_act AS\n",
    "        SELECT DISTINCT oc.contact_id\n",
    "        FROM   dm.offer_contact oc\n",
    "        JOIN   dm.offer o ON o.offer_pk = oc.offer_pk\n",
    "        WHERE  o.code = '{code_act}'\n",
    "        AND  oc.created_on BETWEEN '{promo_start_date_act}'::timestamp\n",
    "        AND '{promo_end_date_act}'::timestamp + INTERVAL '1 day' - INTERVAL '1 second'\n",
    "        ;\"\"\")\n",
    "\n",
    "        # ──────────────────────────────────────────────────────────\n",
    "        # Акцепты «Категории» в promo_start_date_prev (для исключения из ЦА)\n",
    "        # ──────────────────────────────────────────────────────────\n",
    "        gp_connector.execute_query(f\"DROP TABLE IF EXISTS ba.tmp_{mask}_{type}_offer_accept_prev;\")\n",
    "        gp_connector.execute_query(f\"\"\"\n",
    "        CREATE TABLE ba.tmp_{mask}_{type}_offer_accept_prev AS\n",
    "        SELECT DISTINCT oc.contact_id\n",
    "        FROM dm.offer_contact oc\n",
    "        JOIN dm.offer o ON o.offer_pk = oc.offer_pk\n",
    "        WHERE o.code = '{code_prev}'\n",
    "        AND oc.created_on BETWEEN '{promo_start_date_prev}'::timestamp\n",
    "        AND '{promo_end_date_prev}'::timestamp + INTERVAL '1 day' - INTERVAL '1 second'\n",
    "        ;\"\"\")\n",
    "\n",
    "        # ──────────────────────────────────────────────────────────\n",
    "        # ЦА = покупали + акцептовали в promo_start_date_act, но не акцептовали в promo_start_date_prev\n",
    "        # ──────────────────────────────────────────────────────────\n",
    "        gp_connector.execute_query(f\"DROP TABLE IF EXISTS ba.vt_{mask}_cus_ruls;\")\n",
    "        gp_connector.execute_query(f\"\"\"\n",
    "        CREATE TABLE ba.vt_{mask}_cus_ruls AS\n",
    "        SELECT contact_id\n",
    "        FROM (\n",
    "        SELECT contact_id\n",
    "        FROM ba.tmp_{mask}_{type}_buyers_act\n",
    "        INTERSECT\n",
    "        SELECT contact_id\n",
    "        FROM ba.tmp_{mask}_{type}_offer_accept_act\n",
    "        ) t\n",
    "        WHERE contact_id NOT IN (\n",
    "        SELECT contact_id FROM ba.tmp_{mask}_{type}_offer_accept_prev)\n",
    "        ;\"\"\")\n",
    "\n",
    "\n",
    "    gp_connector.execute_query(f\"\"\"\n",
    "    DELETE FROM BA.T_ZIG_SPR_IDN_ACTN\n",
    "    WHERE ACTN_NAME = '{actn_name}'\n",
    "    ;\"\"\")\n",
    "\n",
    "    gp_connector.execute_query(f\"\"\"\n",
    "    INSERT INTO BA.T_ZIG_SPR_IDN_ACTN\n",
    "    SELECT DISTINCT\n",
    "        contact_id\n",
    "        ,'{actn_name}'\n",
    "        ,date('{promo_start_date_act}')\n",
    "        ,date('{promo_end_date_act}')\n",
    "    FROM \n",
    "        ba.vt_{mask}_cus_ruls\n",
    "    ;\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851e0489",
   "metadata": {},
   "source": [
    "## create_kg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "e29dd805",
   "metadata": {},
   "outputs": [],
   "source": [
    "@log_function_call\n",
    "def create_kg(gp_connector, mask, actn_name, art_grp_lvl_2_name, promo_start_date_act, promo_end_date_act, type, code_act, code_prev, promo_start_date_prev, promo_end_date_prev):\n",
    "    # ──────────────────────────────────────────────────────────\n",
    "    # Покупатели товаров в promo_start_date_act\n",
    "    # ──────────────────────────────────────────────────────────\n",
    "    gp_connector.execute_query(f\"DROP TABLE IF EXISTS ba.tmp_{mask}_{type}_buyers_act;\")\n",
    "    gp_connector.execute_query(f\"\"\"\n",
    "    CREATE TABLE ba.tmp_{mask}_{type}_buyers_act AS\n",
    "    SELECT DISTINCT ch.contact_id\n",
    "    FROM dm.cheque_item  ci\n",
    "    JOIN ba.tmp_{mask}_{type}_articles a  ON a.article_id = ci.article_id\n",
    "    JOIN dm.cheque ch ON ch.cheque_pk = ci.cheque_pk\n",
    "    WHERE ch.datetime BETWEEN '{promo_start_date_act}'::timestamp\n",
    "    AND '{promo_end_date_act}'::timestamp + INTERVAL '1 day' - INTERVAL '1 second'\n",
    "    ;\"\"\")\n",
    "\n",
    "    # ──────────────────────────────────────────────────────────\n",
    "    # Акцепты «Категории» в promo_start_date_act (для исключения из КГ)\n",
    "    # ──────────────────────────────────────────────────────────\n",
    "    gp_connector.execute_query(f\"DROP TABLE IF EXISTS ba.tmp_{mask}_{type}_offer_accept_act;\")\n",
    "    gp_connector.execute_query(f\"\"\"\n",
    "    CREATE TABLE ba.tmp_{mask}_{type}_offer_accept_act AS\n",
    "    SELECT DISTINCT oc.contact_id\n",
    "    FROM dm.offer_contact oc\n",
    "    JOIN dm.offer o ON o.offer_pk = oc.offer_pk\n",
    "    WHERE o.code = '{code_act}'\n",
    "    AND oc.created_on BETWEEN '{promo_start_date_act}'::timestamp\n",
    "    AND '{promo_end_date_act}'::timestamp + INTERVAL '1 day' - INTERVAL '1 second'\n",
    "    ;\"\"\")\n",
    "\n",
    "    # ──────────────────────────────────────────────────────────\n",
    "    # Акцепты «Категории» в promo_start_date_prev (для исключения из КГ)\n",
    "    # ──────────────────────────────────────────────────────────\n",
    "    gp_connector.execute_query(f\"DROP TABLE IF EXISTS ba.tmp_{mask}_{type}_offer_accept_prev;\")\n",
    "    gp_connector.execute_query(f\"\"\"\n",
    "    CREATE TABLE ba.tmp_{mask}_{type}_offer_accept_prev AS\n",
    "    SELECT DISTINCT oc.contact_id\n",
    "    FROM dm.offer_contact oc\n",
    "    JOIN dm.offer o ON o.offer_pk = oc.offer_pk\n",
    "    WHERE o.code = '{code_prev}'\n",
    "    AND oc.created_on BETWEEN '{promo_start_date_prev}'::timestamp\n",
    "    AND '{promo_end_date_prev}'::timestamp + INTERVAL '1 day' - INTERVAL '1 second'\n",
    "    ;\"\"\")\n",
    "\n",
    "    # ──────────────────────────────────────────────────────────\n",
    "    # КГ = покупали, но не акцептовали promo_start_date_prev‑promo_end_date_act\n",
    "    # ──────────────────────────────────────────────────────────\n",
    "    gp_connector.execute_query(f\"DROP TABLE IF EXISTS ba.vt_{mask}_cus_ctrl;\")\n",
    "    gp_connector.execute_query(f\"\"\"\n",
    "    CREATE TABLE ba.vt_{mask}_cus_ctrl AS\n",
    "    SELECT contact_id\n",
    "    FROM ba.tmp_{mask}_{type}_buyers_act\n",
    "    WHERE contact_id NOT IN (SELECT contact_id\n",
    "                             FROM ba.tmp_{mask}_{type}_offer_accept_act\n",
    "                             UNION \n",
    "                             SELECT contact_id\n",
    "                             FROM ba.tmp_{mask}_{type}_offer_accept_prev)\n",
    "    ;\"\"\")\n",
    "\n",
    "    # Объединяем ЦА и КГ\n",
    "    gp_connector.execute_query(f\"drop table if exists ba.{mask}_ca_and_kg;\")\n",
    "    gp_connector.execute_query(f\"\"\" --sql\n",
    "    create Table ba.{mask}_ca_and_kg (\n",
    "    contact_id INTEGER\n",
    "    )\n",
    "    WITH (\n",
    "        appendonly=true,\n",
    "        blocksize=32768,\n",
    "        compresstype=zstd,\n",
    "        compresslevel=4,\n",
    "        orientation=column)\n",
    "    distributed by (contact_id)\n",
    "    ;\"\"\")\n",
    "\n",
    "    gp_connector.execute_query(f\"\"\" --sql\n",
    "    insert into ba.{mask}_ca_and_kg \n",
    "        select contact_id\n",
    "        from ba.vt_{mask}_cus_ruls\n",
    "        \n",
    "        union\n",
    "        \n",
    "        select contact_id\n",
    "        from ba.vt_{mask}_cus_ctrl\n",
    "    ;\"\"\")\n",
    "\n",
    "    cnt_cus = gp_connector.gp(f\"\"\"SELECT count(1) FROM BA.T_ZIG_SPR_IDN_ACTN WHERE ACTN_NAME = '{actn_name}';\"\"\")\n",
    "\n",
    "    cnt_cus_value = cnt_cus.iloc[0, 0]\n",
    "    if cnt_cus_value <= 500_000:\n",
    "        n_KG = 10\n",
    "    elif 500_000 < cnt_cus_value <= 1_000_000:\n",
    "        n_KG = 5\n",
    "    else:\n",
    "        n_KG = 2\n",
    "    return n_KG\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e17c7a",
   "metadata": {},
   "source": [
    "## create_spr_actn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "09803ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "@log_function_call\n",
    "def create_spr_actn(gp_connector, mask, actn_type, actn_name, lengthprev, lengthpost):\n",
    "    gp_connector.execute_query(f\"\"\"\n",
    "    INSERT INTO BA.T_ZIG_SPR_ACTN\n",
    "    SELECT\n",
    "        ACTN_NAME\n",
    "        ,max_ACTN_ID + 1 AS ACTN_ID\n",
    "        ,DATE_START\n",
    "        ,DATE_END\n",
    "        ,DATE_END - DATE_START + 1 AS ACTN_LEGTH\n",
    "        ,'{actn_type}'\n",
    "    FROM (\n",
    "        SELECT DISTINCT\n",
    "            ACTN_NAME\n",
    "            ,DATE_START\n",
    "            ,DATE_END\n",
    "        FROM\n",
    "            BA.T_ZIG_SPR_IDN_ACTN TSIA\n",
    "        WHERE\n",
    "            ACTN_NAME = '{actn_name}'\n",
    "        ) D\n",
    "    LEFT JOIN (\n",
    "        SELECT max(ACTN_ID) AS max_ACTN_ID FROM BA.T_ZIG_SPR_ACTN\n",
    "        ) s ON 1 = 1\n",
    "    ;\n",
    "    \"\"\")\n",
    "\n",
    "    gp_connector.execute_query(f\"\"\"drop table if exists ba.vt_{mask}_spr_actn;\"\"\")\n",
    "    gp_connector.execute_query(f\"\"\" --sql\n",
    "    Create Table ba.vt_{mask}_spr_actn (\n",
    "    ACTN_NAME VARCHAR(50),\n",
    "    ACTN_ID SMALLINT,\n",
    "    ACTN_GRP VARCHAR(50),\n",
    "    DATE_START DATE,\n",
    "    DATE_END DATE,\n",
    "    ACTN_LENGTH INTEGER,\n",
    "    DATE_ST_PRE DATE,\n",
    "    DATE_END_LAST DATE\n",
    "    )\n",
    "    ;\"\"\")\n",
    "\n",
    "    gp_connector.execute_query(f\"\"\"\n",
    "    INSERT INTO ba.vt_{mask}_spr_actn\n",
    "    SELECT\n",
    "        ACTN_NAME\n",
    "        ,ACTN_ID\n",
    "        ,ACTN_GRP\n",
    "        ,DATE_START\n",
    "        ,DATE_END\n",
    "        ,ACTN_LENGTH\n",
    "        ,DATE_START - {lengthprev} AS DATE_ST_PRE\n",
    "        ,DATE_END + {lengthpost} AS DATE_END_LAST\n",
    "    FROM\n",
    "        BA.T_ZIG_SPR_ACTN\n",
    "    ;\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49dd67be",
   "metadata": {},
   "source": [
    "## days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "bab72ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "@log_function_call\n",
    "def create_days(gp_connector, mask, actn_id, DateStPre, DateEndLast):\n",
    "    # 1. Уже есть запись\n",
    "    row = gp_connector.gp(f\"\"\"\n",
    "        SELECT cutoff_id\n",
    "        FROM   ba.t_actn_fix\n",
    "        WHERE  actn_id = {actn_id};\n",
    "    \"\"\")\n",
    "\n",
    "    # 2. Если нет — берём актуальный cutoff и вставляем -----------------\n",
    "    if row.empty:\n",
    "        cutoff = actn_id - 1\n",
    "        cutoff = gp_connector.gp(\"\"\"\n",
    "            SELECT MAX(actn_id) AS id\n",
    "            FROM   ba.t_zig_spr_actn\n",
    "        \"\"\").id[0]\n",
    "\n",
    "        gp_connector.execute_query(f\"\"\"\n",
    "            INSERT INTO ba.t_actn_fix (actn_id, cutoff_id)\n",
    "            VALUES ({actn_id}, {cutoff});\n",
    "        \"\"\")\n",
    "    else:\n",
    "        cutoff = row.cutoff_id[0] \n",
    "\n",
    "    #КалендарныеНедели\n",
    "    gp_connector.execute_query(f\"\"\" Drop Table if exists ba.vt_{mask}_promo_week;\"\"\")\n",
    "    gp_connector.execute_query(f\"\"\" --sql\n",
    "    Create Table ba.vt_{mask}_promo_week (\n",
    "    day_id date,\n",
    "    week_id integer,\n",
    "    month_id integer\n",
    "    )\n",
    "    ;\"\"\")\n",
    "\n",
    "    gp_connector.execute_query(f\"\"\"\n",
    "    INSERT INTO ba.vt_{mask}_promo_week\n",
    "    SELECT \n",
    "        day_id\n",
    "        ,week_id_2\n",
    "        ,month_id\n",
    "    FROM dict.days d\n",
    "    WHERE day_id BETWEEN '2019-11-01' AND CURRENT_DATE\t\n",
    "    ;\"\"\")\n",
    "\n",
    "    #Справочник акция - день\n",
    "    gp_connector.execute_query(f\"\"\"drop table if exists ba.vt_{mask}_days;\"\"\")\n",
    "    gp_connector.execute_query(f\"\"\" --sql\n",
    "    Create Table ba.vt_{mask}_days (\n",
    "    ACTN_NAME VARCHAR(50),\n",
    "    ACTN_ID SMALLINT,\n",
    "    DATE_START DATE,\n",
    "    DATE_END DATE,\n",
    "    ACTN_LENGTH INTEGER,\n",
    "    DAY_ID DATE,\n",
    "    WEEK_ID INTEGER,\n",
    "    MONTH_ID INTEGER,\n",
    "    ACTN_PERIOD SMALLINT\n",
    "    )\n",
    "    ;\"\"\")\n",
    "\n",
    "    gp_connector.execute_query(f\"\"\"\n",
    "    INSERT INTO ba.vt_{mask}_days\n",
    "    SELECT\n",
    "        ACTN_NAME\n",
    "        ,ACTN_ID\n",
    "        ,DATE_START\n",
    "        ,DATE_END\n",
    "        ,ACTN_LENGTH\n",
    "        ,D.DAY_ID\n",
    "        ,D.WEEK_ID\n",
    "        ,D.MONTH_ID\n",
    "        ,CASE WHEN D.DAY_ID < DATE_START THEN 1\n",
    "            WHEN D.DAY_ID BETWEEN DATE_START AND DATE_END THEN 2\n",
    "            WHEN D.DAY_ID > DATE_END THEN 3\n",
    "        END AS ACTN_PERIOD\n",
    "    FROM\n",
    "        BA.T_ZIG_SPR_ACTN TSA\n",
    "    JOIN\n",
    "        ba.vt_{mask}_promo_week D\n",
    "        ON D.DAY_ID BETWEEN '{DateStPre}' AND '{DateEndLast}'\n",
    "    ;\"\"\")\n",
    "    return cutoff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6c304c",
   "metadata": {},
   "source": [
    "## days_cross"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "b4e0fbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@log_function_call\n",
    "def create_days_cross(gp_connector, mask, cutoff, actn_id):\n",
    "\t#Пересечение акций\n",
    "\tgp_connector.execute_query(f\"\"\"drop table if exists ba.vt_{mask}_actn_duble;\"\"\")\n",
    "\tgp_connector.execute_query(f\"\"\" --sql\n",
    "\tCreate Table ba.vt_{mask}_actn_duble (\n",
    "\tACTN_NAME VARCHAR(50),\n",
    "\tACTN_ID SMALLINT,\n",
    "\tACTN_GRP VARCHAR(50),\n",
    "\tDATE_START DATE,\n",
    "\tDATE_END DATE,\n",
    "\tACTN_NAME_DUBLE VARCHAR(50),\n",
    "\tACTN_ID_DUBLE SMALLINT,\n",
    "\tACTN_GRP_DUBLE VARCHAR(50),\n",
    "\tDATE_START_DUBLE DATE,\n",
    "\tDATE_END_DUBLE DATE\n",
    "\t)\n",
    "\t;\"\"\")\n",
    "\n",
    "\tgp_connector.execute_query(f\"\"\"\n",
    "\tINSERT INTO ba.vt_{mask}_actn_duble\n",
    "\tSELECT\n",
    "\t\tACTN_NAME\n",
    "\t\t,ACTN_ID\n",
    "\t\t,ACTN_GRP\n",
    "\t\t,DATE_START\n",
    "\t\t,DATE_END\n",
    "\t\t,ACTN_NAME_DUBLE\n",
    "\t\t,ACTN_ID_DUBLE\n",
    "\t\t,ACTN_GRP_DUBLE\n",
    "\t\t,DATE_START_DUBLE\n",
    "\t\t,DATE_END_DUBLE\n",
    "\tFROM (\n",
    "\t\tSELECT DISTINCT\n",
    "\t\t\tSA.ACTN_NAME\n",
    "\t\t\t,SA.ACTN_ID\n",
    "\t\t\t,SA.ACTN_GRP\n",
    "\t\t\t,SA.DATE_START\n",
    "\t\t\t,SA.DATE_END\n",
    "\t\t\t,B.ACTN_NAME AS ACTN_NAME_DUBLE\n",
    "\t\t\t,B.ACTN_ID AS ACTN_ID_DUBLE\n",
    "\t\t\t,B.ACTN_GRP AS ACTN_GRP_DUBLE\n",
    "\t\t\t,B.DATE_START AS DATE_START_DUBLE\n",
    "\t\t\t,B.DATE_END AS DATE_END_DUBLE\n",
    "\t\t\t,CASE WHEN SA.ACTN_ID <> B.ACTN_ID THEN 1 ELSE 0 END IS_DUBLE\n",
    "\t\tFROM (\n",
    "\t\t\tSELECT DISTINCT\n",
    "\t\t\t\tSA.ACTN_NAME\n",
    "\t\t\t\t,SA.ACTN_ID\n",
    "\t\t\t\t,SA.ACTN_GRP\n",
    "\t\t\t\t,SA.DATE_START\n",
    "\t\t\t\t,SA.DATE_END\n",
    "\t\t\t\t,D.DAY_ID\n",
    "\t\t\tFROM \n",
    "\t\t\t\tba.vt_{mask}_days D\n",
    "\t\t\tJOIN\n",
    "\t\t\t\tba.vt_{mask}_spr_actn SA\n",
    "\t\t\t\tON D.DAY_ID BETWEEN SA.DATE_START AND SA.DATE_END\n",
    "\t\t\t) SA\n",
    "\t\tJOIN\n",
    "\t\t\tba.vt_{mask}_spr_actn B\n",
    "\t\t\tON SA.DAY_ID BETWEEN B.DATE_START AND B.DATE_END\n",
    "\t\t\tAND B.actn_id <= {cutoff} -- <<< добавил\n",
    "\t\t) D\n",
    "\tWHERE\n",
    "\t\tIS_DUBLE = 1\n",
    "\t\tand ACTN_ID > ACTN_ID_DUBLE\n",
    "\t\tand (\n",
    "\t\t\t(\n",
    "\t\t\tACTN_GRP = 'Кроссформатная акция'\n",
    "\t\t\tand\n",
    "\t\t\tACTN_GRP_DUBLE in ('Кроссформатная акция','Купонная акция','Механики MAU')\n",
    "\t\t\t)\n",
    "\t\t\tor\n",
    "\t\t\t(\n",
    "\t\t\t\tACTN_GRP in ('Акция Лояльности', 'Купонная акция','Механики MAU') \n",
    "\t\t\t\tand\n",
    "\t\t\t\tACTN_GRP_DUBLE in ('Акция Лояльности','Кроссформатная акция','Купонная акция','Механики MAU')\n",
    "\t\t\t)\n",
    "\t\t\t\n",
    "\t\t\tor \n",
    "\t\t\t(\n",
    "\t\t\t\tACTN_GRP in ('Выпечка','Оценка проекта','Пилот','Розыгрыш','Розыгрыши','ТВ реклама') \n",
    "\t\t\t\tand\n",
    "\t\t\t\tACTN_GRP_DUBLE in ('Выпечка','Оценка проекта','Пилот','Розыгрыш','Розыгрыши','ТВ реклама')\n",
    "\t\t\t)\n",
    "\t\t\t)\n",
    "\t;\"\"\")\n",
    "\n",
    "\tdf_duble_actn = gp_connector.gp(f\"\"\"SELECT * FROM ba.vt_{mask}_actn_duble WHERE ACTN_ID = {actn_id};\"\"\")\n",
    "\n",
    "\t#Список акций, которые нужно исключить из exclude_actn_str\n",
    "\tactions_to_exclude = []\n",
    "\t#Фильтруем df_duble_actn, удаляя указанные акции\n",
    "\tdf_filtered = df_duble_actn[~df_duble_actn[\"actn_name_duble\"].isin(actions_to_exclude)]\n",
    "\n",
    "\t#Формируем строку для SQL\n",
    "\texclude_actn_str = gp_connector.to_sql_list(df_filtered[\"actn_name_duble\"], quotes=True)\n",
    "\n",
    "\texclude_actn = exclude_actn_str\n",
    "\n",
    "\t#Справочник дней с пересечениями акций\n",
    "\tgp_connector.execute_query(f\"\"\"drop table if exists ba.vt_{mask}_days_cross;\"\"\")\n",
    "\tgp_connector.execute_query(f\"\"\" --sql\n",
    "\tCreate Table ba.vt_{mask}_days_cross (\n",
    "\tCONTACT_ID INTEGER,\n",
    "\tACTN_NAME VARCHAR(50),\n",
    "\tACTN_ID SMALLINT,\n",
    "\tACTN_GRP VARCHAR(50),\n",
    "\tDATE_START DATE,\n",
    "\tDATE_END DATE,\n",
    "\tDAY_ID DATE,\n",
    "\tWEEK_ID INTEGER,\n",
    "\tIS_CROSS SMALLINT,\n",
    "\tCNT_DAY_WO_CROSS INTEGER\n",
    "\t)\n",
    "\t;\"\"\")\n",
    "\n",
    "\tgp_connector.execute_query(f\"\"\" --sql\n",
    "\tinsert into ba.vt_{mask}_days_cross\n",
    "\tWITH data AS (\n",
    "\t\tSELECT DISTINCT\n",
    "\t\t\tc.CONTACT_ID\n",
    "\t\t\t,c.ACTN_NAME\n",
    "\t\t\t,c.ACTN_ID\n",
    "\t\t\t,c.ACTN_GRP\n",
    "\t\t\t,c.DATE_START\n",
    "\t\t\t,c.DATE_END\n",
    "\t\t\t,c.DAY_ID\n",
    "\t\t\t,c.WEEK_ID\n",
    "\t\t\t,CASE WHEN d.CONTACT_ID IS NOT NULL THEN 1 ELSE 0 END AS IS_CROSS\n",
    "\t\tFROM (\n",
    "\t\t\tSELECT\n",
    "\t\t\t\tsi.CONTACT_ID\n",
    "\t\t\t\t,sa.ACTN_NAME\n",
    "\t\t\t\t,sa.ACTN_ID\n",
    "\t\t\t\t,sa.ACTN_GRP\n",
    "\t\t\t\t,sa.DATE_START\n",
    "\t\t\t\t,sa.DATE_END\n",
    "\t\t\t\t,d.DAY_ID\n",
    "\t\t\t\t,d.WEEK_ID\n",
    "\t\t\tFROM \n",
    "\t\t\t\tba.vt_{mask}_promo_week d\n",
    "\t\t\tJOIN\n",
    "\t\t\t\tba.vt_{mask}_spr_actn sa \n",
    "\t\t\t\tON d.DAY_ID BETWEEN SA.DATE_START AND SA.DATE_END\n",
    "\t\t\t\tAND sa.ACTN_ID = {actn_id}\n",
    "\t\t\tJOIN\n",
    "\t\t\t\tBA.T_ZIG_SPR_IDN_ACTN si \n",
    "\t\t\t\ton si.ACTN_NAME = sa.ACTN_NAME\n",
    "\t\t\t) c\n",
    "\t\tLEFT JOIN (               --Определяю клиентов и свободные даты из других акций\n",
    "\t\t\tSELECT distinct\n",
    "\t\t\t\tCONTACT_ID\n",
    "\t\t\t\t,DAY_ID\n",
    "\t\t\tFROM\n",
    "\t\t\t\tBA.T_ZIG_SPR_IDN_ACTN c\n",
    "\t\t\tJOIN\n",
    "\t\t\t\tba.vt_{mask}_actn_duble a\n",
    "\t\t\t\ton a.ACTN_ID = {actn_id}\n",
    "\t\t\t\tand a.actn_id_duble <= {cutoff} -- <<< добавил\n",
    "\t\t\t\tand a.ACTN_NAME_DUBLE = c.ACTN_NAME\n",
    "\t\t\t\tand a.ACTN_NAME_DUBLE not in ({exclude_actn})\n",
    "\t\t\tjoin\n",
    "\t\t\t\tba.vt_{mask}_promo_week d\n",
    "\t\t\t\ton d.DAY_ID between a.date_start_duble and a.date_end_duble\n",
    "\t\t\t) d ON d.DAY_ID = c.DAY_ID\n",
    "\t\t\t\tAND d.CONTACT_ID = c.CONTACT_ID\n",
    "\t\tWHERE\n",
    "\t\t\tc.ACTN_ID = {actn_id}\n",
    "\t)\n",
    "\n",
    "\tSELECT DISTINCT\n",
    "\t\tCONTACT_ID\n",
    "\t\t,ACTN_NAME\n",
    "\t\t,ACTN_ID\n",
    "\t\t,ACTN_GRP\n",
    "\t\t,DATE_START\n",
    "\t\t,DATE_END\n",
    "\t\t,DAY_ID\n",
    "\t\t,WEEK_ID\n",
    "\t\t,IS_CROSS\n",
    "\t\t,MAX(CNT_DAY) OVER (PARTITION BY CONTACT_ID)  AS CNT_DAY_WO_CROSS\n",
    "\tFROM (\n",
    "\t\tSELECT DISTINCT\n",
    "\t\t\tCONTACT_ID\n",
    "\t\t\t,ACTN_NAME\n",
    "\t\t\t,ACTN_ID\n",
    "\t\t\t,ACTN_GRP\n",
    "\t\t\t,DATE_START\n",
    "\t\t\t,DATE_END\n",
    "\t\t\t,DAY_ID\n",
    "\t\t\t,WEEK_ID\n",
    "\t\t\t,IS_CROSS\n",
    "\t\t\t,CASE WHEN IS_CROSS = 0 THEN COUNT(DAY_ID) OVER (PARTITION BY IS_CROSS, CONTACT_ID) ELSE 0 END as CNT_DAY\n",
    "\t\tFROM\n",
    "\t\t\tdata\n",
    "\t) d\n",
    "\torder by DAY_ID\n",
    "\t;\"\"\")\n",
    "\n",
    "\tgp_connector.execute_query(f\"\"\"--sql \n",
    "\tdelete from ba.vt_{mask}_days_cross\n",
    "\twhere CNT_DAY_WO_CROSS = 0\n",
    "\t;\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76ed1f8",
   "metadata": {},
   "source": [
    "## frod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "a5917661",
   "metadata": {},
   "outputs": [],
   "source": [
    "@log_function_call\n",
    "def frod(gp_connector, mask):\n",
    "    gp_connector.execute_query(f\"\"\"drop table if exists ba.vt_{mask}_frod;\"\"\")\n",
    "    gp_connector.execute_query(f\"\"\" --sql\n",
    "    CREATE TABLE ba.vt_{mask}_frod (\n",
    "    CONTACT_ID NUMERIC\n",
    "    )  WITH (\n",
    "        appendonly=true,\n",
    "        blocksize=32768,\n",
    "        compresstype=zstd,\n",
    "        compresslevel=4,\n",
    "        orientation=column)\n",
    "    ;\"\"\")\n",
    "\n",
    "    gp_connector.execute_query(f\"\"\" --sql \n",
    "    insert into ba.vt_{mask}_frod\n",
    "    select contact_id\n",
    "    from dm.contact_ea \n",
    "    where  lower(name) like '%client%soft%' \n",
    "        or lower(name) like  '%client%hard%'    \n",
    "    group by 1\n",
    "    ;\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0b4665",
   "metadata": {},
   "source": [
    "## create_trn_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "8b1e3a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@log_function_call\n",
    "def create_trn_0(gp_connector, mask, actnId, lengthPrev):\n",
    "    month = gp_connector.gp(f\"\"\"\n",
    "            select\n",
    "                    month_id\n",
    "                    ,min(day_id) as min_dt\n",
    "                    ,max(day_id) as max_dt\n",
    "            from\n",
    "                    ba.vt_{mask}_days\n",
    "                where\n",
    "                    actn_id = {actnId} \n",
    "                    and actn_period = 1\n",
    "                group by 1 \n",
    "                order by 1\n",
    "            ;\"\"\")\n",
    "\n",
    "    month\n",
    "\n",
    "    #Период \"до\". Транзакции\n",
    "    gp_connector.execute_query(f\"\"\"drop table if exists ba.vt_{mask}_trn_0;\"\"\")\n",
    "    gp_connector.execute_query(f\"\"\" --sql\n",
    "    CREATE TABLE ba.vt_{mask}_trn_0 (\n",
    "    CONTACT_ID NUMERIC,\n",
    "    ORGUNIT_ID INTEGER,\n",
    "    SQUARE_TRADE NUMERIC,\n",
    "    FRMT_ID INTEGER,\n",
    "    REGION_ID INTEGER,\n",
    "    DAY_DATE DATE,\n",
    "    CHEQUE_PK BYTEA,\n",
    "    SUMM_DISCOUNTED NUMERIC,\n",
    "    ACTN_PERIOD SMALLINT,\n",
    "    REGISTRATION_DATE DATE,\n",
    "    CNT_DAY_WO_CROSS INTEGER,\n",
    "    IS_TRN_FLTR SMALLINT,\n",
    "    CARD_NUMBER VARCHAR(50)\n",
    "    )  WITH (\n",
    "        appendonly=true,\n",
    "        blocksize=32768,\n",
    "        compresstype=zstd,\n",
    "        compresslevel=4,\n",
    "        orientation=column)\n",
    "    DISTRIBUTED BY (contact_id)\n",
    "    ;\"\"\")\n",
    "\n",
    "    for i in tqdm_notebook(range(len(month))):\n",
    "        dt_start = str(month.min_dt[i])\n",
    "        dt_end = str(month.max_dt[i])\n",
    "\n",
    "        gp_connector.execute_query(f\"\"\"drop table if exists ba.vt_{mask}_trn_temp;\"\"\")\n",
    "        gp_connector.execute_query(f\"\"\" --sql\n",
    "        CREATE TABLE ba.vt_{mask}_trn_temp (\n",
    "        contact_id integer,\n",
    "        orgunit_id integer,\n",
    "        datetime date,\n",
    "        cheque_pk bytea,\n",
    "        summ_discounted numeric,\n",
    "        card_number varchar,\n",
    "        number varchar,\n",
    "        dt_load date\n",
    "        ) \n",
    "            WITH (\n",
    "            appendonly=true,\n",
    "            blocksize=32768,\n",
    "            compresstype=zstd,\n",
    "            compresslevel=4,\n",
    "            orientation=column)\n",
    "        DISTRIBUTED BY (card_number, datetime, number)\n",
    "        ;\"\"\")\n",
    "\n",
    "        gp_connector.execute_query(f\"\"\" --sql\n",
    "        insert into ba.vt_{mask}_trn_temp \n",
    "        SELECT \n",
    "            t.contact_id\n",
    "            ,t.orgunit_id\n",
    "            ,t.datetime\n",
    "            ,t.cheque_pk\n",
    "            ,t.summ_discounted\n",
    "            ,t.card_number\n",
    "            ,t.number\n",
    "            ,t.dt_load\n",
    "        FROM \n",
    "            dm.cheque t\n",
    "        WHERE\n",
    "            operation_type_id = 1\n",
    "            AND t.datetime between ('{dt_start}'::timestamp) AND ('{dt_end}'::timestamp + interval '1' day - interval '1' second)\n",
    "        ;\"\"\")\n",
    "\n",
    "        gp_connector.execute_query(f\"\"\" --sql\n",
    "        INSERT INTO ba.vt_{mask}_trn_0\n",
    "        SELECT \n",
    "            contact_id\n",
    "            ,orgunit_id\n",
    "            ,square_trade\n",
    "            ,frmt_id\n",
    "            ,region_id\n",
    "            ,datetime\n",
    "            ,cheque_pk\n",
    "            ,summ_discounted\n",
    "            ,ACTN_PERIOD                 -- Период \"ДО\"\n",
    "            ,registration_date\n",
    "            ,CNT_DAY_WO_CROSS\n",
    "            ,IS_TRN_FLTR\n",
    "            ,card_number\n",
    "        from (\n",
    "            SELECT \n",
    "                t.contact_id\n",
    "                ,t.orgunit_id\n",
    "                ,w.square_trade\n",
    "                ,w.frmt_id\n",
    "                ,w.region_id\n",
    "                ,t.datetime\n",
    "                ,t.cheque_pk\n",
    "                ,t.summ_discounted\n",
    "                ,1 as ACTN_PERIOD                 -- Период \"ДО\"\n",
    "                ,c.registration_date\n",
    "                ,{lengthPrev} as CNT_DAY_WO_CROSS\n",
    "                ,0 as IS_TRN_FLTR\n",
    "                ,t.card_number\n",
    "                ,row_number() over(partition by t.card_number, t.datetime, t.number order by t.datetime nulls last, t.dt_load nulls first) rn\n",
    "            FROM \n",
    "                ba.vt_{mask}_trn_temp t\n",
    "            JOIN\n",
    "                ba.vt_{mask}_whs ww on ww.orgunit_id = t.orgunit_id\n",
    "            JOIN\n",
    "                dm.whs w ON w.orgunit_id = t.orgunit_id\n",
    "            JOIN \n",
    "                dm.contact c ON c.contact_id = t.contact_id\n",
    "            ) d\n",
    "        WHERE\n",
    "            rn = 1\n",
    "        ;\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e8e13f",
   "metadata": {},
   "source": [
    "## create_trn_0_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "c6a2d6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "@log_function_call\n",
    "def create_trn_0_v2(gp_connector, mask, actnId, lengthActn):\n",
    "    month = gp_connector.gp(f\"\"\"\n",
    "            select\n",
    "                    month_id\n",
    "                    ,min(day_id) as min_dt\n",
    "                    ,max(day_id) as max_dt\n",
    "            from\n",
    "                    ba.vt_{mask}_days\n",
    "                where\n",
    "                    actn_id = {actnId} \n",
    "                    and actn_period = 2\n",
    "                group by 1 \n",
    "                order by 1\n",
    "            ;\"\"\")\n",
    "\n",
    "    month\n",
    "    \n",
    "    for i in tqdm_notebook(range(len(month))):\n",
    "        dt_start = month.min_dt[i]\n",
    "        dt_end = month.max_dt[i]\n",
    "\n",
    "        gp_connector.execute_query(f\"\"\"drop table if exists ba.vt_{mask}_trn_temp;\"\"\")\n",
    "        gp_connector.execute_query(f\"\"\" --sql\n",
    "        CREATE TABLE ba.vt_{mask}_trn_temp  ( \n",
    "        contact_id integer,\n",
    "        orgunit_id integer,\n",
    "        datetime date,\n",
    "        cheque_pk bytea,\n",
    "        summ_discounted numeric,\n",
    "        card_number varchar (50),\n",
    "        number varchar (50),\n",
    "        dt_load date\n",
    "        )\n",
    "        WITH (\n",
    "            appendonly=true,\n",
    "            blocksize=32768,\n",
    "            compresstype=zstd,\n",
    "            compresslevel=4,\n",
    "            orientation=column)\n",
    "        DISTRIBUTED BY (card_number, datetime, number)\n",
    "        ;\"\"\")\n",
    "\n",
    "        gp_connector.execute_query(f\"\"\" --sql\n",
    "        insert into ba.vt_{mask}_trn_temp\n",
    "        SELECT \n",
    "            t.contact_id\n",
    "            ,t.orgunit_id\n",
    "            ,t.datetime\n",
    "            ,t.cheque_pk\n",
    "            ,t.summ_discounted\n",
    "            ,t.card_number\n",
    "            ,t.number\n",
    "            ,t.dt_load\n",
    "        FROM \n",
    "            dm.cheque t\n",
    "        WHERE\n",
    "            operation_type_id = 1\n",
    "            AND t.datetime between ('{dt_start}'::timestamp) AND ('{dt_end}'::timestamp + interval '1' day - interval '1' second)\n",
    "        ;\"\"\")\n",
    "\n",
    "        gp_connector.execute_query(f\"\"\" --sql\n",
    "        INSERT INTO ba.vt_{mask}_trn_0\n",
    "        SELECT \n",
    "            contact_id\n",
    "            ,orgunit_id\n",
    "            ,square_trade\n",
    "            ,frmt_id\n",
    "            ,region_id\n",
    "            ,datetime\n",
    "            ,cheque_pk\n",
    "            ,summ_discounted\n",
    "            ,ACTN_PERIOD                 -- Период \"Акционный\"\n",
    "            ,registration_date\n",
    "            ,CNT_DAY_WO_CROSS\n",
    "            ,IS_TRN_FLTR\n",
    "            ,card_number\n",
    "        from (\n",
    "            SELECT \n",
    "                t.contact_id\n",
    "                ,t.orgunit_id\n",
    "                ,w.square_trade\n",
    "                ,w.frmt_id\n",
    "                ,w.region_id\n",
    "                ,t.datetime\n",
    "                ,t.cheque_pk\n",
    "                ,t.summ_discounted\n",
    "                ,2 as ACTN_PERIOD                 -- Акционный период\n",
    "                ,c.registration_date\n",
    "                ,coalesce(cd.CNT_DAY_WO_CROSS, {lengthActn}) as CNT_DAY_WO_CROSS\n",
    "                ,coalesce(cd.IS_CROSS, 0) as IS_TRN_FLTR\n",
    "                ,t.card_number\n",
    "                ,row_number() over(partition by t.card_number, t.datetime, t.number order by t.datetime nulls last, t.dt_load nulls first) rn\n",
    "            FROM \n",
    "                ba.vt_{mask}_trn_temp t\n",
    "            JOIN\n",
    "                ba.vt_{mask}_whs ww on ww.orgunit_id = t.orgunit_id\n",
    "            JOIN\n",
    "                dm.whs w ON w.orgunit_id = t.orgunit_id\n",
    "            JOIN \n",
    "                dm.contact c ON c.contact_id = t.contact_id\n",
    "            left JOIN \n",
    "                ba.vt_{mask}_days_cross cd\n",
    "                on cd.contact_id = t.contact_id\n",
    "                and cd.day_id = date(t.datetime)\n",
    "            ) d\n",
    "        where\n",
    "            rn = 1\n",
    "        ;\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9852fa7",
   "metadata": {},
   "source": [
    "## create_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "283f7580",
   "metadata": {},
   "outputs": [],
   "source": [
    "@log_function_call\n",
    "def create_agg(gp_connector, mask, DateStart):\n",
    "    gp_connector.execute_query(f\"ANALYZE ba.{mask}_ca_and_kg;\")\n",
    "    gp_connector.execute_query(f\"ANALYZE ba.vt_{mask}_trn_0;\")\n",
    "    gp_connector.execute_query(f\"ANALYZE dict.days;\")\n",
    "    gp_connector.execute_query(f\"ANALYZE ba.vt_{mask}_frod;\")\n",
    "    \"\"\"\n",
    "    Формирует таблицу ba.vt_{mask}_trn_1 с агрегированными показателями\n",
    "    по периодам (1 — период ДО, 2 — период АКЦИИ).\n",
    "    Если is_kg_needed = TRUE для данной акции, \n",
    "    добавляем JOIN на ba.t_{mask}_control_group, \n",
    "    чтобы оставить только клиентов из контрольной группы.\n",
    "    \"\"\"\n",
    "\n",
    "    # Смотрим, нужна ли контрольная группа\n",
    "    df_check_kg = gp_connector.gp(f\"\"\"\n",
    "        SELECT is_kg_needed\n",
    "        FROM BA.helper_category\n",
    "        WHERE mask = '{mask}'\n",
    "    \"\"\")\n",
    "    if df_check_kg.empty:\n",
    "        logging.warning(f\"[create_agg] Не найдена запись в helper_category для mask={mask}.\")\n",
    "        return\n",
    "\n",
    "    is_kg_needed = df_check_kg['is_kg_needed'].iloc[0]  # True/False\n",
    "\n",
    "    # Строим дополнительный JOIN, если КГ нужна\n",
    "    if is_kg_needed:\n",
    "        kg_join_str = f\"JOIN ba.{mask}_ca_and_kg cg ON cg.contact_id = t.contact_id\"\n",
    "        logging.info(f\"[create_agg][mask={mask}] КГ включена => используем JOIN на {mask}_ca_and_kg.\")\n",
    "    else:\n",
    "        kg_join_str = \"\"  # Пустая строка, если КГ не требуется\n",
    "\n",
    "    logging.info(f\"[create_agg][mask={mask}] Начинаем создание таблицы ba.vt_{mask}_trn_1...\")\n",
    "\n",
    "    # Агрегация транзакций\n",
    "    gp_connector.execute_query(f\"\"\"drop table if exists ba.vt_{mask}_trn_1;\"\"\")\n",
    "    gp_connector.execute_query(f\"\"\"\n",
    "    CREATE TABLE ba.vt_{mask}_trn_1 (\n",
    "    CONTACT_ID INTEGER,\n",
    "    ACTN_PERIOD SMALLINT,\n",
    "    FRMT_ID INTEGER,\n",
    "    REGION_ID INTEGER,\n",
    "    REGISTRATION_DATE DATE,\n",
    "    CNT_DAY INTEGER,\n",
    "    CNT_TRN INTEGER,\n",
    "    OPSUM NUMERIC,\n",
    "    AVG_TXN NUMERIC,\n",
    "    AVG_SPEND NUMERIC,\n",
    "    CNT_TRN_FLTR INTEGER,\n",
    "    AVG_TXN_FLTR NUMERIC,\n",
    "    LONG_VISIT INTEGER,\n",
    "    SQUARE_TRADE NUMERIC,\n",
    "    CNT_WEEK INTEGER\n",
    "    )\n",
    "    WITH (\n",
    "        appendonly=true,\n",
    "        blocksize=32768,\n",
    "        compresstype=zstd,\n",
    "        compresslevel=4,\n",
    "        orientation=column)\n",
    "    DISTRIBUTED BY (contact_id)\n",
    "    ;\"\"\")\n",
    "\n",
    "    gp_connector.execute_query(f\"\"\"\n",
    "    INSERT INTO ba.vt_{mask}_trn_1\n",
    "    WITH trn AS ( \n",
    "        SELECT\n",
    "            CONTACT_ID\n",
    "            ,ORGUNIT_ID\n",
    "            ,SQUARE_TRADE\n",
    "            ,ACTN_PERIOD\n",
    "            ,FRMT_ID\n",
    "            ,REGION_ID\n",
    "            ,REGISTRATION_DATE\n",
    "            ,DAY_DATE\n",
    "            ,CHEQUE_PK\n",
    "            ,SUMM_DISCOUNTED\n",
    "            ,CNT_DAY_WO_CROSS\n",
    "            ,IS_TRN_FLTR\n",
    "        FROM\n",
    "            ba.vt_{mask}_trn_0\n",
    "        WHERE\n",
    "            SUMM_DISCOUNTED > 0\n",
    "            AND ACTN_PERIOD = 1    --Период \"ДО\"\n",
    "        ), favorite_whs AS (\n",
    "        select\n",
    "            contact_id,\n",
    "            orgunit_id,\n",
    "            frmt_id,\n",
    "            region_id,\n",
    "            square_trade,\n",
    "            cnt_trn,\n",
    "            row_number() over (partition by contact_id, frmt_id, region_id order by cnt_trn desc) as rang_whs\n",
    "        from (\n",
    "            select\n",
    "                contact_id,\n",
    "                orgunit_id,\n",
    "                frmt_id,\n",
    "                region_id,\n",
    "                max(square_trade) as square_trade,\n",
    "                count(distinct cheque_pk) as cnt_trn\n",
    "            from trn\n",
    "            group by 1,2,3,4) d\n",
    "        )\n",
    "\n",
    "    SELECT\n",
    "        t.CONTACT_ID\n",
    "        ,ACTN_PERIOD\n",
    "        ,t.FRMT_ID\n",
    "        ,t.REGION_ID\n",
    "        ,REGISTRATION_DATE\n",
    "        ,COUNT(DISTINCT DAY_DATE)                       AS CNT_DAY\n",
    "        ,COUNT(DISTINCT CHEQUE_PK)                      AS CNT_TRN\n",
    "        ,SUM(SUMM_DISCOUNTED)                           AS OPSUM\n",
    "        ,AVG(SUMM_DISCOUNTED)                           AS AVG_TXN\n",
    "        ,SUM(case when IS_TRN_FLTR = 0 then SUMM_DISCOUNTED end) / MAX(CNT_DAY_WO_CROSS)   AS AVG_SPEND\n",
    "        ,COUNT(DISTINCT case when IS_TRN_FLTR = 0 then CHEQUE_PK end)                      AS CNT_TRN_FLTR\n",
    "        ,AVG(case when IS_TRN_FLTR = 0 then SUMM_DISCOUNTED end)                           AS AVG_TXN_FLTR\n",
    "        ,MAX(date('{DateStart}')) - MAX(DAY_DATE)       AS LONG_VISIT\n",
    "        ,max(w.square_trade)                            as square_trade\n",
    "        ,COUNT(DISTINCT d.week_id_2)                    AS CNT_WEEK\n",
    "    FROM trn t\n",
    "    left join favorite_whs w \n",
    "        on w.contact_id = t.contact_id\n",
    "        and w.orgunit_id = t.orgunit_id\n",
    "        and w.rang_whs = 1\n",
    "    {kg_join_str}\n",
    "    join dict.days d on d.day_id = t.day_date\n",
    "    left join ba.vt_{mask}_frod f on f.contact_id = t.contact_id\n",
    "    where f.contact_id is null\n",
    "    GROUP BY 1,2,3,4,5\n",
    "    ;\"\"\")\n",
    "\n",
    "    gp_connector.execute_query(f\"\"\"\n",
    "    INSERT INTO ba.vt_{mask}_trn_1\n",
    "    WITH trn AS ( \n",
    "        SELECT\n",
    "            CONTACT_ID\n",
    "            ,ORGUNIT_ID\n",
    "            ,SQUARE_TRADE\n",
    "            ,ACTN_PERIOD\n",
    "            ,FRMT_ID\n",
    "            ,REGION_ID\n",
    "            ,REGISTRATION_DATE\n",
    "            ,DAY_DATE\n",
    "            ,CHEQUE_PK\n",
    "            ,SUMM_DISCOUNTED\n",
    "            ,CNT_DAY_WO_CROSS\n",
    "            ,IS_TRN_FLTR\n",
    "        FROM\n",
    "            ba.vt_{mask}_trn_0\n",
    "        WHERE\n",
    "            SUMM_DISCOUNTED > 0\n",
    "            AND ACTN_PERIOD = 2    --Акц.период\n",
    "        ), favorite_whs AS (\n",
    "        select\n",
    "            contact_id,\n",
    "            orgunit_id,\n",
    "            frmt_id,\n",
    "            region_id,\n",
    "            square_trade,\n",
    "            cnt_trn,\n",
    "            row_number() over (partition by contact_id, frmt_id, region_id order by cnt_trn desc) as rang_whs\n",
    "        from (\n",
    "            select\n",
    "                contact_id,\n",
    "                orgunit_id,\n",
    "                frmt_id,\n",
    "                region_id,\n",
    "                max(square_trade) as square_trade,\n",
    "                count(distinct cheque_pk) as cnt_trn\n",
    "            from trn\n",
    "            group by 1,2,3,4) d\n",
    "        )\n",
    "\n",
    "    SELECT\n",
    "        t.CONTACT_ID\n",
    "        ,ACTN_PERIOD\n",
    "        ,t.FRMT_ID\n",
    "        ,t.REGION_ID\n",
    "        ,REGISTRATION_DATE\n",
    "        ,COUNT(DISTINCT DAY_DATE)                       AS CNT_DAY\n",
    "        ,COUNT(DISTINCT CHEQUE_PK)                      AS CNT_TRN\n",
    "        ,SUM(SUMM_DISCOUNTED)                           AS OPSUM\n",
    "        ,AVG(SUMM_DISCOUNTED)                           AS AVG_TXN\n",
    "        ,SUM(case when IS_TRN_FLTR = 0 then SUMM_DISCOUNTED end) / MAX(CNT_DAY_WO_CROSS)   AS AVG_SPEND\n",
    "        ,COUNT(DISTINCT case when IS_TRN_FLTR = 0 then CHEQUE_PK end)                      AS CNT_TRN_FLTR\n",
    "        ,AVG(case when IS_TRN_FLTR = 0 then SUMM_DISCOUNTED end)                           AS AVG_TXN_FLTR\n",
    "        ,0                                              AS LONG_VISIT\n",
    "        ,max(w.square_trade)                            as square_trade\n",
    "        ,COUNT(DISTINCT d.week_id_2)                    AS CNT_WEEK\n",
    "    FROM\n",
    "        trn t\n",
    "    left join\n",
    "        favorite_whs w \n",
    "        on w.contact_id = t.contact_id\n",
    "        and w.orgunit_id = t.orgunit_id\n",
    "        and w.rang_whs = 1\n",
    "    {kg_join_str}\n",
    "    join dict.days d on d.day_id = t.day_date\n",
    "    left join ba.vt_{mask}_frod f on f.contact_id = t.contact_id\n",
    "    where f.contact_id is null\n",
    "    GROUP BY 1,2,3,4,5\n",
    "    ;\n",
    "    \"\"\")\n",
    "\n",
    "    # Проверка результатов\n",
    "\n",
    "    df_check = gp_connector.gp(f\"\"\"\n",
    "        SELECT ACTN_PERIOD, COUNT(DISTINCT CONTACT_ID) AS cnt_cont\n",
    "        FROM ba.vt_{mask}_trn_1\n",
    "        GROUP BY ACTN_PERIOD\n",
    "        ORDER BY ACTN_PERIOD\n",
    "    \"\"\")\n",
    "    logging.info(f\"[create_agg][mask={mask}] Кол-во уникальных клиентов по периодам:\\n{df_check}\")\n",
    "\n",
    "    df_null_square = gp_connector.gp(f\"\"\"\n",
    "        SELECT *\n",
    "        FROM ba.vt_{mask}_trn_1\n",
    "        WHERE square_trade IS NULL\n",
    "        LIMIT 5\n",
    "    \"\"\")\n",
    "    if not df_null_square.empty:\n",
    "        logging.warning(f\"[create_agg][mask={mask}] Есть записи, где square_trade IS NULL. Пример:\\n{df_null_square}\")\n",
    "\n",
    "    logging.info(f\"[create_agg][mask={mask}] Агрегация транзакций (trn_1) завершена.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6ecaba",
   "metadata": {},
   "source": [
    "## process_clear_and_aggregate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "662e72f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@log_function_call\n",
    "def process_clear_and_aggregate(gp_connector, mask):\n",
    "\t# от покупки\n",
    "\tgp_connector.execute_query(f\"\"\"drop table if exists ba.vt_{mask}_ca_clear;\"\"\")\n",
    "\tgp_connector.execute_query(f\"\"\"\n",
    "\tCREATE TABLE ba.vt_{mask}_ca_clear (\n",
    "\tcontact_id integer,\n",
    "\topsum numeric,\n",
    "\tcnt_trn numeric,\n",
    "\tRANK_OPSUM_MIN numeric,\n",
    "\tRANK_OPSUM_MAX numeric,\n",
    "\tRANK_TRN_MIN numeric,\n",
    "\tRANK_TRN_MAX numeric\n",
    "\t)\n",
    "\tWITH (\n",
    "\t\tappendonly=true,\n",
    "\t\tblocksize=32768,\n",
    "\t\tcompresstype=zstd,\n",
    "\t\tcompresslevel=4,\n",
    "\t\torientation=column)\n",
    "\t;\"\"\")\n",
    "\n",
    "\tgp_connector.execute_query(f\"\"\"\n",
    "\tINSERT INTO ba.vt_{mask}_ca_clear\n",
    "\tWITH cus_actn AS (\n",
    "\t\tselect\n",
    "\t\t\tcontact_id\n",
    "\t\tfrom\n",
    "\t\t\tba.vt_{mask}_days_cross\n",
    "\t\tgroup by 1\n",
    "\t\t), cus_data as (\n",
    "\t\tselect\n",
    "\t\t\tt.contact_id\n",
    "\t\t\t,sum(opsum) as opsum\n",
    "\t\t\t,sum(cnt_trn) as cnt_trn\n",
    "\t\tFROM \n",
    "\t\t\tba.vt_{mask}_trn_1 t\n",
    "\t\tJOIN\n",
    "\t\t\tcus_actn c on c.contact_id = t.contact_id\n",
    "\t\tGROUP BY 1\n",
    "\t\t), ca_rank as (\n",
    "\t\tSELECT \n",
    "\t\t\tPERCENTILE_DISC(0.01) WITHIN GROUP (ORDER BY opsum) as RANK_OPSUM_MIN\n",
    "\t\t\t,PERCENTILE_DISC(0.99) WITHIN GROUP (ORDER BY opsum) as RANK_OPSUM_MAX\n",
    "\t\t\t,PERCENTILE_DISC(0.01) WITHIN GROUP (ORDER BY cnt_trn) as RANK_TRN_MIN\n",
    "\t\t\t,PERCENTILE_DISC(0.99) WITHIN GROUP (ORDER BY cnt_trn) as RANK_TRN_MAX\n",
    "\t\tFROM\n",
    "\t\t\tcus_data\n",
    "\t\t)\n",
    "\tselect\n",
    "\t\tt.contact_id\n",
    "\t\t,t.opsum\n",
    "\t\t,t.cnt_trn\n",
    "\t\t,RANK_OPSUM_MIN\n",
    "\t\t,RANK_OPSUM_MAX\n",
    "\t\t,RANK_TRN_MIN\n",
    "\t\t,RANK_TRN_MAX\n",
    "\tfrom\n",
    "\t\tcus_data t\n",
    "\tjoin\n",
    "\t\tca_rank c on 1=1\n",
    "\t;\"\"\")\n",
    "\t\n",
    "\t# CA/KG\n",
    "\tgp_connector.execute_query(f\"\"\"drop table if exists ba.vt_{mask}_cus_clear;\"\"\")\n",
    "\tgp_connector.execute_query(f\"\"\" --sql\n",
    "\tCreate Table ba.vt_{mask}_cus_clear (\n",
    "\tCONTACT_ID INTEGER\n",
    "\t);\n",
    "\t\"\"\")\n",
    "\n",
    "\tgp_connector.execute_query(f\"\"\"\n",
    "\tINSERT INTO ba.vt_{mask}_cus_clear\n",
    "\tWITH cus_kg as (\n",
    "\t\tselect\n",
    "\t\t\tt.contact_id\n",
    "\t\t\t,sum(opsum) as opsum\n",
    "\t\t\t,sum(cnt_trn) as cnt_trn\n",
    "\t\tFROM \n",
    "\t\t\tba.vt_{mask}_trn_1 t\n",
    "\t\tleft join\n",
    "\t\t\t(select contact_id from ba.vt_{mask}_days_cross group by 1) c on c.contact_id = t.contact_id\n",
    "\t\twhere\n",
    "\t\t\tc.contact_id is null\n",
    "\t\tGROUP BY 1\n",
    "\t\t), rank as (\n",
    "\t\tselect distinct\n",
    "\t\t\tRANK_OPSUM_MIN\n",
    "\t\t\t,RANK_OPSUM_MAX\n",
    "\t\t\t,RANK_TRN_MIN\n",
    "\t\t\t,RANK_TRN_MAX\n",
    "\t\tfrom\n",
    "\t\t\tba.vt_{mask}_ca_clear\n",
    "\t\t)\n",
    "\tselect\n",
    "\t\tcontact_id\n",
    "\tfrom\n",
    "\t\tba.vt_{mask}_ca_clear\n",
    "\twhere\n",
    "\t\topsum BETWEEN RANK_OPSUM_MIN AND RANK_OPSUM_MAX\n",
    "\t\tand cnt_trn BETWEEN RANK_TRN_MIN AND RANK_TRN_MAX\n",
    "\tUNION \n",
    "\tselect\n",
    "\t\tt.contact_id\n",
    "\tfrom\n",
    "\t\tcus_kg t\n",
    "\tjoin\n",
    "\t\trank r on 1=1\n",
    "\twhere\n",
    "\t\topsum BETWEEN RANK_OPSUM_MIN AND RANK_OPSUM_MAX\n",
    "\t\tand cnt_trn BETWEEN RANK_TRN_MIN AND RANK_TRN_MAX\n",
    "\t;\"\"\")\n",
    "\t# Агрегация транзакций\n",
    "\tgp_connector.execute_query(f\"\"\"drop table if exists ba.vt_{mask}_trn;\"\"\")\n",
    "\tgp_connector.execute_query(f\"\"\"\n",
    "\tCREATE TABLE ba.vt_{mask}_trn (\n",
    "\tCONTACT_ID INTEGER,\n",
    "\tACTN_PERIOD SMALLINT,\n",
    "\tFRMT_ID INTEGER,\n",
    "\tREGION_ID INTEGER,\n",
    "\tREGISTRATION_DATE DATE,\n",
    "\tCNT_DAY INTEGER,\n",
    "\tCNT_TRN INTEGER,\n",
    "\tOPSUM NUMERIC,\n",
    "\tAVG_TXN NUMERIC,\n",
    "\tAVG_SPEND NUMERIC,\n",
    "\tCNT_TRN_FLTR INTEGER,\n",
    "\tAVG_TXN_FLTR NUMERIC,\n",
    "\tLONG_VISIT INTEGER,\n",
    "\tSQUARE_TRADE NUMERIC,\n",
    "\tCNT_WEEK INTEGER\n",
    "\t)\n",
    "\tWITH (\n",
    "\t\tappendonly=true,\n",
    "\t\tblocksize=32768,\n",
    "\t\tcompresstype=zstd,\n",
    "\t\tcompresslevel=4,\n",
    "\t\torientation=column)\n",
    "\t;\"\"\")\n",
    "\n",
    "\tgp_connector.execute_query(f\"\"\"\n",
    "\tINSERT INTO ba.vt_{mask}_trn\n",
    "\tSELECT\n",
    "\t\tt.CONTACT_ID\n",
    "\t\t,ACTN_PERIOD\n",
    "\t\t,FRMT_ID\n",
    "\t\t,REGION_ID\n",
    "\t\t,REGISTRATION_DATE\n",
    "\t\t,CNT_DAY\n",
    "\t\t,CNT_TRN\n",
    "\t\t,OPSUM\n",
    "\t\t,AVG_TXN\n",
    "\t\t,AVG_SPEND\n",
    "\t\t,CNT_TRN_FLTR\n",
    "\t\t,AVG_TXN_FLTR\n",
    "\t\t,LONG_VISIT\n",
    "\t\t,SQUARE_TRADE\n",
    "\t\t,CNT_WEEK\n",
    "\tFROM\n",
    "\t\tba.vt_{mask}_trn_1 t\n",
    "\tjoin\n",
    "\t\tba.vt_{mask}_cus_clear c on c.contact_id = t.contact_id\n",
    "\t;\n",
    "\t\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae6a04e",
   "metadata": {},
   "source": [
    "## reg_new_returned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "4b00961e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@log_function_call\n",
    "def reg_new_returned(gp_connector, mask, promo_start_date):\n",
    "   #ОПЕРЕДЕЛЯЮ ТИП КЛИЕНТА: РЕГУЛЯРНЫЙ/НОВЫЙ/ВЕРНУВШИЙСЯ\n",
    "    gp_connector.execute_query(f\"\"\"drop table if exists ba.vt_{mask}_cus_type;\"\"\")\n",
    "    gp_connector.execute_query(f\"\"\" --sql\n",
    "    Create Table ba.vt_{mask}_cus_type (\n",
    "    CONTACT_ID INTEGER,\n",
    "    FRMT_ID INTEGER,\n",
    "    REGION_ID INTEGER,\n",
    "    CUS_TYPE VARCHAR(10)\n",
    "    )\n",
    "    WITH (\n",
    "        appendonly=true,\n",
    "        blocksize=32768,\n",
    "        compresstype=zstd,\n",
    "        compresslevel=4,\n",
    "        orientation=column);\n",
    "    \"\"\")\n",
    "\n",
    "    #regular\n",
    "    gp_connector.execute_query(f\"\"\"\n",
    "    INSERT INTO ba.vt_{mask}_cus_type\n",
    "    SELECT\n",
    "        CONTACT_ID\n",
    "        ,FRMT_ID\n",
    "        ,REGION_ID\n",
    "        ,'REGULAR'\n",
    "    FROM\n",
    "        ba.vt_{mask}_trn\n",
    "    GROUP BY \n",
    "        CONTACT_ID\n",
    "        ,FRMT_ID\n",
    "        ,REGION_ID\n",
    "    HAVING COUNT(DISTINCT ACTN_PERIOD) = 2\n",
    "    ;\n",
    "    \"\"\")\n",
    "    #returned\n",
    "    gp_connector.execute_query(f\"\"\"\n",
    "    INSERT INTO ba.vt_{mask}_cus_type\n",
    "    SELECT DISTINCT\n",
    "        CONTACT_ID\n",
    "        ,FRMT_ID\n",
    "        ,REGION_ID\n",
    "        ,'RETURNED'\n",
    "    FROM (\n",
    "        SELECT DISTINCT\n",
    "            CONTACT_ID\n",
    "            ,FRMT_ID\n",
    "            ,REGION_ID\n",
    "        FROM\n",
    "            ba.vt_{mask}_trn\n",
    "        WHERE\n",
    "            ACTN_PERIOD = 2\n",
    "            AND REGISTRATION_DATE < '{promo_start_date}'\n",
    "        EXCEPT \n",
    "            SELECT DISTINCT\n",
    "                CONTACT_ID\n",
    "                ,FRMT_ID\n",
    "                ,REGION_ID\n",
    "            FROM\n",
    "                ba.vt_{mask}_trn\n",
    "            WHERE\n",
    "                ACTN_PERIOD = 1\n",
    "        ) D\n",
    "    ;\n",
    "    \"\"\")\n",
    "    #new\n",
    "    gp_connector.execute_query(f\"\"\"\n",
    "    INSERT INTO ba.vt_{mask}_cus_type\n",
    "    SELECT DISTINCT\n",
    "        CONTACT_ID\n",
    "        ,FRMT_ID\n",
    "        ,REGION_ID\n",
    "        ,'NEW'\n",
    "    FROM (\n",
    "        SELECT DISTINCT\n",
    "            CONTACT_ID\n",
    "            ,FRMT_ID\n",
    "            ,REGION_ID\n",
    "        FROM\n",
    "            ba.vt_{mask}_trn\n",
    "        WHERE\n",
    "            ACTN_PERIOD = 2\n",
    "        EXCEPT \n",
    "            SELECT DISTINCT\n",
    "                CONTACT_ID\n",
    "                ,FRMT_ID\n",
    "                ,REGION_ID\n",
    "            FROM\n",
    "                ba.vt_{mask}_cus_type\n",
    "        ) D\n",
    "    ;\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6dc63b0",
   "metadata": {},
   "source": [
    "## clear_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "c7d2f866",
   "metadata": {},
   "outputs": [],
   "source": [
    "@log_function_call\n",
    "def clear_reg(gp_connector, mask, actnId, actn_name, lengthPrev, lengthActn): \n",
    "    #Очистка Регулярных\n",
    "    gp_connector.execute_query(f\"\"\"drop table if exists ba.vt_{mask}_cus_reg;\"\"\")\n",
    "    gp_connector.execute_query(f\"\"\" --sql\n",
    "    Create Table ba.vt_{mask}_cus_reg (\n",
    "    CONTACT_ID INTEGER,\n",
    "    IS_CA SMALLINT,\n",
    "    ACTN_ID SMALLINT,\n",
    "    ACTN_PERIOD SMALLINT,\n",
    "    FRMT_ID INTEGER,\n",
    "    REGION_ID INTEGER,\n",
    "    CUS_TYPE varchar(10),\n",
    "    CNT_DAY INTEGER,\n",
    "    CNT_TRN INTEGER,\n",
    "    OPSUM NUMERIC,\n",
    "    AVG_TXN NUMERIC,\n",
    "    AVG_SPEND NUMERIC,\n",
    "    CNT_TRN_FLTR INTEGER,\n",
    "    AVG_TXN_FLTR NUMERIC,\n",
    "    LONG_VISIT INTEGER,\n",
    "    SQUARE_TRADE NUMERIC,\n",
    "    CNT_WEEK INTEGER\n",
    "    )\n",
    "    WITH (\n",
    "        appendonly=true,\n",
    "        blocksize=32768,\n",
    "        compresstype=zstd,\n",
    "        compresslevel=4,\n",
    "        orientation=column);\n",
    "    \"\"\")\n",
    "\n",
    "    gp_connector.execute_query(f\"\"\"\n",
    "    INSERT INTO ba.vt_{mask}_cus_reg\n",
    "    SELECT\n",
    "        CONTACT_ID\n",
    "        ,IS_CA\n",
    "        ,ACTN_ID\n",
    "        ,ACTN_PERIOD\n",
    "        ,FRMT_ID\n",
    "        ,REGION_ID\n",
    "        ,CUS_TYPE\n",
    "        ,CNT_DAY\n",
    "        ,CNT_TRN\n",
    "        ,OPSUM\n",
    "        ,AVG_TXN\n",
    "        ,AVG_SPEND\n",
    "        ,CNT_TRN_FLTR\n",
    "        ,AVG_TXN_FLTR\n",
    "        ,LONG_VISIT\n",
    "        ,SQUARE_TRADE\n",
    "        ,CNT_WEEK\n",
    "    FROM (\n",
    "        SELECT\n",
    "            T.CONTACT_ID\n",
    "            ,case when ca.CONTACT_ID is not null then 1 else 0 end IS_CA\n",
    "            ,{actnId} AS ACTN_ID\n",
    "            ,ACTN_PERIOD\n",
    "            ,T.FRMT_ID\n",
    "            ,T.REGION_ID\n",
    "            ,CUS_TYPE\n",
    "            ,CNT_DAY\n",
    "            ,CNT_TRN\n",
    "            ,OPSUM\n",
    "            ,AVG_TXN\n",
    "            ,AVG_SPEND\n",
    "            ,CNT_TRN_FLTR\n",
    "            ,AVG_TXN_FLTR\n",
    "            ,LONG_VISIT\n",
    "            ,SQUARE_TRADE\n",
    "            ,CNT_WEEK\n",
    "            ,max(case when ACTN_PERIOD = 1 then CNT_TRN else 0 end) over (partition by t.CONTACT_ID, t.FRMT_ID, t.REGION_ID) as CNT_TRN_PREV\n",
    "            ,max(case when ACTN_PERIOD = 2 then CNT_TRN else 0 end) over (partition by t.CONTACT_ID, t.FRMT_ID, t.REGION_ID) as CNT_TRN_ACTN\n",
    "            ,max(case when ACTN_PERIOD = 1 then CNT_DAY else 0 end) over (partition by t.CONTACT_ID, t.FRMT_ID, t.REGION_ID) as CNT_DAY_PREV\n",
    "            ,max(case when ACTN_PERIOD = 2 then CNT_DAY else 0 end) over (partition by t.CONTACT_ID, t.FRMT_ID, t.REGION_ID) as CNT_DAY_ACTN\n",
    "        FROM \n",
    "            ba.vt_{mask}_trn T\n",
    "        JOIN\n",
    "            ba.vt_{mask}_cus_type C\n",
    "            ON C.CONTACT_ID = T.CONTACT_ID \n",
    "            AND C.FRMT_ID = T.FRMT_ID\n",
    "            AND C.REGION_ID = T.REGION_ID\n",
    "        left JOIN\n",
    "            (SELECT distinct CONTACT_ID FROM BA.T_ZIG_SPR_IDN_ACTN WHERE ACTN_NAME = '{actn_name}') CA \n",
    "            ON CA.CONTACT_ID = T.CONTACT_ID\n",
    "        ) D\n",
    "    WHERE 1=1\n",
    "        and CNT_DAY_PREV >= 2\n",
    "        and CNT_DAY_ACTN >= 2\n",
    "        and CNT_TRN_PREV BETWEEN 2 AND {lengthPrev}\n",
    "        and CNT_TRN_ACTN BETWEEN 2 AND {lengthActn}\n",
    "    ;\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea84f293",
   "metadata": {},
   "source": [
    "## dna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "85a8515b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@log_function_call\n",
    "def dna(gp_connector, mask, lengthActn):\n",
    "#ДНК клиента по признакам Траты/ср.чек/частота покупок\n",
    "\tgp_connector.execute_query(f\"\"\"drop table if exists ba.vt_{mask}_ca_frmt;\"\"\")\n",
    "\tgp_connector.execute_query(f\"\"\" --sql\n",
    "\tCreate Table ba.vt_{mask}_ca_frmt (\n",
    "\tCONTACT_ID INTEGER,\n",
    "\tFRMT_ID INTEGER,\n",
    "\tREGION_ID INTEGER,\n",
    "\tCUS_TYPE varchar(10),\n",
    "\tOPSUM_LVL INTEGER,\n",
    "\tAVG_TXN_LVL INTEGER,\n",
    "\tCNT_TRN_LVL INTEGER\n",
    "\t)\n",
    "\tWITH (\n",
    "\t\tappendonly=true,\n",
    "\t\tblocksize=32768,\n",
    "\t\tcompresstype=zstd,\n",
    "\t\tcompresslevel=4,\n",
    "\t\torientation=column);\n",
    "\t\"\"\")\n",
    "\t#подбираю КГ со схожим поведением\n",
    "\tgp_connector.execute_query(f\"\"\"drop table if exists ba.vt_{mask}_kg_frmt;\"\"\")\n",
    "\tgp_connector.execute_query(f\"\"\" --sql\n",
    "\tCreate Table ba.vt_{mask}_kg_frmt (\n",
    "\tCONTACT_ID INTEGER,\n",
    "\tFRMT_ID INTEGER,\n",
    "\tREGION_ID INTEGER,\n",
    "\tCUS_TYPE varchar(10),\n",
    "\tOPSUM_LVL INTEGER,\n",
    "\tAVG_TXN_LVL INTEGER,\n",
    "\tCNT_TRN_LVL INTEGER\n",
    "\t)\n",
    "\tWITH (\n",
    "\t\tappendonly=true,\n",
    "\t\tblocksize=32768,\n",
    "\t\tcompresstype=zstd,\n",
    "\t\tcompresslevel=4,\n",
    "\t\torientation=column);\n",
    "\t\"\"\")\n",
    "\n",
    "\tgp_connector.execute_query(f\"\"\"\n",
    "\tINSERT INTO ba.vt_{mask}_ca_frmt\n",
    "\tSELECT\n",
    "\t\tc.CONTACT_ID\n",
    "\t\t,FRMT_ID\n",
    "\t\t,REGION_ID\n",
    "\t\t,CUS_TYPE\n",
    "\t\t,COALESCE((FLOOR(OPSUM/{lengthActn}/100) * 100), 0) AS OPSUM_LVL\t--100\n",
    "\t\t,COALESCE((FLOOR(AVG_TXN/50) * 50), 0) AS AVG_TXN_LVL\n",
    "\t\t,COALESCE((FLOOR(CNT_TRN/1)*1), 0) AS CNT_TRN_LVL\n",
    "\tFROM\n",
    "\t\tba.vt_{mask}_cus_reg c\n",
    "\tJOIN\n",
    "\t\t(SELECT distinct CONTACT_ID FROM ba.vt_{mask}_days_cross) CA \n",
    "\t\tON CA.CONTACT_ID = c.CONTACT_ID\n",
    "\tWHERE \n",
    "\t\tCUS_TYPE = 'REGULAR'\n",
    "\t\tand IS_CA = 1\n",
    "\t\tand ACTN_PERIOD = 1 -- prev\n",
    "\t;\n",
    "\t\"\"\")\n",
    "\tgp_connector.execute_query(f\"\"\"\n",
    "\tINSERT INTO ba.vt_{mask}_kg_frmt\n",
    "\tSELECT\n",
    "\t\tCONTACT_ID\n",
    "\t\t,FRMT_ID\n",
    "\t\t,REGION_ID\n",
    "\t\t,CUS_TYPE\n",
    "\t\t,COALESCE((FLOOR(OPSUM/{lengthActn}/100) * 100), 0) AS OPSUM_LVL\t--100\n",
    "\t\t,COALESCE((FLOOR(AVG_TXN/50) * 50), 0) AS AVG_TXN_LVL\n",
    "\t\t,COALESCE((FLOOR(CNT_TRN/1)*1), 0) AS CNT_TRN_LVL\n",
    "\tFROM\n",
    "\t\tba.vt_{mask}_cus_reg\n",
    "\tWHERE \n",
    "\t\tCUS_TYPE = 'REGULAR'\n",
    "\t\tand IS_CA = 0\n",
    "\t\tand ACTN_PERIOD = 1 -- prev\n",
    "\t;\n",
    "\t\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a14238",
   "metadata": {},
   "source": [
    "## kg_for_ca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "75967c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@log_function_call\n",
    "def kg_for_ca(gp_connector, mask, n_KG):\n",
    "\tgp_connector.execute_query(f\"\"\"drop table if exists ba.vt_{mask}_ca_frmt_grp;\"\"\")\n",
    "\tgp_connector.execute_query(f\"\"\" --sql\n",
    "\tCreate Table ba.vt_{mask}_ca_frmt_grp (\n",
    "\tFRMT_ID INTEGER,\n",
    "\tREGION_ID INTEGER,\n",
    "\tCUS_TYPE VARCHAR(10),\n",
    "\tOPSUM_LVL INTEGER,\n",
    "\tAVG_TXN_LVL INTEGER,\n",
    "\tCNT_TRN_LVL INTEGER,\n",
    "\tCNT_CUS INTEGER\n",
    "\t)\n",
    "\tWITH (\n",
    "\t\tappendonly=true,\n",
    "\t\tblocksize=32768,\n",
    "\t\tcompresstype=zstd,\n",
    "\t\tcompresslevel=4,\n",
    "\t\torientation=column);\n",
    "\t\"\"\")\n",
    "\n",
    "\tgp_connector.execute_query(f\"\"\"\n",
    "\tINSERT INTO ba.vt_{mask}_ca_frmt_grp\n",
    "\tSELECT\n",
    "\t\tFRMT_ID\n",
    "\t\t,REGION_ID\n",
    "\t\t,CUS_TYPE\n",
    "\t\t,OPSUM_LVL\n",
    "\t\t,AVG_TXN_LVL\n",
    "\t\t,CNT_TRN_LVL\n",
    "\t\t,COUNT(DISTINCT CONTACT_ID) AS CNT_CUS\n",
    "\tFROM\n",
    "\t\tba.vt_{mask}_ca_frmt\n",
    "\tGROUP BY\n",
    "\t\tFRMT_ID\n",
    "\t\t,REGION_ID\n",
    "\t\t,CUS_TYPE\n",
    "\t\t,OPSUM_LVL\n",
    "\t\t,AVG_TXN_LVL\n",
    "\t\t,CNT_TRN_LVL\n",
    "\t;\n",
    "\t\"\"\")\n",
    "\tgp_connector.execute_query(f\"\"\"drop table if exists ba.vt_{mask}_kg_lfl_frmt;\"\"\")\n",
    "\tgp_connector.execute_query(f\"\"\" --sql\n",
    "\tCreate Table ba.vt_{mask}_kg_lfl_frmt (\n",
    "\tCONTACT_ID INTEGER,\n",
    "\tFRMT_ID INTEGER,\n",
    "\tREGION_ID INTEGER,\n",
    "\tCUS_TYPE varchar(10),\n",
    "\tOPSUM_LVL INTEGER,\n",
    "\tAVG_TXN_LVL INTEGER,\n",
    "\tCNT_TRN_LVL INTEGER,\n",
    "\tCNT_CUS INTEGER,\n",
    "\tCNT_KG INTEGER\n",
    "\t)\n",
    "\tWITH (\n",
    "\t\tappendonly=true,\n",
    "\t\tblocksize=32768,\n",
    "\t\tcompresstype=zstd,\n",
    "\t\tcompresslevel=4,\n",
    "\t\torientation=column)\n",
    "\t;\"\"\")\n",
    "\n",
    "\tgp_connector.execute_query(f\"\"\"\n",
    "\tINSERT INTO ba.vt_{mask}_kg_lfl_frmt\n",
    "\tSELECT\n",
    "\t\tCONTACT_ID\n",
    "\t\t,FRMT_ID\n",
    "\t\t,REGION_ID\n",
    "\t\t,CUS_TYPE\n",
    "\t\t,OPSUM_LVL\n",
    "\t\t,AVG_TXN_LVL\n",
    "\t\t,CNT_TRN_LVL\n",
    "\t\t,CNT_CUS\n",
    "\t\t,CNT_KG\n",
    "\tFROM (\n",
    "\t\tSELECT\n",
    "\t\t\tCONTACT_ID\n",
    "\t\t\t,FRMT_ID\n",
    "\t\t\t,REGION_ID\n",
    "\t\t\t,CUS_TYPE\n",
    "\t\t\t,OPSUM_LVL\n",
    "\t\t\t,AVG_TXN_LVL\n",
    "\t\t\t,CNT_TRN_LVL\n",
    "\t\t\t,CNT_CUS\n",
    "\t\t\t,ROW_NUM\n",
    "\t\t\t,count(CONTACT_ID) over (partition by FRMT_ID, REGION_ID, CUS_TYPE, OPSUM_LVL, AVG_TXN_LVL, CNT_TRN_LVL) as CNT_KG\n",
    "\t\tFROM (\n",
    "\t\t\tSELECT\n",
    "\t\t\t\tKF.CONTACT_ID\n",
    "\t\t\t\t,KF.FRMT_ID\n",
    "\t\t\t\t,KF.REGION_ID\n",
    "\t\t\t\t,kf.CUS_TYPE\n",
    "\t\t\t\t,KF.OPSUM_LVL\n",
    "\t\t\t\t,KF.AVG_TXN_LVL\n",
    "\t\t\t\t,KF.CNT_TRN_LVL\n",
    "\t\t\t\t,CFG.CNT_CUS\n",
    "\t\t\t\t,ROW_NUMBER() OVER (PARTITION BY KF.REGION_ID, KF.FRMT_ID, KF.CUS_TYPE, KF.OPSUM_LVL, KF.AVG_TXN_LVL, KF.CNT_TRN_LVL order by KF.CNT_TRN_LVL desc) AS ROW_NUM\n",
    "\t\t\tFROM\n",
    "\t\t\t\tba.vt_{mask}_kg_frmt KF\n",
    "\t\t\tJOIN\n",
    "\t\t\t\tba.vt_{mask}_ca_frmt_grp CFG\n",
    "\t\t\t\ton CFG.FRMT_ID = KF.FRMT_ID\n",
    "\t\t\t\tAND CFG.REGION_ID = KF.REGION_ID\n",
    "\t\t\t\tAND cfg.CUS_TYPE = kf.CUS_TYPE\n",
    "\t\t\t\tAND CFG.OPSUM_LVL = KF.OPSUM_LVL\n",
    "\t\t\t\tAND CFG.AVG_TXN_LVL = KF.AVG_TXN_LVL\n",
    "\t\t\t\tAND CFG.CNT_TRN_LVL = KF.CNT_TRN_LVL\n",
    "\t\t\t) d\n",
    "\t\tWHERE\n",
    "\t\t\t(case when FRMT_ID = 1 then ROW_NUM else 0 end) <= CNT_CUS * {n_KG}\n",
    "\t\t) d\n",
    "\t;\n",
    "\t\"\"\")\n",
    "\t#Фильтрую ЦА для которых не подобралась КГ\n",
    "\tgp_connector.execute_query(f\"\"\"drop table if exists ba.vt_{mask}_ca_lfl_frmt;\"\"\")\n",
    "\tgp_connector.execute_query(f\"\"\" --sql\n",
    "\tCreate Table ba.vt_{mask}_ca_lfl_frmt (\n",
    "\tCONTACT_ID INTEGER,\n",
    "\tFRMT_ID INTEGER,\n",
    "\tREGION_ID INTEGER,\n",
    "\tCUS_TYPE varchar(10),\n",
    "\tOPSUM_LVL INTEGER,\n",
    "\tAVG_TXN_LVL INTEGER,\n",
    "\tCNT_TRN_LVL INTEGER\n",
    "\t)\n",
    "\tWITH (\n",
    "\t\tappendonly=true,\n",
    "\t\tblocksize=32768,\n",
    "\t\tcompresstype=zstd,\n",
    "\t\tcompresslevel=4,\n",
    "\t\torientation=column);\n",
    "\t\"\"\")\n",
    "\n",
    "\tgp_connector.execute_query(f\"\"\"\n",
    "\tINSERT INTO ba.vt_{mask}_ca_lfl_frmt\n",
    "\tSELECT\n",
    "\t\tC.CONTACT_ID\n",
    "\t\t,C.FRMT_ID\n",
    "\t\t,C.REGION_ID\n",
    "\t\t,c.CUS_TYPE\n",
    "\t\t,C.OPSUM_LVL\n",
    "\t\t,C.AVG_TXN_LVL\n",
    "\t\t,C.CNT_TRN_LVL\n",
    "\tFROM \n",
    "\t\tba.vt_{mask}_ca_frmt C\n",
    "\tJOIN (\n",
    "\t\tSELECT DISTINCT\n",
    "\t\t\tFRMT_ID\n",
    "\t\t\t,REGION_ID\n",
    "\t\t\t,CUS_TYPE\n",
    "\t\t\t,OPSUM_LVL\n",
    "\t\t\t,AVG_TXN_LVL\n",
    "\t\t\t,CNT_TRN_LVL\n",
    "\t\tFROM \n",
    "\t\t\tba.vt_{mask}_kg_lfl_frmt\n",
    "\t\t) D\n",
    "\t\ton D.FRMT_ID = C.FRMT_ID\n",
    "\t\tAND D.REGION_ID = C.REGION_ID\n",
    "\t\tAND d.CUS_TYPE = c.CUS_TYPE\n",
    "\t\tAND d.OPSUM_LVL = c.OPSUM_LVL\n",
    "\t\tAND D.AVG_TXN_LVL = C.AVG_TXN_LVL\n",
    "\t\tAND D.CNT_TRN_LVL = C.CNT_TRN_LVL\n",
    "\t;\n",
    "\t\"\"\")\n",
    "\t#Собираю в таблицу ЦА/КГ\n",
    "\tgp_connector.execute_query(f\"\"\"drop table if exists ba.vt_{mask}_ca_cg;\"\"\")\n",
    "\tgp_connector.execute_query(f\"\"\" --sql\n",
    "\tCreate Table ba.vt_{mask}_ca_cg (\n",
    "\tCONTACT_ID INTEGER,\n",
    "\tFRMT_ID INTEGER,\n",
    "\tREGION_ID INTEGER,\n",
    "\tCUS_TYPE VARCHAR(10),\n",
    "\tIS_CA SMALLINT\n",
    "\t)\n",
    "\tWITH (\n",
    "\t\tappendonly=true,\n",
    "\t\tblocksize=32768,\n",
    "\t\tcompresstype=zstd,\n",
    "\t\tcompresslevel=4,\n",
    "\t\torientation=column);\n",
    "\t\"\"\")\n",
    "\n",
    "\tgp_connector.execute_query(f\"\"\"\n",
    "\tINSERT INTO ba.vt_{mask}_ca_cg\n",
    "\tSELECT DISTINCT\n",
    "\t\tCONTACT_ID\n",
    "\t\t,FRMT_ID\n",
    "\t\t,REGION_ID\n",
    "\t\t,CUS_TYPE\n",
    "\t\t,1 AS IS_CA\n",
    "\tFROM \n",
    "\t\tba.vt_{mask}_ca_lfl_frmt\n",
    "\tUNION \n",
    "\tSELECT DISTINCT\n",
    "\t\tCONTACT_ID\n",
    "\t\t,FRMT_ID\n",
    "\t\t,REGION_ID\n",
    "\t\t,CUS_TYPE\n",
    "\t\t,0 AS IS_CA\n",
    "\tFROM \n",
    "\t\tba.vt_{mask}_kg_lfl_frmt\n",
    "\t;\n",
    "\t\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa032780",
   "metadata": {},
   "source": [
    "## cnt_actn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "1b83e410",
   "metadata": {},
   "outputs": [],
   "source": [
    "@log_function_call\n",
    "def cnt_actn(gp_connector, mask, DateStPre, DateStart, DateEnd, actnId):    \n",
    "    gp_connector.execute_query(f\"\"\"drop table if exists ba.vt_{mask}_cnt_actn;\"\"\")\n",
    "    gp_connector.execute_query(f\"\"\" --sql\n",
    "    CREATE TABLE ba.vt_{mask}_cnt_actn (\n",
    "    CONTACT_ID NUMERIC,\n",
    "    IS_CA smallint,\n",
    "    ACTN_PERIOD smallint,\n",
    "    CNT_ACTN NUMERIC\n",
    "    )  WITH (\n",
    "        appendonly=true,\n",
    "        blocksize=32768,\n",
    "        compresstype=zstd,\n",
    "        compresslevel=4,\n",
    "        orientation=column)\n",
    "    ;\"\"\")\n",
    "\n",
    "\n",
    "    gp_connector.execute_query(f\"\"\" --sql\n",
    "    insert into ba.vt_{mask}_cnt_actn \n",
    "    SELECT \n",
    "        contact_id,\n",
    "        is_ca,\n",
    "        actn_period,\n",
    "        count(distinct actn_grp) as cnt_actn\n",
    "    FROM (\n",
    "    select b.contact_id,\n",
    "        b.actn_name,\n",
    "        b.date_start,\n",
    "        b.date_end,\n",
    "        d.actn_grp,\n",
    "        c.is_ca,\n",
    "        case when (b.date_start between '{DateStPre}' and '{DateStart}'\n",
    "                or b.date_end between '{DateStPre}' and '{DateStart}') then 1\n",
    "            when (b.date_start between '{DateStart}' and '{DateEnd}'\n",
    "                or b.date_end between '{DateStart}' and '{DateEnd}') then 2\n",
    "            else 0\n",
    "        end as actn_period\n",
    "    from BA.T_ZIG_SPR_IDN_ACTN b \n",
    "    join (select distinct contact_id, is_ca from ba.vt_{mask}_ca_cg) c on c.contact_id = b.contact_id\n",
    "    join BA.T_ZIG_SPR_ACTN d on d.actn_name = b.actn_name\n",
    "    where (b.date_start between '{DateStPre}' and '{DateEnd}'\n",
    "        or b.date_end between '{DateStPre}' and '{DateEnd}')\n",
    "        and d.actn_id < {actnId}\n",
    "        --and d.actn_id < 1589\n",
    "        ) d\n",
    "    group by 1,2,3\n",
    "    ;\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67cfc060",
   "metadata": {},
   "source": [
    "## dynamic_gr20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "c7b72a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "@log_function_call\n",
    "def dynamic_gr20(gp_connector, mask, actnId):\n",
    "    month = gp_connector.gp(f\"\"\"\n",
    "           select\n",
    "                month_id\n",
    "                ,min(day_id) as min_dt\n",
    "                ,max(day_id) as max_dt\n",
    "           from\n",
    "                ba.vt_{mask}_days\n",
    "            where\n",
    "                actn_id = {actnId} \n",
    "                and actn_period = 1\n",
    "            group by 1 \n",
    "            order by 1\n",
    "        ;\"\"\")\n",
    "\n",
    "    month\n",
    "\n",
    "    gp_connector.execute_query(f\"\"\"drop table if exists ba.vt_{mask}_cus_gr_0;\"\"\")\n",
    "    gp_connector.execute_query(f\"\"\" --sql\n",
    "    Create Table ba.vt_{mask}_cus_gr_0 (\n",
    "    CONTACT_ID INTEGER,\n",
    "    GR20_ID INTEGER,\n",
    "    FRMT_ID INTEGER,\n",
    "    REGION_ID INTEGER,\n",
    "    CNT_TRN INTEGER,\n",
    "    OPSUM NUMERIC,\n",
    "    QNTY NUMERIC\n",
    "    )\n",
    "    WITH (\n",
    "        appendonly=true,\n",
    "        blocksize=32768,\n",
    "        compresstype=zstd,\n",
    "        compresslevel=4,\n",
    "        orientation=column);\n",
    "    \"\"\")\n",
    "\n",
    "    for i in tqdm_notebook(range(len(month))):\n",
    "        dt_start = str(month.min_dt[i])\n",
    "        dt_end = str(month.max_dt[i])\n",
    "\n",
    "        gp_connector.execute_query(f\"\"\"drop table if exists ba.vt_{mask}_trn_temp;\"\"\")\n",
    "        gp_connector.execute_query(f\"\"\" --sql\n",
    "        CREATE TABLE ba.vt_{mask}_trn_temp  (\n",
    "        contact_id integer,\n",
    "        orgunit_id integer,\n",
    "        frmt_id integer,\n",
    "        region_id integer,\n",
    "        cheque_pk bytea,\n",
    "        article_id integer,\n",
    "        summ_discounted numeric,\n",
    "        quantity numeric\n",
    "        )\n",
    "        WITH (\n",
    "            appendonly=true,\n",
    "            blocksize=32768,\n",
    "            compresstype=zstd,\n",
    "            compresslevel=4,\n",
    "            orientation=column)\n",
    "        ;\"\"\")\n",
    "\n",
    "        gp_connector.execute_query(f\"\"\" --sql\n",
    "        insert into ba.vt_{mask}_trn_temp\n",
    "        with trn as (\n",
    "            select \n",
    "                t.contact_id,\n",
    "                t.orgunit_id,\n",
    "                t.frmt_id,\n",
    "                t.region_id,\n",
    "                t.cheque_pk,\n",
    "                t.summ_discounted\n",
    "            from ba.vt_{mask}_trn_0 t\n",
    "            join ba.vt_{mask}_ca_cg cc \n",
    "                on cc.contact_id = t.contact_id\n",
    "                and cc.frmt_id = t.frmt_id\n",
    "                and cc.region_id = t.region_id\n",
    "            where day_date between ('{dt_start}'::timestamp) AND ('{dt_end}'::timestamp + interval '1' day - interval '1' second)\n",
    "        )\n",
    "        SELECT \n",
    "            t.contact_id,\n",
    "            t.orgunit_id,\n",
    "            t.frmt_id,\n",
    "            t.region_id,\n",
    "            t.cheque_pk,\n",
    "            ci.article_id,\n",
    "            ci.summ_discounted,\n",
    "            ci.quantity\n",
    "        FROM trn t\n",
    "        JOIN dm.cheque_item ci on ci.cheque_pk = t.cheque_pk\n",
    "        WHERE ci.datetime between ('{dt_start}'::timestamp) AND ('{dt_end}'::timestamp + interval '1' day - interval '1' second)\n",
    "        ;\"\"\")\n",
    "\n",
    "        gp_connector.execute_query(f\"\"\" --sql\n",
    "        insert into ba.vt_{mask}_cus_gr_0\n",
    "        SELECT\n",
    "            t.contact_id,\n",
    "            ae.ART_GRP_LVL_0_ID as gr20_id,\n",
    "            t.frmt_id,\n",
    "            t.region_id,\n",
    "            count(DISTINCT t.cheque_pk) AS cnt_trn,\n",
    "            sum(t.summ_discounted) AS opsum,\n",
    "            sum(t.quantity) AS qnty\n",
    "        from ba.vt_{mask}_trn_temp t\n",
    "        JOIN dm.art_ext ae ON ae.article_id = t.article_id\n",
    "        GROUP BY 1,2,3,4\n",
    "        ;\"\"\")\n",
    "\n",
    "    gp_connector.execute_query(f\"\"\"drop table if exists ba.vt_{mask}_cus_gr;\"\"\")\n",
    "    gp_connector.execute_query(f\"\"\" --sql\n",
    "    Create Table ba.vt_{mask}_cus_gr (\n",
    "    CONTACT_ID INTEGER,\n",
    "    GR20_ID INTEGER,\n",
    "    FRMT_ID INTEGER,\n",
    "    REGION_ID INTEGER,\n",
    "    CNT_TRN INTEGER,\n",
    "    OPSUM NUMERIC,\n",
    "    QNTY NUMERIC\n",
    "    )\n",
    "    WITH (\n",
    "        appendonly=true,\n",
    "        blocksize=32768,\n",
    "        compresstype=zstd,\n",
    "        compresslevel=4,\n",
    "        orientation=column);\n",
    "    \"\"\")\n",
    "\n",
    "    gp_connector.execute_query(f\"\"\"\n",
    "    INSERT INTO ba.vt_{mask}_cus_gr\n",
    "    SELECT\n",
    "        CONTACT_ID\n",
    "        ,GR20_ID\n",
    "        ,FRMT_ID\n",
    "        ,REGION_ID\n",
    "        ,sum(cnt_trn) AS cnt_trn\n",
    "        ,sum(opsum) AS opsum\n",
    "        ,sum(qnty) AS qnty\n",
    "    from\n",
    "        ba.vt_{mask}_cus_gr_0\n",
    "    GROUP BY \n",
    "        CONTACT_ID\n",
    "        ,GR20_ID\n",
    "        ,FRMT_ID\n",
    "        ,REGION_ID\n",
    "    ;\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b50dfd",
   "metadata": {},
   "source": [
    "## gr20_transp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "d30f3da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@log_function_call\n",
    "def gr20_transp(gp_connector, mask):\n",
    "\tgp_connector.execute_query(f\"\"\"drop table if exists ba.vt_{mask}_cus_gr_transp;\"\"\")\n",
    "\tgp_connector.execute_query(f\"\"\" --sql\n",
    "\tCreate Table ba.vt_{mask}_cus_gr_transp (\n",
    "\tCONTACT_ID INTEGER,\n",
    "\tFRMT_ID INTEGER,\n",
    "\tREGION_ID INTEGER,\n",
    "\t\"cnt_trn_Бакалея\" NUMERIC,\n",
    "\t\"cnt_trn_Безалкогольные напитки\" NUMERIC,\n",
    "\t\"cnt_trn_Бытовая химия\" NUMERIC,\n",
    "\t\"cnt_trn_Вино\" NUMERIC,\n",
    "\t\"cnt_trn_Детское питание\" NUMERIC,\n",
    "\t\"cnt_trn_Замороженная продукция\" NUMERIC,\n",
    "\t\"cnt_trn_Кондитерские изделия\" NUMERIC,\n",
    "\t\"cnt_trn_Консервированные продукты\" NUMERIC,\n",
    "\t\"cnt_trn_Кофе, какао\" NUMERIC,\n",
    "\t\"cnt_trn_Крепкий алкоголь\" NUMERIC,\n",
    "\t\"cnt_trn_Кулинария\" NUMERIC,\n",
    "\t\"cnt_trn_Молочная продукция\" NUMERIC,\n",
    "\t\"cnt_trn_Мучные кондитерские изделия\" NUMERIC,\n",
    "\t\"cnt_trn_Мясная гастрономия\" NUMERIC,\n",
    "\t\"cnt_trn_Мясо\" NUMERIC,\n",
    "\t\"cnt_trn_Парфюмерия и декоративная косметика\" NUMERIC,\n",
    "\t\"cnt_trn_Продукция для животных\" NUMERIC,\n",
    "\t\"cnt_trn_Промышленные товары\" NUMERIC,\n",
    "\t\"cnt_trn_Птица\" NUMERIC,\n",
    "\t\"cnt_trn_Рыба\" NUMERIC,\n",
    "\t\"cnt_trn_Рыбная гастрономия\" NUMERIC,\n",
    "\t\"cnt_trn_Свежие овощи\" NUMERIC,\n",
    "\t\"cnt_trn_Свежие фрукты\" NUMERIC,\n",
    "\t\"cnt_trn_Слабоалкогольные напитки\" NUMERIC,\n",
    "\t\"cnt_trn_Снэки\" NUMERIC,\n",
    "\t\"cnt_trn_Специальное питание\" NUMERIC,\n",
    "\t\"cnt_trn_Сыры\" NUMERIC,\n",
    "\t\"cnt_trn_Табачные изделия\" NUMERIC,\n",
    "\t\"cnt_trn_Уход и гигиена\" NUMERIC,\n",
    "\t\"cnt_trn_Хлеб и хлебобулочные изделия\" NUMERIC,\n",
    "\t\"cnt_trn_Чай\" NUMERIC,\n",
    "\t\"cnt_trn_Яичные товары\" NUMERIC\n",
    "\t)\n",
    "\tWITH (\n",
    "\t\tappendonly=true,\n",
    "\t\tblocksize=32768,\n",
    "\t\tcompresstype=zstd,\n",
    "\t\tcompresslevel=4,\n",
    "\t\torientation=column)\n",
    "\t;\"\"\")\n",
    "\n",
    "\tgp_connector.execute_query(f\"\"\" --sql\n",
    "\tinsert into ba.vt_{mask}_cus_gr_transp\n",
    "\tSELECT\n",
    "\t\tCONTACT_ID\n",
    "\t\t,FRMT_ID\n",
    "\t\t,REGION_ID\n",
    "\t\t,max(CASE WHEN GR20_ID = 16722\tTHEN CNT_TRN_GR ELSE 0 END) AS \"cnt_trn_Бакалея\"\n",
    "\t\t,max(CASE WHEN GR20_ID = 2135\tTHEN CNT_TRN_GR ELSE 0 END) AS \"cnt_trn_Безалкогольные напитки\"\n",
    "\t\t,max(CASE WHEN GR20_ID = 1262\tTHEN CNT_TRN_GR ELSE 0 END) AS \"cnt_trn_Бытовая химия\"\n",
    "\t\t,max(CASE WHEN GR20_ID = 1173\tTHEN CNT_TRN_GR ELSE 0 END) AS \"cnt_trn_Вино\"\n",
    "\t\t,max(CASE WHEN GR20_ID = 551\tTHEN CNT_TRN_GR ELSE 0 END) AS \"cnt_trn_Детское питание\"\n",
    "\t\t,max(CASE WHEN GR20_ID = 16906\tTHEN CNT_TRN_GR ELSE 0 END) AS \"cnt_trn_Замороженная продукция\"\n",
    "\t\t,max(CASE WHEN GR20_ID = 102\tTHEN CNT_TRN_GR ELSE 0 END) AS \"cnt_trn_Кондитерские изделия\"\n",
    "\t\t,max(CASE WHEN GR20_ID = 16562\tTHEN CNT_TRN_GR ELSE 0 END) AS \"cnt_trn_Консервированные продукты\"\n",
    "\t\t,max(CASE WHEN GR20_ID = 78\t\tTHEN CNT_TRN_GR ELSE 0 END) AS \"cnt_trn_Кофе, какао\"\n",
    "\t\t,max(CASE WHEN GR20_ID = 17034\tTHEN CNT_TRN_GR ELSE 0 END) AS \"cnt_trn_Крепкий алкоголь\"\n",
    "\t\t,max(CASE WHEN GR20_ID = 684\tTHEN CNT_TRN_GR ELSE 0 END) AS \"cnt_trn_Кулинария\"\n",
    "\t\t,max(CASE WHEN GR20_ID = 16352\tTHEN CNT_TRN_GR ELSE 0 END) AS \"cnt_trn_Молочная продукция\"\n",
    "\t\t,max(CASE WHEN GR20_ID = 17079\tTHEN CNT_TRN_GR ELSE 0 END) AS \"cnt_trn_Мучные кондитерские изделия\"\n",
    "\t\t,max(CASE WHEN GR20_ID = 16315\tTHEN CNT_TRN_GR ELSE 0 END) AS \"cnt_trn_Мясная гастрономия\"\n",
    "\t\t,max(CASE WHEN GR20_ID = 16332\tTHEN CNT_TRN_GR ELSE 0 END) AS \"cnt_trn_Мясо\"\n",
    "\t\t,max(CASE WHEN GR20_ID = 1181\tTHEN CNT_TRN_GR ELSE 0 END) AS \"cnt_trn_Парфюмерия и декоративная косметика\"\n",
    "\t\t,max(CASE WHEN GR20_ID = 1155\tTHEN CNT_TRN_GR ELSE 0 END) AS \"cnt_trn_Продукция для животных\"\n",
    "\t\t,max(CASE WHEN GR20_ID = 1869\tTHEN CNT_TRN_GR ELSE 0 END) AS \"cnt_trn_Промышленные товары\"\n",
    "\t\t,max(CASE WHEN GR20_ID = 16322\tTHEN CNT_TRN_GR ELSE 0 END) AS \"cnt_trn_Птица\"\n",
    "\t\t,max(CASE WHEN GR20_ID = 16342\tTHEN CNT_TRN_GR ELSE 0 END) AS \"cnt_trn_Рыба\"\n",
    "\t\t,max(CASE WHEN GR20_ID = 16752\tTHEN CNT_TRN_GR ELSE 0 END) AS \"cnt_trn_Рыбная гастрономия\"\n",
    "\t\t,max(CASE WHEN GR20_ID = 16864\tTHEN CNT_TRN_GR ELSE 0 END) AS \"cnt_trn_Свежие овощи\"\n",
    "\t\t,max(CASE WHEN GR20_ID = 17241\tTHEN CNT_TRN_GR ELSE 0 END) AS \"cnt_trn_Свежие фрукты\"\n",
    "\t\t,max(CASE WHEN GR20_ID = 323\tTHEN CNT_TRN_GR ELSE 0 END) AS \"cnt_trn_Слабоалкогольные напитки\"\n",
    "\t\t,max(CASE WHEN GR20_ID = 1128\tTHEN CNT_TRN_GR ELSE 0 END) AS \"cnt_trn_Снэки\"\n",
    "\t\t,max(CASE WHEN GR20_ID = 1327\tTHEN CNT_TRN_GR ELSE 0 END) AS \"cnt_trn_Специальное питание\"\n",
    "\t\t,max(CASE WHEN GR20_ID = 16343\tTHEN CNT_TRN_GR ELSE 0 END) AS \"cnt_trn_Сыры\"\n",
    "\t\t,max(CASE WHEN GR20_ID = 367\tTHEN CNT_TRN_GR ELSE 0 END) AS \"cnt_trn_Табачные изделия\"\n",
    "\t\t,max(CASE WHEN GR20_ID = 252\tTHEN CNT_TRN_GR ELSE 0 END) AS \"cnt_trn_Уход и гигиена\"\n",
    "\t\t,max(CASE WHEN GR20_ID = 679\tTHEN CNT_TRN_GR ELSE 0 END) AS \"cnt_trn_Хлеб и хлебобулочные изделия\"\n",
    "\t\t,max(CASE WHEN GR20_ID = 415\tTHEN CNT_TRN_GR ELSE 0 END) AS \"cnt_trn_Чай\"\n",
    "\t\t,max(CASE WHEN GR20_ID = 222\tTHEN CNT_TRN_GR ELSE 0 END) AS \"cnt_trn_Яичные товары\"                  \n",
    "\tFROM ( \n",
    "\t\tSELECT\n",
    "\t\t\tcg.CONTACT_ID\n",
    "\t\t\t,cg.GR20_ID\n",
    "\t\t\t,cg.FRMT_ID\n",
    "\t\t\t,cg.REGION_ID\n",
    "\t\t\t--,cg.OPSUM / co.CNT_TRN as AVG_SPEND_GR\n",
    "\t\t\t,cg.CNT_TRN as CNT_TRN_GR\n",
    "\t\tFROM\n",
    "\t\t\tba.vt_{mask}_cus_gr cg\n",
    "\t\tJOIN\n",
    "\t\t\tba.vt_{mask}_cus_reg co \n",
    "\t\t\ton co.CONTACT_ID = cg.CONTACT_ID\n",
    "\t\t\tand co.FRMT_ID = cg.FRMT_ID\n",
    "\t\t\tand co.REGION_ID = cg.REGION_ID\n",
    "\t\t\tand co.ACTN_PERIOD = 1\n",
    "\t\t) d\n",
    "\tGROUP BY\n",
    "\t\tCONTACT_ID\n",
    "\t\t,FRMT_ID\n",
    "\t\t,REGION_ID\n",
    "\t;\n",
    "\t\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c880466",
   "metadata": {},
   "source": [
    "## age_and_active_virt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "41e11086",
   "metadata": {},
   "outputs": [],
   "source": [
    "@log_function_call\n",
    "def age_and_active_virt(gp_connector, mask):\n",
    "    gp_connector.execute_query(f\"\"\"drop table if exists ba.vt_{mask}_cus_gender;\"\"\")\n",
    "    gp_connector.execute_query(f\"\"\" --sql\n",
    "    Create Table ba.vt_{mask}_cus_gender (\n",
    "    CONTACT_ID INTEGER,\n",
    "    GENDER_CODE smallint,\n",
    "    AGE_CALC INTEGER\n",
    "    )\n",
    "    WITH (\n",
    "        appendonly=true,\n",
    "        blocksize=32768,\n",
    "        compresstype=zstd,\n",
    "        compresslevel=4,\n",
    "        orientation=column)\n",
    "    ;\"\"\")\n",
    "\n",
    "    gp_connector.execute_query(f\"\"\"\n",
    "    INSERT INTO ba.vt_{mask}_cus_gender\n",
    "    SELECT\n",
    "        c.CONTACT_ID\n",
    "        ,case when gendercalc = 'F' then 1\n",
    "            when gendercalc = 'M' then 2\n",
    "            else 0\n",
    "        end as GENDER_CODE\n",
    "        ,(current_date - date(birth_date))/364 AS AGE_CALC\n",
    "    FROM \n",
    "        dm.contact c\n",
    "    JOIN\n",
    "        (select distinct CONTACT_ID from ba.vt_{mask}_ca_cg) cg on cg.CONTACT_ID = c.CONTACT_ID\n",
    "    ;\"\"\")\n",
    "    ### Активный пользователь вирт.карты\n",
    "    #Выделяю клиентов с виртуальной картой\n",
    "    gp_connector.execute_query(f\"\"\"drop table if exists ba.vt_{mask}_cus_virt;\"\"\")\n",
    "    gp_connector.execute_query(f\"\"\" --sql\n",
    "    Create TABLE ba.vt_{mask}_cus_virt (\n",
    "    CONTACT_ID INTEGER\n",
    "    )\n",
    "    WITH (\n",
    "        appendonly=true,\n",
    "        blocksize=32768,\n",
    "        compresstype=zstd,\n",
    "        compresslevel=4,\n",
    "        orientation=column)\n",
    "    ;\"\"\")\n",
    "\n",
    "    # CA\n",
    "    gp_connector.execute_query(f\"\"\"\n",
    "    INSERT INTO ba.vt_{mask}_cus_virt\n",
    "    WITH trn AS (\n",
    "    SELECT distinct\n",
    "        contact_id\n",
    "        ,card_number\n",
    "    FROM\n",
    "        ba.vt_{mask}_trn_0\n",
    "    WHERE\n",
    "        actn_period = 1\n",
    "    )\n",
    "\n",
    "    SELECT DISTINCT\n",
    "        t.CONTACT_ID\n",
    "    FROM\n",
    "        trn t\n",
    "    JOIN\n",
    "        (select distinct CONTACT_ID from ba.vt_{mask}_ca_cg) cg on cg.CONTACT_ID = T.CONTACT_ID\n",
    "    JOIN\n",
    "        dm.card cc ON cc.card_number = t.card_number\n",
    "    WHERE\n",
    "        cc.card_type_id in (1, 90) -- VIRTUAL_01, VIRTUAL_02\n",
    "    ;\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f71d52",
   "metadata": {},
   "source": [
    "## itog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "b3ec8123",
   "metadata": {},
   "outputs": [],
   "source": [
    "@log_function_call\n",
    "def itog(gp_connector, mask, lengthActn):\n",
    "    gp_connector.execute_query(f\"\"\"drop table if exists ba.vt_{mask}_cus_profile;\"\"\")\n",
    "    gp_connector.execute_query(f\"\"\" --sql\n",
    "    Create Table ba.vt_{mask}_cus_profile (\n",
    "    CONTACT_ID INTEGER,\n",
    "    FRMT_ID INTEGER,\n",
    "    REGION_ID INTEGER,\n",
    "    IS_CA SMALLINT,\n",
    "    IS_VIRT SMALLINT,\n",
    "    GENDER SMALLINT,\n",
    "    AGE INTEGER,\n",
    "    LONG_VISIT INTEGER,\n",
    "    SQUARE_TRADE NUMERIC,\n",
    "    SPEND_PREV float,\n",
    "    SPEND_ACTN float,\n",
    "    AVG_TXN_PREV float,\n",
    "    AVG_TXN_ACTN float,\n",
    "    CNT_TRN_PREV float,\n",
    "    CNT_TRN_ACTN float,\n",
    "    CNT_DAY_PREV float,\n",
    "    OPSUM_ACTN float,\n",
    "    CNT_TRN_FLTR_ACTN float,\n",
    "    AVG_TXN_FLTR_ACTN float,\n",
    "    CNT_WEEK_PREV float,\n",
    "    CNT_WEEK_ACTN float,\n",
    "    CNT_ACTN_PREV INTEGER,\n",
    "    CNT_ACTN_ACTN INTEGER,\n",
    "    \"cnt_trn_Бакалея\" NUMERIC,\n",
    "    \"cnt_trn_Безалкогольные напитки\" NUMERIC,\n",
    "    \"cnt_trn_Бытовая химия\" NUMERIC,\n",
    "    \"cnt_trn_Вино\" NUMERIC,\n",
    "    \"cnt_trn_Детское питание\" NUMERIC,\n",
    "    \"cnt_trn_Замороженная продукция\" NUMERIC,\n",
    "    \"cnt_trn_Кондитерские изделия\" NUMERIC,\n",
    "    \"cnt_trn_Консервированные продукты\" NUMERIC,\n",
    "    \"cnt_trn_Кофе, какао\" NUMERIC,\n",
    "    \"cnt_trn_Крепкий алкоголь\" NUMERIC,\n",
    "    \"cnt_trn_Кулинария\" NUMERIC,\n",
    "    \"cnt_trn_Молочная продукция\" NUMERIC,\n",
    "    \"cnt_trn_Мучные кондитерские изделия\" NUMERIC,\n",
    "    \"cnt_trn_Мясная гастрономия\" NUMERIC,\n",
    "    \"cnt_trn_Мясо\" NUMERIC,\n",
    "    \"cnt_trn_Парфюмерия и декоративная косметика\" NUMERIC,\n",
    "    \"cnt_trn_Продукция для животных\" NUMERIC,\n",
    "    \"cnt_trn_Промышленные товары\" NUMERIC,\n",
    "    \"cnt_trn_Птица\" NUMERIC,\n",
    "    \"cnt_trn_Рыба\" NUMERIC,\n",
    "    \"cnt_trn_Рыбная гастрономия\" NUMERIC,\n",
    "    \"cnt_trn_Свежие овощи\" NUMERIC,\n",
    "    \"cnt_trn_Свежие фрукты\" NUMERIC,\n",
    "    \"cnt_trn_Слабоалкогольные напитки\" NUMERIC,\n",
    "    \"cnt_trn_Снэки\" NUMERIC,\n",
    "    \"cnt_trn_Специальное питание\" NUMERIC,\n",
    "    \"cnt_trn_Сыры\" NUMERIC,\n",
    "    \"cnt_trn_Табачные изделия\" NUMERIC,\n",
    "    \"cnt_trn_Уход и гигиена\" NUMERIC,\n",
    "    \"cnt_trn_Хлеб и хлебобулочные изделия\" NUMERIC,\n",
    "    \"cnt_trn_Чай\" NUMERIC,\n",
    "    \"cnt_trn_Яичные товары\" NUMERIC\n",
    "    )\n",
    "    WITH (\n",
    "        appendonly=true,\n",
    "        blocksize=32768,\n",
    "        compresstype=zstd,\n",
    "        compresslevel=4,\n",
    "        orientation=column);\n",
    "    \"\"\")\n",
    "\n",
    "    gp_connector.execute_query(f\"\"\"\n",
    "    INSERT INTO ba.vt_{mask}_cus_profile\n",
    "    WITH opsum_agg AS ( \n",
    "        select\n",
    "            t.CONTACT_ID\n",
    "            ,t.FRMT_ID\n",
    "            ,t.REGION_ID\n",
    "            ,c.IS_CA\n",
    "            ,t.ACTN_PERIOD\n",
    "            ,coalesce(t.AVG_SPEND, 0) as AVG_SPEND\n",
    "            ,t.AVG_TXN\n",
    "            ,t.CNT_TRN\n",
    "            ,t.LONG_VISIT\n",
    "            ,t.SQUARE_TRADE\n",
    "            ,case when cv.CONTACT_ID is not null then 1 else 0 end as IS_VIRT\n",
    "            ,t.CNT_DAY\n",
    "            ,t.OPSUM\n",
    "            ,coalesce(t.CNT_TRN_FLTR, 0) as CNT_TRN_FLTR\n",
    "            ,coalesce(t.AVG_TXN_FLTR, 0) as AVG_TXN_FLTR\n",
    "            ,coalesce(t.CNT_WEEK, 0)  as CNT_WEEK\n",
    "            ,coalesce(ca.CNT_ACTN, 0) as CNT_ACTN\n",
    "        from\n",
    "            ba.vt_{mask}_cus_reg t\n",
    "        JOIN\n",
    "            ba.vt_{mask}_ca_cg c \n",
    "            on c.CONTACT_ID = t.CONTACT_ID\n",
    "            and c.FRMT_ID = t.FRMT_ID\n",
    "            and c.REGION_ID = t.REGION_ID\n",
    "            and c.IS_CA = t.IS_CA\n",
    "        left JOIN\n",
    "            ba.vt_{mask}_cus_virt cv on cv.CONTACT_ID = t.CONTACT_ID\n",
    "        left join\n",
    "            ba.vt_{mask}_cnt_actn ca \n",
    "            on ca.contact_id = t.contact_id\n",
    "            and ca.is_ca = t.is_ca\n",
    "            and ca.actn_period = t.actn_period\n",
    "    ), opsum_agg_transp AS (\n",
    "        select\n",
    "            CONTACT_ID\n",
    "            ,FRMT_ID\n",
    "            ,REGION_ID\n",
    "            ,IS_CA\n",
    "            ,IS_VIRT\n",
    "            ,sum(case when ACTN_PERIOD = 1 then AVG_SPEND else 0 end) as SPEND_PREV\n",
    "            ,sum(case when ACTN_PERIOD = 2 then AVG_SPEND else 0 end) as SPEND_ACTN\n",
    "            ,max(case when ACTN_PERIOD = 1 then AVG_TXN end) as AVG_TXN_PREV\n",
    "            ,max(case when ACTN_PERIOD = 2 then AVG_TXN end) as AVG_TXN_ACTN\n",
    "            ,sum(case when ACTN_PERIOD = 1 then CNT_TRN end) as CNT_TRN_PREV\n",
    "            ,sum(case when ACTN_PERIOD = 2 then CNT_TRN end) as CNT_TRN_ACTN\n",
    "            ,max(case when ACTN_PERIOD = 1 then LONG_VISIT end) as LONG_VISIT\n",
    "            ,max(case when ACTN_PERIOD = 1 then SQUARE_TRADE end) as SQUARE_TRADE\n",
    "            ,max(case when ACTN_PERIOD = 1 then CNT_DAY end) as CNT_DAY_PREV\n",
    "            ,max(case when ACTN_PERIOD = 2 then OPSUM / {lengthActn} end) as OPSUM_ACTN\n",
    "            ,max(case when ACTN_PERIOD = 2 then CNT_TRN_FLTR else 0 end) as CNT_TRN_FLTR_ACTN\n",
    "            ,max(case when ACTN_PERIOD = 2 then AVG_TXN_FLTR else 0 end) as AVG_TXN_FLTR_ACTN\n",
    "            ,max(case when ACTN_PERIOD = 1 then CNT_WEEK else 0 end) as CNT_WEEK_PREV\n",
    "            ,max(case when ACTN_PERIOD = 2 then CNT_WEEK else 0 end) as CNT_WEEK_ACTN\n",
    "            ,max(case when ACTN_PERIOD = 1 then CNT_ACTN else 0 end) as CNT_ACTN_PREV\n",
    "            ,max(case when ACTN_PERIOD = 2 then CNT_ACTN else 0 end) as CNT_ACTN_ACTN\n",
    "        from\n",
    "            opsum_agg\n",
    "        group by\n",
    "            CONTACT_ID\n",
    "            ,FRMT_ID\n",
    "            ,REGION_ID\n",
    "            ,IS_CA\n",
    "            ,IS_VIRT\n",
    "    )\n",
    "\n",
    "    SELECT distinct\n",
    "        t.CONTACT_ID\n",
    "        ,t.FRMT_ID\n",
    "        ,t.REGION_ID\n",
    "        ,t.IS_CA\n",
    "        ,t.IS_VIRT\n",
    "        ,cg.GENDER_CODE\n",
    "        ,cg.AGE_CALC\n",
    "        ,t.LONG_VISIT\n",
    "        ,t.SQUARE_TRADE\n",
    "        ,t.SPEND_PREV\n",
    "        ,t.SPEND_ACTN\n",
    "        ,t.AVG_TXN_PREV\n",
    "        ,t.AVG_TXN_ACTN\n",
    "        ,t.CNT_TRN_PREV\n",
    "        ,t.CNT_TRN_ACTN\n",
    "        ,t.CNT_DAY_PREV\n",
    "        ,t.OPSUM_ACTN\n",
    "        ,t.CNT_TRN_FLTR_ACTN\n",
    "        ,t.AVG_TXN_FLTR_ACTN\n",
    "        ,t.CNT_WEEK_PREV\n",
    "        ,t.CNT_WEEK_ACTN\n",
    "        ,t.CNT_ACTN_PREV\n",
    "        ,t.CNT_ACTN_ACTN\n",
    "        ,\"cnt_trn_Бакалея\"\n",
    "        ,\"cnt_trn_Безалкогольные напитки\"\n",
    "        ,\"cnt_trn_Бытовая химия\"\n",
    "        ,\"cnt_trn_Вино\"\n",
    "        ,\"cnt_trn_Детское питание\"\n",
    "        ,\"cnt_trn_Замороженная продукция\"\n",
    "        ,\"cnt_trn_Кондитерские изделия\"\n",
    "        ,\"cnt_trn_Консервированные продукты\"\n",
    "        ,\"cnt_trn_Кофе, какао\"\n",
    "        ,\"cnt_trn_Крепкий алкоголь\"\n",
    "        ,\"cnt_trn_Кулинария\"\n",
    "        ,\"cnt_trn_Молочная продукция\"\n",
    "        ,\"cnt_trn_Мучные кондитерские изделия\"\n",
    "        ,\"cnt_trn_Мясная гастрономия\"\n",
    "        ,\"cnt_trn_Мясо\"\n",
    "        ,\"cnt_trn_Парфюмерия и декоративная косметика\"\n",
    "        ,\"cnt_trn_Продукция для животных\"\n",
    "        ,\"cnt_trn_Промышленные товары\"\n",
    "        ,\"cnt_trn_Птица\"\n",
    "        ,\"cnt_trn_Рыба\"\n",
    "        ,\"cnt_trn_Рыбная гастрономия\"\n",
    "        ,\"cnt_trn_Свежие овощи\"\n",
    "        ,\"cnt_trn_Свежие фрукты\"\n",
    "        ,\"cnt_trn_Слабоалкогольные напитки\"\n",
    "        ,\"cnt_trn_Снэки\"\n",
    "        ,\"cnt_trn_Специальное питание\"\n",
    "        ,\"cnt_trn_Сыры\"\n",
    "        ,\"cnt_trn_Табачные изделия\"\n",
    "        ,\"cnt_trn_Уход и гигиена\"\n",
    "        ,\"cnt_trn_Хлеб и хлебобулочные изделия\"\n",
    "        ,\"cnt_trn_Чай\"\n",
    "        ,\"cnt_trn_Яичные товары\"\n",
    "    FROM\n",
    "        opsum_agg_transp t\n",
    "    JOIN\n",
    "        ba.vt_{mask}_cus_gender cg on cg.CONTACT_ID = t.CONTACT_ID\n",
    "    left JOIN\n",
    "        ba.vt_{mask}_cus_gr_transp cgt \n",
    "        on cgt.CONTACT_ID = t.CONTACT_ID\n",
    "        and cgt.FRMT_ID = t.FRMT_ID\n",
    "        and cgt.REGION_ID = t.REGION_ID\n",
    "    ;\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4fc4416",
   "metadata": {},
   "source": [
    "## psm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "9148bc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "@log_function_call\n",
    "def psm(gp_connector, mask, actn_name, actnId):\n",
    "    import numpy as np\n",
    "    #ЗАПОЛНИТЬ!\n",
    "    mde_ratio = 10.0 / 100.0 #10% минимальный детектируемый эффект прироста трат\n",
    "    # Оптимизированная функция\n",
    "    def perform_matching(indexes: np.ndarray,\n",
    "                        is_ca_array: np.ndarray,\n",
    "                        frmt_id_array: np.ndarray,\n",
    "                        region_id_array: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Batch-функция для мэтчинга KNN.\n",
    "        Перебирает все индексы, где is_ca == 1, для каждого такого индекса ищет\n",
    "        первого подходящего кандидата (is_ca == 0) из его ближайших соседей, который:\n",
    "        1) Не совпадает с самим индексом.\n",
    "        2) Имеет тот же frmt_id.\n",
    "        3) Имеет тот же region_id.\n",
    "        4) Ещё не использован (уникальный).\n",
    "        Параметры:\n",
    "        ----------\n",
    "        indexes : np.ndarray\n",
    "            Результат вызова knn.kneighbors(...)[1], массив индексов ближайших соседей.\n",
    "            Размерность: (n_samples, n_neighbors).\n",
    "        is_ca_array : np.ndarray\n",
    "            Массив признака is_ca (0/1) для каждой строки.\n",
    "        frmt_id_array : np.ndarray\n",
    "            Массив, в котором хранится frmt_id для каждой строки.\n",
    "        region_id_array : np.ndarray\n",
    "            Массив, в котором хранится region_id для каждой строки.\n",
    "\n",
    "        Возвращает:\n",
    "        ----------\n",
    "        np.ndarray\n",
    "            Массив matched_element длиной n_samples, где:\n",
    "            - matched_element[i] = индекс подобранного «не ЦА» для строки i,\n",
    "            - matched_element[i] = np.nan, если подходящий кандидат не найден.\n",
    "        \"\"\"\n",
    "\n",
    "        n = len(is_ca_array)\n",
    "        # Сюда запишем итоговый индекс «пары» для каждой строки (или np.nan, если нет)\n",
    "        matched_element = np.full(n, np.nan, dtype=np.float32)\n",
    "\n",
    "        # Булевый массив для учёта уже использованных кандидатов:\n",
    "        used_kg_mask = np.zeros(n, dtype=bool)\n",
    "\n",
    "        # Определяем индексы, где is_ca == 1 (лечебная группа)\n",
    "        treated_indices = np.where(is_ca_array == 1)[0]\n",
    "\n",
    "        for current_index in treated_indices:\n",
    "            # Ближайшие соседи для текущего индекса\n",
    "            candidates = indexes[current_index, :]\n",
    "\n",
    "            # Маска: не сам себя\n",
    "            mask_not_self = (candidates != current_index)\n",
    "            # Маска: кандидат из контрольной группы (is_ca == 0)\n",
    "            mask_ca = (is_ca_array[candidates] == 0)\n",
    "            # Маска: тот же формат\n",
    "            mask_frmt = (frmt_id_array[candidates] == frmt_id_array[current_index])\n",
    "            # Маска: тот же регион\n",
    "            mask_region = (region_id_array[candidates] == region_id_array[current_index])\n",
    "            # Маска: ещё не использован (unique pair)\n",
    "            mask_unused = ~used_kg_mask[candidates]\n",
    "\n",
    "            valid_mask = mask_not_self & mask_ca & mask_frmt & mask_region & mask_unused\n",
    "            valid_indices = np.where(valid_mask)[0]\n",
    "\n",
    "            if len(valid_indices) > 0:\n",
    "                # Берём первого подходящего кандидата\n",
    "                chosen_idx = candidates[valid_indices[0]]\n",
    "                matched_element[current_index] = chosen_idx\n",
    "                # Отмечаем, что chosen_idx теперь нельзя использовать повторно\n",
    "                used_kg_mask[chosen_idx] = True\n",
    "\n",
    "        return matched_element\n",
    "\n",
    "    def perfom_matching_v1(row, indexes, df):\n",
    "        current_index = int(row['level_0']) # Obtain value from index-named column, not the actual DF index.\n",
    "        for idx in indexes[current_index,:]:\n",
    "            if (current_index != idx) and (row.is_ca == 1) and (df.loc[idx].is_ca == 0) and\\\n",
    "            (row.frmt_id == df.loc[idx].frmt_id) and (row.region_id == df.loc[idx].region_id):\n",
    "                return int(idx)\n",
    "            \n",
    "    def perfom_matching_v2(row, indexes, df, kg_lst):\n",
    "        current_index = int(row['level_0']) # Obtain value from index-named column, not the actual DF index.\n",
    "        for idx in indexes[current_index,:]:\n",
    "            if (current_index != idx) and (row.is_ca == 1) and (df.loc[idx].is_ca == 0) and (idx not in kg_lst) and\\\n",
    "            (row.frmt_id == df.loc[idx].frmt_id) and (row.region_id == df.loc[idx].region_id):\n",
    "                kg_lst.append(idx)\n",
    "                return int(idx)\n",
    "\n",
    "    def min_sample_size_avg(std, mean_diff, power = 0.8, sig_level = 0.05, alternative = \"two-sided\", control_ratio = 0.5):\n",
    "        if alternative == \"one-sided\":\n",
    "            alternative = \"larger\"\n",
    "        power_analysis  = TTestIndPower()\n",
    "        d = mean_diff / std \n",
    "        ratio = (1 - control_ratio) / control_ratio\n",
    "        sample_size = power_analysis.solve_power(\n",
    "            effect_size=d,\n",
    "            nobs1=None,\n",
    "            alpha=sig_level,\n",
    "            power=power,\n",
    "            ratio=ratio,\n",
    "            alternative=alternative)\n",
    "        sample_power = power_analysis.power(\n",
    "            effect_size=d,\n",
    "            nobs1=sample_size,\n",
    "            alpha=sig_level,\n",
    "            ratio=ratio)\n",
    "        return int(sample_size), float(sample_power) # nobs1 = размер контрольной группы\n",
    "\n",
    "    def absolute_ttest(control, test):\n",
    "        mean_control = np.mean(control)\n",
    "        mean_test = np.mean(test)\n",
    "        var_mean_control  = np.var(control) / len(control)\n",
    "        var_mean_test  = np.var(test) / len(test)\n",
    "        \n",
    "        difference_mean = mean_test - mean_control\n",
    "        difference_mean_var = var_mean_control + var_mean_test\n",
    "        difference_distribution = sps.norm(loc=difference_mean, scale=np.sqrt(difference_mean_var))\n",
    "\n",
    "        left_bound, right_bound = difference_distribution.ppf([0.025, 0.975])\n",
    "        ci_length = (right_bound - left_bound)\n",
    "        pvalue = 2 * min(difference_distribution.cdf(0), difference_distribution.sf(0))\n",
    "        effect = difference_mean\n",
    "        return ExperimentComparisonResults(round(pvalue, 4), round(effect, 4), round(ci_length, 4), round(left_bound, 4), round(right_bound, 4))\n",
    "\n",
    "\n",
    "    def cuped_ttest(control, test, control_before, test_before):\n",
    "        theta = (np.cov(control, control_before)[0, 1] + np.cov(test, test_before)[0, 1]) /\\\n",
    "                    (np.var(control_before) + np.var(test_before))\n",
    "        control_cup = control - theta * control_before\n",
    "        test_cup = test - theta * test_before\n",
    "        return absolute_ttest(control_cup, test_cup)\n",
    "    \n",
    "    query = f\"\"\"select distinct FRMT_ID, REGION_ID from ba.vt_{mask}_cus_profile order by FRMT_ID desc;\"\"\"\n",
    "    frmt_region = gp_connector.gp(query)\n",
    "\n",
    "    #Использование новой функции с заранее выделенными массивами\n",
    "    frmt = frmt_region.frmt_id.unique().tolist()\n",
    "    region = frmt_region.region_id.unique().tolist()\n",
    "    # frmt = [1]\n",
    "    # region = [227]\n",
    "\n",
    "    #Сразу создадим списки, куда будем складывать результаты\n",
    "    cus_lfl_list = []\n",
    "    stat_test_list = []\n",
    "\n",
    "    print('Доля мэтчинга ЛФЛ ЦА/КГ:')\n",
    "\n",
    "    batch_size = 100000\n",
    "\n",
    "    for f in range(len(frmt)):\n",
    "        for r in range(len(region)):\n",
    "            gc.collect()\n",
    "\n",
    "            data_chunks = []\n",
    "            offset = 0\n",
    "                \n",
    "            print(f\"\\nЗагрузка данных frmt_id={frmt[f]}, region_id={region[r]} батчами...\")\n",
    "\n",
    "            # Загрузка батчами\n",
    "            while True:\n",
    "                query = f\"\"\"\n",
    "                    SELECT * FROM ba.vt_{mask}_cus_profile \n",
    "                    WHERE frmt_id = '{frmt[f]}' AND region_id = '{region[r]}'\n",
    "                    LIMIT {batch_size} OFFSET {offset}\n",
    "                \"\"\"\n",
    "                batch_df = gp_connector.gp(query)\n",
    "\n",
    "                if batch_df.empty:\n",
    "                    break\n",
    "\n",
    "                batch_df = gp_connector.reduce_mem_usage(batch_df, verbose=False)\n",
    "                data_chunks.append(batch_df)\n",
    "                offset += batch_size\n",
    "\n",
    "                print(f\"Загружено всего строк: {offset}, в текущем батче: {len(batch_df)}\")\n",
    "\n",
    "            if not data_chunks:\n",
    "                print(f\"Нет данных для frmt_id={frmt[f]}, region_id={region[r]}. Пропускаем.\")\n",
    "                continue\n",
    "\n",
    "            # Объединяем все батчи в один DataFrame\n",
    "            df = pd.concat(data_chunks, ignore_index=True)\n",
    "            data_chunks = []  # Освобождаем память\n",
    "            gc.collect()     \n",
    "\n",
    "            # Заполняю пропуски средним\n",
    "            # cols = df.iloc[:, 6:].columns\n",
    "            # df[cols] = df[cols].fillna(df[cols].mean())\n",
    "\n",
    "            df = df.dropna().reset_index(drop=True)\n",
    "            df_len = df.groupby('is_ca')['contact_id'].count()\n",
    "        \n",
    "            #Модель\n",
    "            if len(df_len) > 1 and df_len.values[0] > 1 and df_len.values[1] > 1:\n",
    "                df['treatment'] = df['is_ca'] == 1\n",
    "                df['is_female'] = df['gender'] == 1\n",
    "\n",
    "                TREATMENT = 'treatment'\n",
    "                OUTCOME = 'opsum_actn'\n",
    "\n",
    "                cols = ['is_female', 'age', 'is_virt', 'long_visit', 'square_trade',\n",
    "                'spend_prev', 'avg_txn_prev', 'cnt_trn_prev',\n",
    "                'cnt_week_prev', 'cnt_week_actn', 'cnt_day_prev', 'cnt_actn_prev', 'cnt_actn_actn',\n",
    "                'cnt_trn_Бакалея', 'cnt_trn_Безалкогольные напитки', 'cnt_trn_Бытовая химия',\n",
    "                'cnt_trn_Вино', 'cnt_trn_Детское питание',\n",
    "                'cnt_trn_Замороженная продукция', 'cnt_trn_Кондитерские изделия',\n",
    "                'cnt_trn_Консервированные продукты', 'cnt_trn_Кофе, какао',\n",
    "                'cnt_trn_Крепкий алкоголь', 'cnt_trn_Кулинария',\n",
    "                'cnt_trn_Молочная продукция', 'cnt_trn_Мучные кондитерские изделия',\n",
    "                'cnt_trn_Мясная гастрономия', 'cnt_trn_Мясо',\n",
    "                'cnt_trn_Парфюмерия и декоративная кос',\n",
    "                'cnt_trn_Продукция для животных', 'cnt_trn_Промышленные товары',\n",
    "                'cnt_trn_Птица', 'cnt_trn_Рыба', 'cnt_trn_Рыбная гастрономия',\n",
    "                'cnt_trn_Свежие овощи', 'cnt_trn_Свежие фрукты',\n",
    "                'cnt_trn_Слабоалкогольные напитки', 'cnt_trn_Снэки',\n",
    "                'cnt_trn_Специальное питание', 'cnt_trn_Сыры',\n",
    "                'cnt_trn_Табачные изделия', 'cnt_trn_Уход и гигиена',\n",
    "                'cnt_trn_Хлеб и хлебобулочные изделия', 'cnt_trn_Чай',\n",
    "                'cnt_trn_Яичные товары']\n",
    "\n",
    "                # Estimate propensity scores \n",
    "                # Build a descriptive model\n",
    "                t = df[TREATMENT]\n",
    "                X = df[cols]\n",
    "                pipe = Pipeline([\n",
    "                    # ('minmax', MinMaxScaler()),\n",
    "                    ('scaler', StandardScaler()),\n",
    "                    ('logistic_classifier', LogisticRegression(random_state=789, class_weight='balanced'))\n",
    "                ])\n",
    "                pipe.fit(X, t)\n",
    "\n",
    "                threshold = 0.5\n",
    "                df['proba'] = pipe.predict_proba(X)[:,1]\n",
    "                ind = df[df.proba == 1].index\n",
    "                df.loc[ind, 'proba'] = 0.9999\n",
    "                df['logit'] = df['proba'].apply(lambda p: np.log(p/(1-p)))\n",
    "                df['pred'] = np.where(df['proba']>=threshold, 1, 0)\n",
    "\n",
    "                # Масштабирование признаков\n",
    "                X_scale = pd.DataFrame(pipe['scaler'].transform(X), columns=pipe['scaler'].get_feature_names_out())\n",
    "                X_scale['logit'] = df['logit'].copy()\n",
    "\n",
    "                #Мэтчинг KNN\n",
    "                caliper = np.std(df.logit) * 0.25\n",
    "                knn = NearestNeighbors(n_neighbors=5, p = 2, radius=caliper)\n",
    "                knn.fit(X_scale[['logit', 'spend_prev', 'avg_txn_prev', 'cnt_trn_prev']].to_numpy())\n",
    "\n",
    "                # Common support distances and indexes\n",
    "                distances , indexes = knn.kneighbors(X_scale[['logit', 'spend_prev', 'avg_txn_prev', 'cnt_trn_prev']].to_numpy(), n_neighbors=5)\n",
    "\n",
    "                treated_x = df[df[TREATMENT]][['logit']].values\n",
    "                non_treated_x = df[~df[TREATMENT]][['logit']].values\n",
    "\n",
    "                # Выносим массивы\n",
    "                is_ca_array = df['is_ca'].values\n",
    "                frmt_id_array = df['frmt_id'].values\n",
    "                region_id_array = df['region_id'].values\n",
    "\n",
    "                # Применяем batch-функцию мэтчинга\n",
    "                matched_element_array = perform_matching(\n",
    "                    indexes, is_ca_array, frmt_id_array, region_id_array\n",
    "                )\n",
    "                df['matched_element'] = matched_element_array\n",
    "\n",
    "                treated_with_match = ~pd.isna(df['matched_element'])\n",
    "                treated_matched_data = df.loc[treated_with_match, [\n",
    "                    'contact_id','frmt_id','region_id','is_ca',\n",
    "                    'spend_prev','spend_actn', 'opsum_actn','logit','matched_element'\n",
    "                ]].copy()\n",
    "\n",
    "                attributes = ['contact_id', 'frmt_id', 'region_id', 'is_ca', 'spend_prev', 'spend_actn', 'opsum_actn', 'logit']\n",
    "                untreated_matched_data = df.loc[treated_matched_data.matched_element.values, attributes]\n",
    "\n",
    "                if len(treated_matched_data) > 1:\n",
    "                    all_mached_data = pd.concat([treated_matched_data, untreated_matched_data])\n",
    "                    # Сохраняем в список (потом склеим за пределами цикла)\n",
    "                    cus_lfl_list.append(\n",
    "                    all_mached_data[['contact_id', 'frmt_id', 'region_id', 'is_ca', 'logit']]\n",
    "                    )\n",
    "\n",
    "                    #Расчет репрезентативности выборки\n",
    "                    n1 = len(all_mached_data.query('is_ca == 0')['contact_id'].unique())\n",
    "                    n2 = len(all_mached_data.query('is_ca == 1')['contact_id'].unique())\n",
    "                    std = all_mached_data['opsum_actn'].std()\n",
    "                    mean_diff = all_mached_data.query('is_ca == 1')['opsum_actn'].mean() -\\\n",
    "                                all_mached_data.query('is_ca == 0')['opsum_actn'].mean()\n",
    "                    \n",
    "                    #mean_diff = df.query('is_ca == 1')['spend_prev'].mean() * mde_ratio\n",
    "                    \n",
    "                    min_sample_size, power = min_sample_size_avg(std = std, mean_diff = mean_diff)\n",
    "                    if n2 >= min_sample_size:\n",
    "                        is_ok_sample = 1\n",
    "                    else:\n",
    "                        is_ok_sample = 0\n",
    "\n",
    "                    # Сходимость на периоде \"ДО\"\n",
    "                    treated_outcome_prev = treated_matched_data.spend_prev\n",
    "                    untreated_outcome_prev = untreated_matched_data.spend_prev\n",
    "                    _ , p_val_prev = stats.ttest_ind(treated_outcome_prev, untreated_outcome_prev)\n",
    "\n",
    "                    # Сходимость на периоде \"АКЦ\"\n",
    "                    treated_outcome_actn = treated_matched_data.opsum_actn\n",
    "                    untreated_outcome_actn = untreated_matched_data.opsum_actn\n",
    "                    ttest_actn = cuped_ttest(untreated_outcome_actn, treated_outcome_actn, untreated_outcome_prev, treated_outcome_prev)\n",
    "                    #_ , p_val_actn = stats.ttest_ind(treated_outcome_actn, untreated_outcome_actn, equal_var=False)\n",
    "                    \n",
    "                    stat_temp = pd.DataFrame({'frmt_id':[frmt[f]],\n",
    "                                            'region_id':[region[r]],\n",
    "                                            'n_ca_total':[n2],\n",
    "                                            'min_sample_size':[min_sample_size],\n",
    "                                            'is_ok_sample':[is_ok_sample],\n",
    "                                            'power':[power],\n",
    "                                            'stat_prev':[p_val_prev],\n",
    "                                            'stat_actn':[ttest_actn[0]],\n",
    "                                            'effect':[ttest_actn[1]],\n",
    "                                            'ci_length':[ttest_actn[2]],\n",
    "                                            'left_bound':[ttest_actn[3]],\n",
    "                                            'right_bound':[ttest_actn[4]]})\n",
    "                    stat_test_list.append(stat_temp)\n",
    "\n",
    "                    # Доля мэтчинга ЛФЛ ЦА/КГ\n",
    "                    match_ratio = treated_matched_data.groupby(['frmt_id', 'region_id'])['contact_id'].count() /\\\n",
    "                                df[df.is_ca == 1].groupby(['frmt_id', 'region_id'])['contact_id'].count() * 100\n",
    "                    print(f'{match_ratio.index[0][0]} {match_ratio.index[0][1]} {match_ratio.values}')\n",
    "            else:\n",
    "                stat_temp = pd.DataFrame({'frmt_id':[frmt[f]],\n",
    "                                        'region_id':[region[r]],\n",
    "                                        'n_ca_total':[n2],\n",
    "                                        'min_sample_size':[0],\n",
    "                                        'is_ok_sample':[0],\n",
    "                                        'power':[0],\n",
    "                                        'stat_prev':[0.0],\n",
    "                                        'stat_actn':[1.0],\n",
    "                                        'effect':[0.0],\n",
    "                                        'ci_length':[0.0],\n",
    "                                        'left_bound':[0.0],\n",
    "                                        'right_bound':[0.0]})\n",
    "                stat_test_list.append(stat_temp)\n",
    "            \n",
    "            df_last = df\n",
    "\n",
    "            if not (f == len(frmt) - 1 and r == len(region) - 1):\n",
    "            # Не держим df в памяти, сохраняем только последний для визуализации\n",
    "                del df\n",
    "                gc.collect()\n",
    "\n",
    "    gc.collect()\n",
    "\n",
    "    #Итоговые объединения\n",
    "    cus_lfl = pd.concat(cus_lfl_list, ignore_index=True) if cus_lfl_list else pd.DataFrame(\n",
    "        columns=['contact_id', 'frmt_id', 'region_id', 'is_ca', 'logit']\n",
    "    )\n",
    "    stat_test = pd.concat(stat_test_list, ignore_index=True) if stat_test_list else pd.DataFrame(\n",
    "        columns=['frmt_id', 'region_id', 'n_ca_total', 'min_sample_size', 'is_ok_sample',\n",
    "                'power', 'stat_prev', 'stat_actn', 'effect', 'ci_length', 'left_bound', 'right_bound']\n",
    "    )\n",
    "\n",
    "    print('Процесс завершен.')\n",
    "    stat_test.reset_index(drop=True, inplace=True)\n",
    "    stat_test['stat_shod'] = 0\n",
    "    stat_test['stat_test'] = 0\n",
    "\n",
    "    for i in range(len(stat_test)):\n",
    "        if stat_test.loc[i, 'stat_prev'] > 0.05:\n",
    "            stat_test.loc[i, 'stat_shod'] = 1\n",
    "            if stat_test.loc[i, 'stat_actn'] < 0.05:\n",
    "                if stat_test.loc[i, 'effect'] > 0:\n",
    "                    stat_test.loc[i, 'stat_test'] = 1\n",
    "\n",
    "    file_name = f\"{actn_name}_stat_test.xlsx\"\n",
    "    stat_test.to_excel(file_name, index=False)\n",
    "\n",
    "    # print('Оцениваемый признак: Траты покупателя')\n",
    "    # print('Тотал результатов: ', len(stat_test))\n",
    "    # print()\n",
    "    # print('Тип клиента: REGULAR')\n",
    "    # print('Кол-во: ', len(stat_test))\n",
    "    # print('Кол-во сходимых результатов: ', sum(stat_test.stat_shod))\n",
    "    # print('Доля сходимых результатов: {:.1f}%'.format(sum(stat_test.stat_shod)/len(stat_test)*100))\n",
    "    # print()\n",
    "    # print('Из них: Кол-во значимых эффектов: ', sum(stat_test.stat_test))\n",
    "    # print('        Доля значимых эффектов: {:.1f}%'.format(sum(stat_test.stat_test)/len(stat_test)*100))\n",
    "    # print()\n",
    "    stat_test\n",
    "    cus_lfl.groupby('is_ca')['contact_id'].nunique()\n",
    "\n",
    "    #Сохраняю Стат.тест\n",
    "    gp_connector.execute_query(f\"\"\"drop table if exists ba.vt_{mask}_stat_temp;\"\"\")\n",
    "    gp_connector.execute_query(f\"\"\" --sql\n",
    "    Create Table ba.vt_{mask}_stat_temp (\n",
    "    FRMT_ID INTEGER,\n",
    "    REGION_ID INTEGER,\n",
    "    STAT_TEST SMALLINT\n",
    "    );\n",
    "    \"\"\")\n",
    "\n",
    "    res = stat_test[['frmt_id', 'region_id', 'stat_test']]\n",
    "    gp_connector.insert_data(df=res, tablename=f'ba.vt_{mask}_stat_temp')\n",
    "    gp_connector.execute_query(f\"\"\"\n",
    "    DELETE FROM BA.T_ZIG_STAT_TEST_PSM\n",
    "    WHERE ACTN_NAME = '{actn_name}';\n",
    "    \"\"\")\n",
    "\n",
    "    gp_connector.execute_query(f\"\"\"\n",
    "    INSERT INTO BA.T_ZIG_STAT_TEST_PSM\n",
    "    SELECT\n",
    "        '{actn_name}'\n",
    "        ,FRMT_ID\n",
    "        ,REGION_ID\n",
    "        ,STAT_TEST\n",
    "    FROM \n",
    "        ba.vt_{mask}_stat_temp\n",
    "    ;\n",
    "    \"\"\")\n",
    "    gp_connector.gp(f\"\"\"SELECT count(1) FROM BA.T_ZIG_STAT_TEST_PSM where ACTN_NAME = '{actn_name}';\"\"\").iloc[:,0][0]\n",
    "    ### Сохраняю ЦА/КГ (ЛФЛ)\n",
    "    cus_lfl.contact_id.nunique()\n",
    "    #Сохраняю результат\n",
    "    gp_connector.execute_query(f\"\"\"drop table if exists ba.vt_{mask}_cus_temp;\"\"\")\n",
    "    gp_connector.execute_query(f\"\"\" --sql\n",
    "    Create Table ba.vt_{mask}_cus_temp (\n",
    "    CONTACT_ID INTEGER,\n",
    "    FRMT_ID INTEGER,\n",
    "    REGION_ID INTEGER,\n",
    "    IS_CA SMALLINT,\n",
    "    LOGIT NUMERIC\n",
    "    );\n",
    "    \"\"\")\n",
    "\n",
    "    cus_lfl = cus_lfl.reset_index(drop=True)\n",
    "    gp_connector.insert_data(df=cus_lfl, tablename=f'ba.vt_{mask}_cus_temp')\n",
    "    #Собираю в таблицу ЦА/КГ\n",
    "    gp_connector.execute_query(f\"\"\"drop table if exists ba.vt_{mask}_cus;\"\"\")\n",
    "    gp_connector.execute_query(f\"\"\" --sql\n",
    "    Create Table ba.vt_{mask}_cus (\n",
    "    CONTACT_ID INTEGER,\n",
    "    ACTN_ID SMALLINT,\n",
    "    FRMT_ID INTEGER,\n",
    "    REGION_ID INTEGER,\n",
    "    CUS_TYPE VARCHAR(10),\n",
    "    IS_CA SMALLINT,\n",
    "    IS_CUS_LFL SMALLINT,\n",
    "    LOGIT NUMERIC\n",
    "    );\n",
    "    \"\"\")\n",
    "\n",
    "    gp_connector.execute_query(f\"\"\"\n",
    "    INSERT INTO ba.vt_{mask}_cus\n",
    "    SELECT DISTINCT\n",
    "        CONTACT_ID\n",
    "        ,{actnId}\n",
    "        ,FRMT_ID\n",
    "        ,REGION_ID\n",
    "        ,'REGULAR' as CUS_TYPE\n",
    "        ,IS_CA\n",
    "        ,1 AS IS_CUS_LFL\n",
    "        ,LOGIT\n",
    "    FROM \n",
    "        ba.vt_{mask}_cus_temp\n",
    "    ;\n",
    "    \"\"\")\n",
    "    #NEW, RETURNED\n",
    "    gp_connector.execute_query(f\"\"\"\n",
    "    INSERT INTO ba.vt_{mask}_cus\n",
    "    SELECT DISTINCT\n",
    "        CONTACT_ID\n",
    "        ,{actnId}\n",
    "        ,FRMT_ID\n",
    "        ,REGION_ID\n",
    "        ,CUS_TYPE\n",
    "        ,1 AS IS_CA\n",
    "        ,1 AS IS_CUS_LFL\n",
    "    --    ,null as LOGIT\n",
    "    FROM (\n",
    "        SELECT DISTINCT\n",
    "            T.CONTACT_ID\n",
    "            ,T.FRMT_ID\n",
    "            ,T.REGION_ID\n",
    "            ,C.CUS_TYPE\n",
    "        FROM\n",
    "            ba.vt_{mask}_trn T\n",
    "        JOIN\n",
    "            (SELECT distinct CONTACT_ID FROM ba.vt_{mask}_days_cross) CA \n",
    "            ON CA.CONTACT_ID = T.CONTACT_ID\n",
    "        JOIN\n",
    "            ba.vt_{mask}_cus_type C\n",
    "            ON C.CONTACT_ID = T.CONTACT_ID \n",
    "            AND C.FRMT_ID = T.FRMT_ID\n",
    "            AND C.REGION_ID = T.REGION_ID\n",
    "        WHERE\n",
    "            ACTN_PERIOD = 2\n",
    "            and CUS_TYPE IN ('NEW', 'RETURNED')\n",
    "            and CNT_TRN >= 2\n",
    "        ) d\n",
    "    ;\n",
    "    \"\"\")\n",
    "    #оставшиеся ЦА - не ЛФЛ\n",
    "    gp_connector.execute_query(f\"\"\"\n",
    "    INSERT INTO ba.vt_{mask}_cus\n",
    "    SELECT distinct\n",
    "        CONTACT_ID\n",
    "        ,{actnId}\n",
    "        ,FRMT_ID\n",
    "        ,REGION_ID\n",
    "        ,CUS_TYPE\n",
    "        ,1 AS IS_CA\n",
    "        ,0 AS IS_CUS_LFL\n",
    "    --    ,NULL as LOGIT\n",
    "    FROM (\n",
    "        SELECT distinct\n",
    "            CONTACT_ID\n",
    "            ,FRMT_ID\n",
    "            ,REGION_ID\n",
    "            ,CUS_TYPE\n",
    "        FROM (\n",
    "            SELECT DISTINCT\n",
    "                T.CONTACT_ID\n",
    "                ,T.FRMT_ID\n",
    "                ,T.REGION_ID\n",
    "                ,C.CUS_TYPE\n",
    "            FROM\n",
    "                ba.vt_{mask}_trn T\n",
    "            JOIN\n",
    "                (SELECT distinct CONTACT_ID FROM ba.vt_{mask}_days_cross) CA \n",
    "                ON CA.CONTACT_ID = T.CONTACT_ID\n",
    "            JOIN\n",
    "                ba.vt_{mask}_cus_type C\n",
    "                ON C.CONTACT_ID = T.CONTACT_ID \n",
    "                AND C.FRMT_ID = T.FRMT_ID\n",
    "                AND C.REGION_ID = T.REGION_ID\n",
    "            WHERE\n",
    "                ACTN_PERIOD = 2) d\n",
    "        EXCEPT\n",
    "        SELECT\n",
    "            CONTACT_ID\n",
    "            ,FRMT_ID\n",
    "            ,REGION_ID\n",
    "            ,CUS_TYPE\n",
    "        FROM \n",
    "            ba.vt_{mask}_cus\n",
    "        WHERE \n",
    "            IS_CA = 1\n",
    "        ) d\n",
    "    ;\n",
    "    \"\"\")\n",
    "    #сохраняю ЦА/КГ\n",
    "    gp_connector.execute_query(f\"\"\"\n",
    "    DELETE FROM BA.T_ZIG_SPR_CUS_LFL\n",
    "    WHERE ACTN_ID = {actnId}\n",
    "    ;\n",
    "    \"\"\")\n",
    "\n",
    "    gp_connector.execute_query(f\"\"\"\n",
    "    INSERT INTO BA.T_ZIG_SPR_CUS_LFL\n",
    "    SELECT\n",
    "        CONTACT_ID\n",
    "        ,ACTN_ID\n",
    "        ,FRMT_ID\n",
    "        ,REGION_ID\n",
    "        ,CUS_TYPE\n",
    "        ,IS_CA\n",
    "        ,IS_CUS_LFL\n",
    "        ,LOGIT\n",
    "    FROM \n",
    "        ba.vt_{mask}_cus\n",
    "    ;\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6dd4f02",
   "metadata": {},
   "source": [
    "## margin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "7da59cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@log_function_call\n",
    "def margin(gp_connector, mask, actn_name, promo_start_date, promo_end_date,\n",
    "            in_code_ruls,\n",
    "            actnId, DateStart, DateEnd, DateStPre, DateEndLast,\n",
    "            lengthprev, lengthpost, lengthActn):\n",
    "    \n",
    "    month = gp_connector.gp(f\"\"\" --sql\n",
    "    SELECT\n",
    "        MONTH_ID\n",
    "        ,min(DAY_ID) as min_dt\n",
    "        ,max(DAY_ID) as max_dt\n",
    "    FROM ba.vt_{mask}_days \n",
    "    WHERE ACTN_NAME = '{actn_name}'\n",
    "        and ACTN_PERIOD IN (1,2,3)\n",
    "    group by MONTH_ID\n",
    "    order by MONTH_ID\n",
    "    ;\"\"\")\n",
    "\n",
    "    gp_connector.execute_query(f\"\"\"DROP TABLE IF EXISTS ba.vt_{mask}_trn_prd;\"\"\")\n",
    "    gp_connector.execute_query(f\"\"\" --sql\n",
    "    CREATE TABLE ba.vt_{mask}_trn_prd (\n",
    "    cheque_pk bytea,\n",
    "    contact_id integer,\n",
    "    is_ca smallint,\n",
    "    day_id date,\n",
    "    orgunit_id integer,\n",
    "    article_id numeric,\n",
    "    summ_discounted numeric,\n",
    "    qnty numeric\n",
    "    )   \n",
    "    WITH (\n",
    "        appendonly=true,\n",
    "        blocksize=32768,\n",
    "        compresstype=zstd,\n",
    "        compresslevel=4,\n",
    "        orientation=column)\n",
    "    DISTRIBUTED BY (cheque_pk)\n",
    "    ;\"\"\")\n",
    "\n",
    "    for i in tqdm_notebook(range(len(month))):\n",
    "        dt_start = str(month.min_dt[i])\n",
    "        dt_end = str(month.max_dt[i])\n",
    "        \n",
    "        gp_connector.execute_query(f\"\"\"drop table if exists ba.vt_{mask}_trn_temp;\"\"\")\n",
    "        gp_connector.execute_query(f\"\"\" --sql\n",
    "        CREATE TABLE ba.vt_{mask}_trn_temp (\n",
    "        contact_id integer,\n",
    "        orgunit_id integer,\n",
    "        cheque_pk bytea,\n",
    "        datetime date,\n",
    "        article_id integer,\n",
    "        summ_discounted numeric,\n",
    "        quantity numeric,\n",
    "        rn smallint\n",
    "        )\n",
    "        WITH (\n",
    "            appendonly=true,\n",
    "            blocksize=32768,\n",
    "            compresstype=zstd,\n",
    "            compresslevel=4,\n",
    "            orientation=column)\n",
    "        DISTRIBUTED BY (cheque_pk)\n",
    "        ;\"\"\")\n",
    "\n",
    "        gp_connector.execute_query(f\"\"\" --sql\n",
    "        insert into ba.vt_{mask}_trn_temp\n",
    "        SELECT \n",
    "            t.contact_id\n",
    "            ,t.orgunit_id\n",
    "            ,t.cheque_pk\n",
    "            ,t.day_id as datetime\n",
    "            ,t.article_id\n",
    "            ,SUM(t.summ_discounted) AS summ_discounted\n",
    "            ,SUM(t.quantity) AS quantity\n",
    "            ,1 as rn\n",
    "        FROM (\n",
    "            SELECT \n",
    "                c.contact_id\n",
    "                ,c.orgunit_id\n",
    "                ,c.cheque_pk\n",
    "                ,date_trunc('day', c.datetime)::date AS day_id\n",
    "                ,ci.article_id\n",
    "                ,ci.summ_discounted\n",
    "                ,ci.quantity\n",
    "            FROM \n",
    "                dm.cheque c\n",
    "            JOIN\n",
    "                dm.cheque_item ci on ci.cheque_pk = c.cheque_pk\n",
    "            WHERE\n",
    "                operation_type_id = 1\n",
    "                AND c.contact_id > 0\n",
    "                AND c.datetime between ('{dt_start}'::timestamp) AND ('{dt_end}'::timestamp + interval '1' day - interval '1' second)\n",
    "                AND ci.datetime between ('{dt_start}'::timestamp) AND ('{dt_end}'::timestamp + interval '1' day - interval '1' second)\n",
    "            ) t\n",
    "        GROUP BY\n",
    "            t.contact_id,\n",
    "            t.orgunit_id,\n",
    "            t.cheque_pk,\n",
    "            t.day_id,\n",
    "            t.article_id;\n",
    "        ;\"\"\")\n",
    "\n",
    "        gp_connector.execute_query(f\"\"\" --sql                          \n",
    "        insert into ba.vt_{mask}_trn_prd\n",
    "        SELECT\n",
    "            t.cheque_pk\n",
    "            ,t.contact_id\n",
    "            ,c.is_ca\n",
    "            ,t.datetime\n",
    "            ,t.orgunit_id\n",
    "            ,t.article_id\n",
    "            ,t.summ_discounted\n",
    "            ,t.quantity\n",
    "        from\n",
    "            ba.vt_{mask}_trn_temp t\n",
    "        JOIN \n",
    "            (SELECT DISTINCT contact_id, is_ca FROM BA.T_ZIG_SPR_CUS_LFL WHERE ACTN_ID = {actnId}) c    -- Клиенты для оценки\n",
    "            ON c.contact_id = t.contact_id\n",
    "        JOIN \n",
    "            ba.vt_{mask}_whs w ON w.orgunit_id = t.orgunit_id\n",
    "        WHERE\n",
    "            t.rn = 1\n",
    "        ;\"\"\")\n",
    "\n",
    "    gp_connector.execute_query(f\"\"\"DROP TABLE IF EXISTS ba.vt_{mask}_trn_clear;\"\"\")\n",
    "    gp_connector.execute_query(f\"\"\" --sql\n",
    "    CREATE TABLE ba.vt_{mask}_trn_clear (\n",
    "    cheque_pk bytea,\n",
    "    contact_id integer,\n",
    "    is_ca smallint,\n",
    "    day_id date,\n",
    "    orgunit_id integer,\n",
    "    article_id integer,\n",
    "    summ_discounted numeric,\n",
    "    qnty numeric,\n",
    "    is_trn_fltr smallint\n",
    "    )\n",
    "    WITH (\n",
    "        appendonly=true,\n",
    "        blocksize=32768,\n",
    "        compresstype=zstd,\n",
    "        compresslevel=4,\n",
    "        orientation=column)\n",
    "    DISTRIBUTED BY (cheque_pk)\n",
    "    ;\"\"\")\n",
    "\n",
    "    gp_connector.execute_query(f\"\"\"drop table if exists ba.vt_{mask}_trn_temp;\"\"\")\n",
    "    gp_connector.execute_query(f\"\"\" --sql\n",
    "    CREATE TABLE ba.vt_{mask}_trn_temp AS (\n",
    "    SELECT\n",
    "        t.cheque_pk\n",
    "        ,t.contact_id\n",
    "        ,t.day_id\n",
    "    FROM\n",
    "        ba.vt_{mask}_trn_prd t\n",
    "    WHERE\n",
    "        t.day_id between '{DateStart}' AND '{DateEnd}'\n",
    "    group by \n",
    "        t.cheque_pk\n",
    "        ,t.contact_id\n",
    "        ,t.day_id\n",
    "    );\"\"\")\n",
    "\n",
    "    gp_connector.execute_query(f\"\"\" --sql\n",
    "    insert into ba.vt_{mask}_trn_clear\n",
    "    WITH trn_ca AS (\n",
    "        SELECT\n",
    "            t.cheque_pk\n",
    "            ,t.contact_id\n",
    "            ,t.day_id\n",
    "            ,cd.IS_CROSS         -- чеки с пересечением в других акциях\n",
    "        FROM\n",
    "            ba.vt_{mask}_trn_temp t\n",
    "        JOIN \n",
    "            (SELECT DISTINCT contact_id FROM ba.vt_{mask}_days_cross) c    -- Клиенты для оценки\n",
    "            ON c.contact_id = t.contact_id\n",
    "        JOIN\n",
    "            ba.vt_{mask}_days_cross cd\n",
    "            on cd.CONTACT_ID = t.CONTACT_ID\n",
    "            and cd.DAY_ID = t.day_id\n",
    "        )\n",
    "\n",
    "    SELECT\n",
    "        t.cheque_pk\n",
    "        ,t.contact_id\n",
    "        ,t.is_ca\n",
    "        ,t.day_id\n",
    "        ,t.orgunit_id\n",
    "        ,t.article_id\n",
    "        ,t.summ_discounted\n",
    "        ,t.qnty\n",
    "        ,coalesce(tc.IS_CROSS, 0) AS IS_TRN_FLTR         -- чеки с пересечением в других акциях\n",
    "    FROM\n",
    "        ba.vt_{mask}_trn_prd t\n",
    "    left JOIN\n",
    "        trn_ca tc on tc.cheque_pk = t.cheque_pk\n",
    "    ;\n",
    "    \"\"\")\n",
    "\n",
    "    gp_connector.execute_query(f\"\"\"\n",
    "    DELETE from ba.vt_{mask}_trn_clear\n",
    "    where IS_TRN_FLTR = 1\n",
    "    ;\"\"\")\n",
    "\n",
    "    # Расчет параметров коммерческой маржи\n",
    "    print(f'Создаем пустую таблицу для параметров расчета маржи.')\n",
    "    gp_connector.execute_query(f\"\"\"drop table if exists ba.vt_{mask}_aum;\"\"\")\n",
    "    gp_connector.execute_query(f\"\"\" --sql\n",
    "    create table ba.vt_{mask}_aum (\n",
    "        day_id date,\n",
    "        article_id integer,\n",
    "        orgunit_id integer,\n",
    "        cp_sum numeric,\n",
    "        comm_comp_out_bill numeric,\n",
    "        bonus numeric,\n",
    "        ri_la_intco_margin_sum numeric,\n",
    "        sp_intco_margin_sum numeric,\n",
    "        logistics_sum numeric,\n",
    "        vat_factor numeric\n",
    "    )\n",
    "    with (\n",
    "        appendonly=true,\n",
    "        blocksize=32768,\n",
    "        compresstype=zstd,\n",
    "        compresslevel=4,\n",
    "        orientation=column)\n",
    "    ;\"\"\")\n",
    "\n",
    "    # собираем налоги на товары\n",
    "    print(f'Создаем таблицу с налогами на товары.')\n",
    "    gp_connector.execute_query(f\"\"\"drop table if exists ba.vt_{mask}_vat_vatrate;\"\"\")\n",
    "    gp_connector.execute_query(f\"\"\" --sql\n",
    "        create table ba.vt_{mask}_vat_vatrate as (\n",
    "        select distinct\n",
    "            article_id,\n",
    "            tax_prcnt as vat_vatrate\n",
    "        from dm.art_ext\n",
    "    );\"\"\")\n",
    "\n",
    "    for i in tqdm_notebook(range(len(month))):\n",
    "        dt_start = str(month.min_dt[i])\n",
    "        dt_end = str(month.max_dt[i])\n",
    "\n",
    "        print(f'Собираем строки из таблицы с чеками за период c {dt_start} по {dt_end}.')\n",
    "        gp_connector.execute_query(f\"\"\"drop table if exists ba.vt_{mask}_trn_temp;\"\"\")\n",
    "        gp_connector.execute_query(f\"\"\" --sql\n",
    "        create table ba.vt_{mask}_trn_temp as (\n",
    "        select\n",
    "            day_id,\n",
    "            orgunit_id,\n",
    "            article_id\n",
    "        from ba.vt_{mask}_trn_clear\n",
    "        where day_id between '{dt_start}' and '{dt_end}'\n",
    "        group by \n",
    "            day_id,\n",
    "            orgunit_id,\n",
    "            article_id\n",
    "        );\"\"\")\n",
    "\n",
    "        \n",
    "        # собираем строки из AUM за исследуемый период\n",
    "        print(f'Cобираем строки из AUM за период c {dt_start} по {dt_end}.')\n",
    "        gp_connector.execute_query(f\"\"\"drop table if exists ba.vt_{mask}_cbi_aum;\"\"\")\n",
    "        gp_connector.execute_query(f\"\"\" --sql\n",
    "        create table ba.vt_{mask}_cbi_aum as (\n",
    "        select \n",
    "            day_id,\n",
    "            article_id, \n",
    "            orgunit_id,\n",
    "            cp_sum_wo_nds,\n",
    "            comm_comp_out_bill_wo_nds,\n",
    "            opsum_bonus_wo_nds,\n",
    "            ri_la_intco_margin_sum,\n",
    "            sp_intco_margin_sum,\n",
    "            logistics_sum,\n",
    "            qnty\n",
    "        from dm.cbi_aum_whs_art\n",
    "        where day_id between '{dt_start}' and '{dt_end}'\n",
    "        );\"\"\")\n",
    "\n",
    "        # Предобработка строк из AUM за исследуемый период\n",
    "        print(f'Предобработка строк из AUM за период c {dt_start} по {dt_end}.')\n",
    "        gp_connector.execute_query(f\"\"\"drop table if exists ba.vt_{mask}_aum_pre_calc;\"\"\")\n",
    "        gp_connector.execute_query(f\"\"\" --sql\n",
    "        create table ba.vt_{mask}_aum_pre_calc as (\n",
    "        select \n",
    "            aum.day_id,\n",
    "            aum.article_id,\n",
    "            aum.orgunit_id,\n",
    "            coalesce(sum(aum.cp_sum_wo_nds::float * (1 + (a.vat_vatrate::float / 100))), 0) as cp_sum,\n",
    "            coalesce(sum(aum.comm_comp_out_bill_wo_nds::float * (1 + (a.vat_vatrate::float / 100))), 0) as comm_comp_out_bill,\n",
    "            coalesce(sum(aum.opsum_bonus_wo_nds::float * (1 + (a.vat_vatrate::float / 100))), 0) as bonus,\n",
    "            coalesce(sum(aum.ri_la_intco_margin_sum::float), 0) as ri_la_intco_margin_sum,\n",
    "            coalesce(sum(aum.sp_intco_margin_sum::float), 0) as sp_intco_margin_sum,\n",
    "            coalesce(sum(aum.logistics_sum::float), 0) as logistics_sum,\n",
    "            coalesce(sum(aum.qnty), 0) as qnty,\n",
    "            max( 1 / (1 + (a.vat_vatrate::float / 100))) as vat_factor\n",
    "        from \n",
    "            ba.vt_{mask}_cbi_aum as aum\n",
    "            join ba.vt_{mask}_trn_temp as t\n",
    "                on t.day_id = aum.day_id\n",
    "                and  t.orgunit_id = aum.orgunit_id\n",
    "                and  t.article_id = aum.article_id\n",
    "            join ba.vt_{mask}_vat_vatrate as a\n",
    "                on a.article_id = aum.article_id\n",
    "        group by \n",
    "            aum.day_id,\n",
    "            aum.article_id,\n",
    "            aum.orgunit_id \n",
    "        having sum(aum.qnty) > 0.01 \n",
    "        );\"\"\")\n",
    "\n",
    "        print(f'Заполняем таблицу параметров для расчета маржи за период c {dt_start} по {dt_end}.')\n",
    "        gp_connector.execute_query(f\"\"\" --sql\n",
    "        insert into ba.vt_{mask}_aum \n",
    "        select\n",
    "            day_id, \t\t\t\t\t\t\t\t\t\t\t\t\t-- дата\n",
    "            article_id, \t\t\t\t\t\t\t\t\t\t\t\t-- продукт\n",
    "            orgunit_id, \t\t\t\t\t\t\t\t\t\t\t\t-- магазин\n",
    "            cp_sum / qnty as cp_sum, \t\t\t\t\t\t\t\t\t-- себестоимость (средняя стоимость товара со склада)\n",
    "            comm_comp_out_bill / qnty as comm_comp_out_bill,\t\t\t-- компенсация вне накладной\n",
    "            bonus / qnty as bonus,\t\t\t\t\t\t\t\t\t\t-- бонусы от поставщиков\n",
    "            ri_la_intco_margin_sum / qnty as ri_la_intco_margin_sum, \t-- внутригрупповые трансферты\n",
    "            sp_intco_margin_sum / qnty as sp_intco_margin_sum, \t\t\t-- внутригрупповые трансферты\n",
    "            logistics_sum / qnty as logistics_sum, \t\t\t\t\t\t-- затраты на логистику\n",
    "            vat_factor\n",
    "        from ba.vt_{mask}_aum_pre_calc\n",
    "        ;\"\"\")\n",
    "        print('***********************************')\n",
    "\n",
    "    #бонусы списанные / начисленные\n",
    "    #вариант 1 без вычитания бонусов по механике\n",
    "\n",
    "    gp_connector.execute_query(f\"\"\"DROP TABLE IF EXISTS ba.vt_{mask}_bonuses;\"\"\")\n",
    "    gp_connector.execute_query(f\"\"\"\n",
    "    CREATE TABLE ba.vt_{mask}_bonuses (\n",
    "    CHEQUE_PK BYTEA,\n",
    "    SUMM_DISCOUNTED NUMERIC,\n",
    "    BONUS_ACCRUAL NUMERIC,\n",
    "    BONUS_REDEMPTION NUMERIC\n",
    "    )\n",
    "    WITH (\n",
    "    appendonly=true,\n",
    "    blocksize=32768,\n",
    "    compresstype=zstd,\n",
    "    compresslevel=4,\n",
    "    orientation=column);\n",
    "    \"\"\")\n",
    "\n",
    "    gp_connector.execute_query(f\"\"\"\n",
    "    INSERT INTO ba.vt_{mask}_bonuses\n",
    "    WITH trn_clear AS ( \n",
    "            select\n",
    "                cheque_pk\n",
    "                ,sum(summ_discounted) as summ_discounted\n",
    "            from\n",
    "                ba.vt_{mask}_trn_prd\n",
    "            where\n",
    "                summ_discounted <> 0\n",
    "            GROUP by 1\n",
    "        ), bonus AS (\n",
    "            select\n",
    "                cheque_pk\n",
    "                ,sum(case when bonus_type = 'addition' then value end)/100.0 as BONUS_ACCRUAL --- бонусы начисленные\n",
    "                ,sum(case when bonus_type = 'write_off' then value end)/100.0 as BONUS_REDEMPTION ---- бонусы списанные\n",
    "            from\n",
    "                dm.bonus_all\n",
    "            where\n",
    "                date(created_on) between '{DateStPre}' and '{DateEndLast}'\n",
    "            group by 1\n",
    "        )\n",
    "\n",
    "    select\n",
    "        t.cheque_pk\n",
    "        ,t.summ_discounted\n",
    "        ,coalesce(b.BONUS_ACCRUAL, 0)/summ_discounted as BONUS_ACCRUAL --- бонусы начисленные в расчете на 1 руб. \n",
    "        ,coalesce(b.BONUS_REDEMPTION, 0)/summ_discounted as BONUS_REDEMPTION ---- бонусы списанные в расчете на 1 руб.\n",
    "    from\n",
    "        trn_clear t\n",
    "    join\n",
    "        bonus b on b.cheque_pk = t.cheque_pk\n",
    "    ;\n",
    "    \"\"\")\n",
    "\n",
    "    gp_connector.execute_query(f\"\"\"drop table if exists ba.vt_{mask}_trn_ruls;\"\"\")\n",
    "    gp_connector.execute_query(f\"\"\" --sql\n",
    "    Create Table ba.vt_{mask}_trn_ruls (\n",
    "    CHEQUE_PK BYTEA,\n",
    "    CONTACT_ID INTEGER,\n",
    "    ORGUNIT_ID INTEGER,\n",
    "    OPSUM NUMERIC,\n",
    "    DISC NUMERIC,\n",
    "    ACCRUEDPOINTS NUMERIC,\n",
    "    DISCOUNTPOINTS NUMERIC,\n",
    "    REDEEMEDPOINTS NUMERIC\n",
    "    )\n",
    "    WITH (\n",
    "    appendonly=true,\n",
    "    blocksize=32768,\n",
    "    compresstype=zstd,\n",
    "    compresslevel=4,\n",
    "    orientation=column);\n",
    "    \"\"\")\n",
    "\n",
    "    import re\n",
    "\n",
    "    def _codes_to_in_clause(raw):\n",
    "        # принимает: \"FC_jul25_S_5\", или \"A;B,C\", или \"'A','B'\"\n",
    "        parts = re.split(r'[;,]', str(raw)) if raw is not None else []\n",
    "        parts = [p.strip().strip(\"'\").strip('\"') for p in parts if p and p.strip()]\n",
    "        if not parts:\n",
    "            return None\n",
    "        return \",\".join(\"'\" + p.replace(\"'\", \"''\") + \"'\" for p in parts)\n",
    "\n",
    "    codes_sql = _codes_to_in_clause(in_code_ruls)\n",
    "    rule_code_filter = f\"rule_code IN ({codes_sql})\" if codes_sql else \"1=0\"\n",
    "\n",
    "    logging.info(\"in_code_ruls: %s, rule_code_filter: %s\", in_code_ruls, rule_code_filter)\n",
    "    \n",
    "    gp_connector.execute_query(f\"\"\"\n",
    "    INSERT INTO ba.vt_{mask}_trn_ruls\n",
    "    SELECT\n",
    "        cheque_pk\n",
    "        ,contact_id\n",
    "        ,orgunit_id\n",
    "        ,sum(transaction_value)       AS opsum \n",
    "        ,sum(discount_value)          AS disc\n",
    "        ,sum(addition_point)/100.0   AS accruedpoints\n",
    "        ,sum(write_off_point)/100.0  AS redeemedpoints\n",
    "    FROM (\n",
    "        SELECT\n",
    "            rule_code \n",
    "            ,orgunit_id\n",
    "            ,contact_id\n",
    "            ,cheque_pk\n",
    "            ,transaction_value\n",
    "            ,discount_value\n",
    "            ,addition_point\n",
    "            ,write_off_point\n",
    "        FROM \n",
    "            dm.transaction_rule t\n",
    "        WHERE \n",
    "            {rule_code_filter}\n",
    "            and created_on between '{promo_start_date}'::timestamp and '{promo_end_date}'::timestamp + interval '1' day - interval '1' second\n",
    "        ) d\n",
    "    GROUP by \n",
    "        cheque_pk\n",
    "        ,contact_id\n",
    "        ,orgunit_id\n",
    "    ;\n",
    "    \"\"\")\n",
    "\n",
    "    gp_connector.execute_query(f\"\"\"drop table if exists ba.vt_{mask}_trn_ruls_clear;\"\"\")\n",
    "    gp_connector.execute_query(f\"\"\" --sql\n",
    "    Create Table ba.vt_{mask}_trn_ruls_clear (\n",
    "    CONTACT_ID INTEGER,\n",
    "    FRMT_ID INTEGER,\n",
    "    REGION_ID INTEGER,\n",
    "    OPSUM NUMERIC,\n",
    "    DISC NUMERIC,\n",
    "    ACCRUEDPOINTS NUMERIC,\n",
    "    DISCOUNTPOINTS NUMERIC,\n",
    "    REDEEMEDPOINTS NUMERIC\n",
    "    )\n",
    "    WITH (\n",
    "    appendonly=true,\n",
    "    blocksize=32768,\n",
    "    compresstype=zstd,\n",
    "    compresslevel=4,\n",
    "    orientation=column);\n",
    "    \"\"\")\n",
    "\n",
    "    gp_connector.execute_query(f\"\"\"\n",
    "    INSERT INTO ba.vt_{mask}_trn_ruls_clear\n",
    "    SELECT\n",
    "        contact_id\n",
    "        ,frmt_id\n",
    "        ,region_id\n",
    "        ,sum(opsum)         AS opsum \n",
    "        ,sum(disc)          AS disc\n",
    "        ,sum(accruedpoints) AS accruedpoints\n",
    "        ,sum(redeemedpoints) AS redeemedpoints\n",
    "    FROM \n",
    "        ba.vt_{mask}_trn_ruls r\n",
    "    JOIN\n",
    "        (select distinct cheque_pk from ba.vt_{mask}_trn_clear) t on t.cheque_pk = r.cheque_pk\n",
    "    JOIN\n",
    "        dm.WHS w on w.orgunit_id = r.orgunit_id\n",
    "    GROUP by\n",
    "        contact_id\n",
    "        ,frmt_id\n",
    "        ,region_id\n",
    "    ;\"\"\")\n",
    "\n",
    "    gp_connector.execute_query(f\"\"\"drop table if exists ba.vt_{mask}_dataset;\"\"\")\n",
    "    gp_connector.execute_query(f\"\"\"\n",
    "    CREATE TABLE ba.vt_{mask}_dataset (\n",
    "    CHEQUE_PK BYTEA,\n",
    "    CONTACT_ID INTEGER,\n",
    "    IS_CA SMALLINT,\n",
    "    ACTN_PERIOD SMALLINT,\n",
    "    DAY_ID DATE,\n",
    "    ORGUNIT_ID INTEGER,\n",
    "    ARTICLE_ID INTEGER,\n",
    "    IS_ACTN_ART SMALLINT,\n",
    "    OPSUM_KONTROLLING DECIMAL(20, 2),\n",
    "    OPSUM_WO_NDS DECIMAL(20, 2),\n",
    "    GROSS_MARGIN_WO_NDS DECIMAL(20, 2),\n",
    "    GROSS_MARGIN_WO_NDS_WO_LOGIST DECIMAL(20, 2)\n",
    "    )\n",
    "    WITH (\n",
    "    appendonly=true,\n",
    "    blocksize=32768,\n",
    "    compresstype=zstd,\n",
    "    compresslevel=4,\n",
    "    orientation=column)\n",
    "    ;\"\"\")\n",
    "\n",
    "    for i in tqdm_notebook(range(len(month))):\n",
    "        dt_start = str(month.min_dt[i])\n",
    "        dt_end = str(month.max_dt[i])\n",
    "\n",
    "        gp_connector.execute_query(f\"\"\"drop table if exists ba.vt_{mask}_aum_temp;\"\"\")\n",
    "        gp_connector.execute_query(f\"\"\" --sql\n",
    "        CREATE TABLE ba.vt_{mask}_aum_temp AS (\n",
    "        SELECT \n",
    "            day_id\n",
    "            ,article_id \n",
    "            ,orgunit_id \n",
    "            ,cp_sum\n",
    "            ,comm_comp_out_bill\n",
    "            ,bonus\n",
    "            ,ri_la_intco_margin_sum\n",
    "            ,sp_intco_margin_sum\n",
    "            ,logistics_sum\n",
    "            ,vat_factor                      \n",
    "        FROM \n",
    "            ba.vt_{mask}_aum aum\n",
    "        WHERE\n",
    "            day_id between '{dt_start}' and '{dt_end}'\n",
    "        );\"\"\")\n",
    "\n",
    "        gp_connector.execute_query(f\"\"\"drop table if exists ba.vt_{mask}_trn_temp;\"\"\")\n",
    "        gp_connector.execute_query(f\"\"\" --sql\n",
    "        CREATE TABLE ba.vt_{mask}_trn_temp AS (\n",
    "        SELECT\n",
    "            cheque_pk\n",
    "            ,contact_id\n",
    "            ,is_ca\n",
    "            ,day_id\n",
    "            ,orgunit_id\n",
    "            ,article_id\n",
    "            ,summ_discounted\n",
    "            ,qnty\n",
    "            ,is_trn_fltr\n",
    "        FROM\n",
    "            ba.vt_{mask}_trn_clear\n",
    "        WHERE\n",
    "            day_id between '{dt_start}' and '{dt_end}'\n",
    "        );\"\"\")\n",
    "        \n",
    "        gp_connector.execute_query(f\"\"\" --sql\n",
    "        INSERT INTO ba.vt_{mask}_dataset    \n",
    "        SELECT\n",
    "            cheque_pk\n",
    "            ,contact_id\n",
    "            ,is_ca\n",
    "            ,actn_period\n",
    "            ,day_id\n",
    "            ,orgunit_id\n",
    "            ,article_id\n",
    "            ,IS_ACTN_ART\n",
    "            ,sku_sale_amt - bonus_redemption AS OPSUM_KONTROLLING ---так контроллинг считает РТО\n",
    "            ,(sku_sale_amt - bonus_redemption) * VAT_FACTOR AS OPSUM_WO_NDS\n",
    "            ,(sku_sale_amt - bonus_redemption - bonus_accrual - cp_sum + comm_comp_out_bill + bonus) *\n",
    "                VAT_FACTOR + ri_la_intco_margin_sum + sp_intco_margin_sum - logistics_sum AS GROSS_MARGIN_WO_NDS ---- гросс-маржа\n",
    "            ,(sku_sale_amt - bonus_redemption - bonus_accrual - cp_sum + comm_comp_out_bill + bonus) *\n",
    "                VAT_FACTOR + ri_la_intco_margin_sum + sp_intco_margin_sum AS GROSS_MARGIN_WO_NDS_WO_LOGIST ---- гросс-маржа без логистики\n",
    "        FROM (\n",
    "            SELECT\n",
    "                t.cheque_pk\n",
    "                ,t.contact_id\n",
    "                ,t.is_ca\n",
    "                ,CASE WHEN t.day_id < '{DateStart}' THEN 1\n",
    "                    WHEN t.day_id between '{DateStart}' and '{DateEnd}' THEN 2\n",
    "                    ELSE 3 END\n",
    "                AS ACTN_PERIOD\n",
    "                ,t.day_id\n",
    "                ,t.orgunit_id\n",
    "                ,t.article_id\n",
    "                ,CASE WHEN aa.article_id IS NOT NULL THEN 1 ELSE 0 END AS IS_ACTN_ART\n",
    "                ,t.summ_discounted                                      AS sku_sale_amt\n",
    "                ,COALESCE(bonus_accrual * t.summ_discounted, 0)         AS bonus_accrual\n",
    "                ,COALESCE(bonus_redemption * t.summ_discounted, 0)      AS bonus_redemption\n",
    "                ,COALESCE(cp_sum * qnty, 0)                             AS cp_sum\n",
    "                ,COALESCE(comm_comp_out_bill * qnty, 0)                 AS comm_comp_out_bill\n",
    "                ,COALESCE(bonus * qnty, 0)                              AS bonus\n",
    "                ,COALESCE(ri_la_intco_margin_sum * qnty, 0)             AS ri_la_intco_margin_sum\n",
    "                ,COALESCE(sp_intco_margin_sum * qnty, 0)                AS sp_intco_margin_sum\n",
    "                ,COALESCE(logistics_sum * qnty, 0)                      AS logistics_sum\n",
    "                ,COALESCE(vat_factor, 1)                                AS VAT_FACTOR\n",
    "            FROM\n",
    "                ba.vt_{mask}_trn_temp t\n",
    "            JOIN\n",
    "                ba.vt_{mask}_aum_temp aum\n",
    "                ON aum.day_id = t.day_id\n",
    "                AND aum.article_id = t.article_id\n",
    "                AND aum.orgunit_id = t.orgunit_id\n",
    "            LEFT JOIN \n",
    "                ba.vt_{mask}_bonuses b ON b.cheque_pk = t.cheque_pk\n",
    "            LEFT JOIN\n",
    "                BA.T_ZIG_SPR_ART_ACTN aa\n",
    "                on aa.article_id = t.article_id\n",
    "                and aa.actn_name = '{actn_name}'\n",
    "            ) d\n",
    "        ;\n",
    "        \"\"\")\n",
    "\n",
    "    #Т.к. Покупателей в выборке слишком много, то делю на несколько групп\n",
    "    n = 3 #Кол-во групп. ~по 1 млн. в группе\n",
    "\n",
    "    gp_connector.execute_query(f\"\"\"drop table if exists ba.vt_{mask}_dataset_cus;\"\"\")\n",
    "    gp_connector.execute_query(f\"\"\"\n",
    "    CREATE TABLE ba.vt_{mask}_dataset_cus (\n",
    "    GRP smallint,\n",
    "    contact_id integer\n",
    "    )\n",
    "    WITH (\n",
    "    appendonly=true,\n",
    "    blocksize=32768,\n",
    "    compresstype=zstd,\n",
    "    compresslevel=4,\n",
    "    orientation=column)\n",
    "    ;\"\"\")\n",
    "\n",
    "    gp_connector.execute_query(f\"\"\"\n",
    "    INSERT INTO ba.vt_{mask}_dataset_cus\n",
    "    SELECT distinct\n",
    "        mod(contact_id, {n}) AS GRP\n",
    "        ,contact_id\n",
    "    FROM \n",
    "        ba.vt_{mask}_dataset\n",
    "    ;\"\"\")\n",
    "\n",
    "    grp = gp_connector.gp(f\"\"\"select GRP from ba.vt_{mask}_dataset_cus group by GRP order by GRP;\"\"\")\n",
    "    len(grp)\n",
    "    \n",
    "    gp_connector.execute_query(f\"\"\"drop table if exists ba.vt_{mask}_dataset_agg;\"\"\")\n",
    "    gp_connector.execute_query(f\"\"\"\n",
    "    CREATE TABLE ba.vt_{mask}_dataset_agg (\n",
    "    CONTACT_ID INTEGER,\n",
    "    IS_CA SMALLINT,\n",
    "    ACTN_PERIOD SMALLINT,\n",
    "    FRMT_ID INTEGER,\n",
    "    REGION_ID INTEGER,\n",
    "    CNT_TRN INTEGER,\n",
    "    CNT_TRN_ART_ACTN INTEGER,\n",
    "    OPSUM_WO_NDS NUMERIC,\n",
    "    GROSS_MARGIN_WO_NDS_WO_LOGIST NUMERIC,\n",
    "    OPSUM_WO_NDS_ART_ACTN NUMERIC,\n",
    "    GROSS_MARGIN_WO_NDS_WO_LOGIST_ART_ACTN NUMERIC\n",
    "    )\n",
    "    WITH (\n",
    "    appendonly=true,\n",
    "    blocksize=32768,\n",
    "    compresstype=zstd,\n",
    "    compresslevel=4,\n",
    "    orientation=column)\n",
    "    ;\"\"\")\n",
    "\n",
    "    for n in tqdm_notebook(range(len(grp))):\n",
    "        gp_connector.execute_query(f\"\"\" --sql\n",
    "        INSERT INTO ba.vt_{mask}_dataset_agg\n",
    "        WITH dataset AS (\n",
    "                SELECT\n",
    "                d.cheque_pk\n",
    "                ,d.contact_id\n",
    "                ,d.is_ca\n",
    "                ,d.actn_period\n",
    "                ,d.orgunit_id\n",
    "                ,d.is_actn_art\n",
    "                ,SUM(OPSUM_WO_NDS) AS OPSUM_WO_NDS\n",
    "                ,SUM(GROSS_MARGIN_WO_NDS_WO_LOGIST) AS GROSS_MARGIN_WO_NDS_WO_LOGIST\n",
    "                ,SUM(case when d.IS_ACTN_ART = 1 then OPSUM_WO_NDS else 0 end) AS OPSUM_WO_NDS_ART_ACTN\n",
    "                ,SUM(case when d.IS_ACTN_ART = 1 then GROSS_MARGIN_WO_NDS_WO_LOGIST else 0 end) AS GROSS_MARGIN_WO_NDS_WO_LOGIST_ART_ACTN\n",
    "            FROM\n",
    "                ba.vt_{mask}_dataset d\n",
    "            JOIN\n",
    "                ba.vt_{mask}_dataset_cus cl on cl.contact_id = d.contact_id\n",
    "            WHERE\n",
    "                cl.GRP = {n}\n",
    "            GROUP BY\n",
    "                d.cheque_pk\n",
    "                ,d.contact_id\n",
    "                ,d.is_ca\n",
    "                ,d.actn_period\n",
    "                ,d.orgunit_id\n",
    "                ,d.is_actn_art\n",
    "        ), dataset_agg AS (\n",
    "            SELECT\n",
    "                d.cheque_pk\n",
    "                ,d.contact_id\n",
    "                ,d.is_ca\n",
    "                ,d.is_actn_art\n",
    "                ,d.actn_period\n",
    "                ,w.frmt_id\n",
    "                ,w.region_id\n",
    "                ,OPSUM_WO_NDS\n",
    "                ,GROSS_MARGIN_WO_NDS_WO_LOGIST\n",
    "                ,OPSUM_WO_NDS_ART_ACTN\n",
    "                ,GROSS_MARGIN_WO_NDS_WO_LOGIST_ART_ACTN\n",
    "                ,case when d.IS_ACTN_ART = 1 then d.cheque_pk end as TRANSACTIONID_ART_ACTN\n",
    "            FROM\n",
    "                dataset d\n",
    "            JOIN\n",
    "                dm.WHS w on w.orgunit_id = d.orgunit_id\n",
    "        )\n",
    "\n",
    "        SELECT\n",
    "            d.contact_id\n",
    "            ,d.is_ca\n",
    "            ,d.actn_period\n",
    "            ,d.frmt_id\n",
    "            ,d.region_id\n",
    "            ,COUNT(distinct d.cheque_pk)                    AS CNT_TRN\n",
    "            ,COUNT(distinct d.TRANSACTIONID_ART_ACTN)       AS CNT_TRN_ART_ACTN\n",
    "            ,SUM(OPSUM_WO_NDS)                              AS OPSUM_WO_NDS\n",
    "            ,SUM(GROSS_MARGIN_WO_NDS_WO_LOGIST)             AS GROSS_MARGIN_WO_NDS_WO_LOGIST\n",
    "            ,SUM(OPSUM_WO_NDS_ART_ACTN)                     AS OPSUM_WO_NDS_ART_ACTN\n",
    "            ,SUM(GROSS_MARGIN_WO_NDS_WO_LOGIST_ART_ACTN)    AS GROSS_MARGIN_WO_NDS_WO_LOGIST_ART_ACTN\n",
    "        FROM\n",
    "            dataset_agg d\n",
    "        GROUP by \n",
    "            d.contact_id\n",
    "            ,d.is_ca\n",
    "            ,d.actn_period\n",
    "            ,d.frmt_id\n",
    "            ,d.region_id\n",
    "        ;\"\"\")\n",
    "\n",
    "    gp_connector.execute_query(f\"\"\"drop table if exists ba.vt_{mask}_cus_margin;\"\"\")\n",
    "    gp_connector.execute_query(f\"\"\"\n",
    "    CREATE TABLE ba.vt_{mask}_cus_margin (\n",
    "    CONTACT_ID INTEGER,\n",
    "    IS_CA SMALLINT,\n",
    "    ACTN_PERIOD SMALLINT,\n",
    "    FRMT_ID INTEGER,\n",
    "    REGION_ID INTEGER,\n",
    "    CUS_TYPE VARCHAR(10),\n",
    "    IS_CUS_LFL SMALLINT,\n",
    "    STAT_TEST SMALLINT,\n",
    "    CNT_TRN INTEGER,\n",
    "    CNT_TRN_ART_ACTN INTEGER,\n",
    "    OPSUM_WO_NDS NUMERIC,\n",
    "    OPSUM_WO_NDS_ART_ACTN NUMERIC,\n",
    "    GROSS_MARGIN_WO_NDS_WO_LOGIST NUMERIC,\n",
    "    GROSS_MARGIN_WO_NDS_WO_LOGIST_ART_ACTN NUMERIC,\n",
    "    DISC NUMERIC\n",
    "    )\n",
    "    WITH (\n",
    "    appendonly=true,\n",
    "    blocksize=32768,\n",
    "    compresstype=zstd,\n",
    "    compresslevel=4,\n",
    "    orientation=column)\n",
    "    ;\"\"\")\n",
    "\n",
    "    gp_connector.execute_query(f\"\"\"\n",
    "    INSERT INTO ba.vt_{mask}_cus_margin\n",
    "    SELECT\n",
    "        d.contact_id\n",
    "        ,d.is_ca\n",
    "        ,d.actn_period\n",
    "        ,d.frmt_id\n",
    "        ,d.region_id\n",
    "        ,cl.cus_type\n",
    "        ,cl.is_cus_lfl\n",
    "        ,stat.stat_test\n",
    "        ,CNT_TRN\n",
    "        ,CNT_TRN_ART_ACTN\n",
    "        ,OPSUM_WO_NDS\n",
    "        ,OPSUM_WO_NDS_ART_ACTN\n",
    "        ,GROSS_MARGIN_WO_NDS_WO_LOGIST\n",
    "        ,GROSS_MARGIN_WO_NDS_WO_LOGIST_ART_ACTN\n",
    "        ,coalesce(r.ACCRUEDPOINTS, 0) as DISC                         -- Кэшбек на ЛК\n",
    "    FROM\n",
    "        ba.vt_{mask}_dataset_agg d\n",
    "    JOIN\n",
    "        BA.T_ZIG_SPR_CUS_LFL cl\n",
    "        on cl.ACTN_ID = {actnId}\n",
    "        and cl.contact_id = d.contact_id\n",
    "        and cl.frmt_id = d.frmt_id\n",
    "        and cl.region_id = d.region_id\n",
    "        and cl.is_ca = d.is_ca\n",
    "    JOIN\n",
    "        BA.T_ZIG_STAT_TEST_PSM stat\n",
    "        on stat.ACTN_NAME = '{actn_name}'\n",
    "        and stat.frmt_id = d.frmt_id\n",
    "        and stat.region_id = d.region_id\n",
    "    left JOIN\n",
    "        ba.vt_{mask}_trn_ruls_clear r  \n",
    "        on r.contact_id = d.contact_id\n",
    "        and r.frmt_id = d.frmt_id\n",
    "        and r.region_id = d.region_id\n",
    "        and d.ACTN_PERIOD = 2\n",
    "    ;\n",
    "    \"\"\")\n",
    "\n",
    "    gp_connector.execute_query(f\"\"\"\n",
    "    DELETE FROM BA.T_ZIG_ACTN_MARGIN\n",
    "    WHERE ACTN_NAME = '{actn_name}'\n",
    "    ;\"\"\")\n",
    "\n",
    "    gp_connector.execute_query(f\"\"\"\n",
    "    INSERT INTO BA.T_ZIG_ACTN_MARGIN\n",
    "    select\n",
    "        '{actn_name}' as ACTN_NAME\n",
    "        ,cm.contact_id\n",
    "        ,IS_CA\n",
    "        ,IS_CUS_LFL\n",
    "        ,ACTN_PERIOD\n",
    "        ,case when ACTN_PERIOD = 1 then {lengthprev}\n",
    "        when ACTN_PERIOD = 3 then {lengthpost}\n",
    "        when ACTN_PERIOD = 2 and IS_CA = 0 then {lengthActn}\n",
    "        when CNT_DAY_WO_CROSS is not NULL then CNT_DAY_WO_CROSS\n",
    "        else 0\n",
    "        end as CNT_DAY_WO_CROSS\n",
    "        ,FRMT_ID\n",
    "        ,REGION_ID\n",
    "        ,CUS_TYPE\n",
    "        ,STAT_TEST\n",
    "        ,CNT_TRN\n",
    "        ,CNT_TRN_ART_ACTN\n",
    "        ,OPSUM_WO_NDS\n",
    "        ,OPSUM_WO_NDS_ART_ACTN\n",
    "        ,GROSS_MARGIN_WO_NDS_WO_LOGIST\n",
    "        ,GROSS_MARGIN_WO_NDS_WO_LOGIST_ART_ACTN\n",
    "        ,DISC\n",
    "        ,CNT_CUS_TOTAL\n",
    "    from\n",
    "        ba.vt_{mask}_cus_margin cm\n",
    "    left join\n",
    "        (select distinct contact_id, CNT_DAY_WO_CROSS from ba.vt_{mask}_days_cross) cd\n",
    "        on cd.contact_id = cm.contact_id\n",
    "        and cm.ACTN_PERIOD = 2\n",
    "    JOIN\n",
    "        (SELECT COUNT(DISTINCT contact_id) AS CNT_CUS_TOTAL FROM BA.T_ZIG_SPR_IDN_ACTN WHERE ACTN_NAME = '{actn_name}') A ON 1=1\n",
    "    ;\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d81250b",
   "metadata": {},
   "source": [
    "## oborot_rto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "ca8842a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@log_function_call\n",
    "def oborot_rto(gp_connector, mask, promo_start_date, promo_end_date, actn_name):\t\n",
    "\tquery = f\"\"\"\n",
    "\tSELECT\n",
    "\t\tcode\n",
    "\tFROM\n",
    "\t\tdm.WHS w\n",
    "\tJOIN\n",
    "\t\tba.vt_{mask}_whs ww \n",
    "\t\ton ww.orgunit_id = w.orgunit_id\n",
    "\t;\n",
    "\t\"\"\"\n",
    "\n",
    "\twhs_code = gp_connector.gp(query)\n",
    "\tlen(whs_code)\n",
    "\twhs_code_lst = gp_connector.to_sql_list(whs_code['code'], quotes=True)\n",
    "\tRTO = teradata_query(f\"\"\"\n",
    "\tSELECT\n",
    "\t\tFRMT_ID\n",
    "\t\t,REGION_ID\n",
    "\t\t,cast(SUM(SALE_WO_NDS) as float) AS SALE_WO_NDS\n",
    "\tFROM\n",
    "\t\tPRD_VD_DM.V_SALE_WHS_DAY S\n",
    "\tJOIN\n",
    "\t\tPRD_VD_DM.V_WHS W ON W.WHS_ID = S.WHS_ID\n",
    "\tWHERE\n",
    "\t\tDAY_ID BETWEEN '{promo_start_date}' and '{promo_end_date}'\n",
    "\t\tAND W.CODE in ({whs_code_lst})\n",
    "\tGROUP by\n",
    "\t\tFRMT_ID\n",
    "\t\t,REGION_ID\n",
    "\t;\"\"\", odbc_td)\n",
    "\tRTO['ACTN_NAME'] = actn_name\n",
    "\tRTO = RTO[['ACTN_NAME', 'FRMT_ID', 'REGION_ID', 'SALE_WO_NDS']]\n",
    "\tRTO['FRMT_ID'] = RTO.FRMT_ID.astype('str')\n",
    "\tRTO['REGION_ID'] = RTO.REGION_ID.astype('str')\n",
    "\tgp_connector.execute_query(f\"\"\"drop table if exists ba.vt_{mask}_opsum_temp;\"\"\")\n",
    "\tgp_connector.execute_query(f\"\"\" --sql\n",
    "\tCREATE TABLE ba.vt_{mask}_opsum_temp (\n",
    "\tactn_name varchar(50),\n",
    "\tfrmt_id integer,\n",
    "\tregion_id integer,\n",
    "\topsum numeric\n",
    "\t)\n",
    "\t;\"\"\")\n",
    "\n",
    "\tgp_connector.insert_data(df=RTO, tablename=f'ba.vt_{mask}_opsum_temp')\n",
    "\n",
    "\tgp_connector.execute_query(f\"\"\"\n",
    "\tDELETE FROM BA.T_ZIG_OPSUM_FRMT_REGION\n",
    "\tWHERE ACTN_NAME = '{actn_name}';\n",
    "\t\"\"\")\n",
    "\n",
    "\tgp_connector.execute_query(f\"\"\" --sql\n",
    "\tinsert into BA.T_ZIG_OPSUM_FRMT_REGION\n",
    "\tselect * from ba.vt_{mask}_opsum_temp\n",
    "\t;\"\"\")\n",
    "\tgp_connector.gp(f\"\"\"\n",
    "\tSELECT\n",
    "\t\tactn_name\n",
    "\t\t,frmt_id\n",
    "\t\t,region_id\n",
    "\t\t,opsum_frmt_region\n",
    "\tFROM \n",
    "\t\tBA.T_ZIG_OPSUM_FRMT_REGION\n",
    "\tWHERE\n",
    "\t\tACTN_NAME = '{actn_name}'\n",
    "\t;\"\"\").head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f5da7e",
   "metadata": {},
   "source": [
    "## delete_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "ca4bb9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "@log_function_call\n",
    "def delete_tables(gp_connector, mask):\n",
    "    # Список шаблонов таблиц, которые нужно исключить\n",
    "    exclude_templates = [\n",
    "        f\"vt_{mask}_whs\",\n",
    "        f\"vt_{mask}_days\",\n",
    "        f\"vt_{mask}_days_cross\",\n",
    "        f\"vt_{mask}_spr_actn\",\n",
    "        f\"vt_{mask}_control_group\"\n",
    "    ]\n",
    "    exclude_tables = set(exclude_templates)  # Используем set для быстрого поиска\n",
    "\n",
    "    # Получаем список таблиц из базы данных\n",
    "    tables = gp_connector.gp(f\"\"\"--sql\n",
    "        SELECT table_schema, table_name\n",
    "        FROM information_schema.tables\n",
    "        WHERE table_schema = 'ba'\n",
    "            AND table_name LIKE '%%{mask}%%'\n",
    "    ;\"\"\")\n",
    "\n",
    "    print('Кол-во таблиц до фильтрации:', len(tables))\n",
    "\n",
    "    # Фильтруем таблицы, исключая указанные в exclude_tables\n",
    "    filtered_tables = [table for table in tables['table_name'] if table not in exclude_tables]\n",
    "\n",
    "    print('Кол-во таблиц после фильтрации:', len(filtered_tables))\n",
    "\n",
    "    # Удаляем только отфильтрованные таблицы\n",
    "    for table in filtered_tables:\n",
    "        gp_connector.execute_query(f\"\"\"--sql\n",
    "            DROP TABLE ba.{table}\n",
    "        ;\"\"\")\n",
    "        print(f\"Таблица ba.{table} удалена\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb80ead",
   "metadata": {},
   "source": [
    "## metrics_act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "bd1d772b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@log_function_call\n",
    "def metrics_act(gp_connector, mask, type, actn_id, promo_start_date_act, promo_end_date_act, version):\n",
    "    # ──────────────────────────────────────────────────────────\n",
    "    # Подготовка участников по расчету\n",
    "    # ──────────────────────────────────────────────────────────\n",
    "    gp_connector.execute_query(f\"DROP TABLE IF EXISTS ba.tmp_{mask}_{type}_{version}_{actn_id}_contact;\")\n",
    "    gp_connector.execute_query(f\"\"\"\n",
    "    CREATE TABLE ba.tmp_{mask}_{type}_{version}_{actn_id}_contact AS\n",
    "    SELECT is_ca, contact_id \n",
    "    FROM BA.T_ZIG_SPR_CUS_LFL \n",
    "    WHERE actn_id = {actn_id} and is_cus_lfl = 1 and cus_type = 'REGULAR' \n",
    "    ;\"\"\")\n",
    "\n",
    "    # ──────────────────────────────────────────────────────────\n",
    "    # Чеки с покупками товаров в promo_start_date_act \n",
    "    # ──────────────────────────────────────────────────────────\n",
    "    gp_connector.execute_query(f\"DROP TABLE IF EXISTS ba.tmp_{mask}_{type}_{version}_cheques_act;\")\n",
    "    gp_connector.execute_query(f\"\"\"\n",
    "    CREATE TABLE ba.tmp_{mask}_{type}_{version}_cheques_act AS\n",
    "    SELECT \n",
    "        ch.cheque_pk,\n",
    "        ch.contact_id,\n",
    "        SUM(ci.summ_discounted) AS total_summ,\n",
    "        SUM(ci.quantity) AS total_qty\n",
    "    FROM dm.cheque_item ci\n",
    "    JOIN ba.tmp_{mask}_{type}_articles a ON ci.article_id = a.article_id\n",
    "    JOIN dm.cheque ch ON ch.cheque_pk = ci.cheque_pk\n",
    "    WHERE ch.datetime BETWEEN '{promo_start_date_act}'::timestamp\n",
    "    AND '{promo_end_date_act}'::timestamp + INTERVAL '1 day' - INTERVAL '1 second'\n",
    "    AND operation_type_id = 1\n",
    "    GROUP BY 1, 2\n",
    "    ;\"\"\")\n",
    "\n",
    "    # ──────────────────────────────────────────────────────────\n",
    "    # Чеки с покупками товаров в promo_start_date_act по клиентам\n",
    "    # ──────────────────────────────────────────────────────────\n",
    "    gp_connector.execute_query(f\"DROP TABLE IF EXISTS ba.tmp_{mask}_{type}_{version}_cheques_act_contacts;\")\n",
    "    gp_connector.execute_query(f\"\"\"\n",
    "    CREATE TABLE ba.tmp_{mask}_{type}_{version}_cheques_act_contacts AS\n",
    "    SELECT\n",
    "        c.contact_id,\n",
    "        c.is_ca,\n",
    "        ci.cheque_pk,\n",
    "        ci.total_summ,\n",
    "        ci.total_qty\n",
    "    FROM ba.tmp_{mask}_{type}_{version}_cheques_act ci\n",
    "    JOIN ba.tmp_{mask}_{type}_{version}_{actn_id}_contact c ON ci.contact_id = c.contact_id\n",
    "    ;\"\"\")\n",
    "\n",
    "    # ──────────────────────────────────────────────────────────\n",
    "    # Расчет итоговых показателей в promo_start_date_act по ЦА/КГ\n",
    "    # ──────────────────────────────────────────────────────────\n",
    "    gp_connector.execute_query(f\"DROP TABLE IF EXISTS ba.vt_{mask}_{type}_{version}_total_metrics_act;\")\n",
    "    gp_connector.execute_query(f\"\"\"\n",
    "    CREATE TABLE ba.vt_{mask}_{type}_{version}_total_metrics_act AS\n",
    "    SELECT \n",
    "        is_ca,\n",
    "        COUNT(DISTINCT cheque_pk)::NUMERIC / NULLIF(COUNT(DISTINCT contact_id), 0) AS visits_per_client_1,\n",
    "        SUM(total_summ) / NULLIF(COUNT(DISTINCT contact_id), 0) AS sales_per_client_rub_2,\n",
    "        SUM(total_qty) / NULLIF(COUNT(DISTINCT contact_id), 0) AS qty_per_client_3, \n",
    "        (SUM(total_summ) / NULLIF(COUNT(DISTINCT contact_id), 0)) / (SUM(total_qty) / NULLIF(COUNT(DISTINCT contact_id), 0)) AS cost_per_piece_4,\n",
    "        SUM(total_summ) / NULLIF(COUNT(DISTINCT cheque_pk), 0) AS avg_receipt_rub_5,\n",
    "        SUM(total_qty) / NULLIF(COUNT(DISTINCT cheque_pk), 0) AS avg_receipt_qty_6,\n",
    "        COUNT(DISTINCT contact_id) AS unique_clients_7\n",
    "    FROM ba.tmp_{mask}_{type}_{version}_cheques_act_contacts\n",
    "    GROUP BY is_ca\n",
    "    ;\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711fc8a0",
   "metadata": {},
   "source": [
    "## metrics_prev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "2920bbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@log_function_call\n",
    "def metrics_prev(gp_connector, mask, type, actn_id, promo_start_date_prev, promo_end_date_prev, version):\n",
    "    # ──────────────────────────────────────────────────────────\n",
    "    # Подготовка участников по расчету\n",
    "    # ──────────────────────────────────────────────────────────\n",
    "    gp_connector.execute_query(f\"DROP TABLE IF EXISTS ba.tmp_{mask}_{type}_{version}_{actn_id}_contact;\")\n",
    "    gp_connector.execute_query(f\"\"\"\n",
    "    CREATE TABLE ba.tmp_{mask}_{type}_{version}_{actn_id}_contact AS\n",
    "    SELECT is_ca, contact_id \n",
    "    FROM BA.T_ZIG_SPR_CUS_LFL \n",
    "    WHERE actn_id = {actn_id} and is_cus_lfl = 1 and cus_type = 'REGULAR' \n",
    "    ;\"\"\")\n",
    "\n",
    "    # ──────────────────────────────────────────────────────────\n",
    "    # Чеки с покупками товаров в promo_start_date_prev \n",
    "    # ──────────────────────────────────────────────────────────\n",
    "    gp_connector.execute_query(f\"DROP TABLE IF EXISTS ba.tmp_{mask}_{type}_{version}_cheques_prev;\")\n",
    "    gp_connector.execute_query(f\"\"\"\n",
    "    CREATE TABLE ba.tmp_{mask}_{type}_{version}_cheques_prev AS\n",
    "    SELECT \n",
    "        ch.cheque_pk,\n",
    "        ch.contact_id,\n",
    "        SUM(ci.summ_discounted) AS total_summ,\n",
    "        SUM(ci.quantity) AS total_qty\n",
    "    FROM dm.cheque_item ci\n",
    "    JOIN ba.tmp_{mask}_{type}_articles a ON ci.article_id = a.article_id\n",
    "    JOIN dm.cheque ch ON ch.cheque_pk = ci.cheque_pk\n",
    "    WHERE ch.datetime BETWEEN '{promo_start_date_prev}'::timestamp\n",
    "    AND '{promo_end_date_prev}'::timestamp + INTERVAL '1 day' - INTERVAL '1 second'\n",
    "    AND operation_type_id = 1\n",
    "    GROUP BY 1, 2\n",
    "    ;\"\"\")\n",
    "\n",
    "    # ──────────────────────────────────────────────────────────\n",
    "    # Чеки с покупками товаров в promo_start_date_prev по клиентам\n",
    "    # ──────────────────────────────────────────────────────────\n",
    "    gp_connector.execute_query(f\"DROP TABLE IF EXISTS ba.tmp_{mask}_{type}_{version}_cheques_prev_contacts;\")\n",
    "    gp_connector.execute_query(f\"\"\"\n",
    "    CREATE TABLE ba.tmp_{mask}_{type}_{version}_cheques_prev_contacts AS\n",
    "    SELECT\n",
    "        c.contact_id,\n",
    "        c.is_ca,\n",
    "        ci.cheque_pk,\n",
    "        ci.total_summ,\n",
    "        ci.total_qty\n",
    "    FROM ba.tmp_{mask}_{type}_{version}_cheques_prev ci\n",
    "    JOIN ba.tmp_{mask}_{type}_{version}_{actn_id}_contact c ON ci.contact_id = c.contact_id\n",
    "    ;\"\"\")\n",
    "\n",
    "    # ──────────────────────────────────────────────────────────\n",
    "    # Расчет итоговых показателей в promo_start_date_prev по ЦА/КГ\n",
    "    # ──────────────────────────────────────────────────────────\n",
    "    gp_connector.execute_query(f\"DROP TABLE IF EXISTS ba.vt_{mask}_{type}_{version}_total_metrics_prev;\")\n",
    "    gp_connector.execute_query(f\"\"\"\n",
    "    CREATE TABLE ba.vt_{mask}_{type}_{version}_total_metrics_prev AS\n",
    "    SELECT \n",
    "        is_ca,\n",
    "        COUNT(DISTINCT cheque_pk)::NUMERIC / NULLIF(COUNT(DISTINCT contact_id), 0) AS visits_per_client_1,\n",
    "        SUM(total_summ) / NULLIF(COUNT(DISTINCT contact_id), 0) AS sales_per_client_rub_2,\n",
    "        SUM(total_qty) / NULLIF(COUNT(DISTINCT contact_id), 0) AS qty_per_client_3, \n",
    "        (SUM(total_summ) / NULLIF(COUNT(DISTINCT contact_id), 0)) / (SUM(total_qty) / NULLIF(COUNT(DISTINCT contact_id), 0)) AS cost_per_piece_4,\n",
    "        SUM(total_summ) / NULLIF(COUNT(DISTINCT cheque_pk), 0) AS avg_receipt_rub_5,\n",
    "        SUM(total_qty) / NULLIF(COUNT(DISTINCT cheque_pk), 0) AS avg_receipt_qty_6,\n",
    "        COUNT(DISTINCT contact_id) AS unique_clients_7\n",
    "    FROM ba.tmp_{mask}_{type}_{version}_cheques_prev_contacts\n",
    "    GROUP BY is_ca\n",
    "    ;\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bfbca3c",
   "metadata": {},
   "source": [
    "## ca_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "9396efd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@log_function_call\n",
    "def ca_metrics(gp_connector, mask, type, version):\n",
    "    # Загружаем \"До\" только для ЦА\n",
    "    df_before_ca = gp_connector.gp(f\"\"\"\n",
    "        select * from ba.vt_{mask}_{type}_{version}_total_metrics_prev\n",
    "        where is_ca = 1;\n",
    "    \"\"\")\n",
    "    df_before_ca[\"period\"] = \"До\"\n",
    "\n",
    "    # Загружаем \"Акционный\" только для ЦА\n",
    "    df_act_ca = gp_connector.gp(f\"\"\"\n",
    "        select * from ba.vt_{mask}_{type}_{version}_total_metrics_act\n",
    "        where is_ca = 1;\n",
    "    \"\"\")\n",
    "    df_act_ca[\"period\"] = \"Акционный\"\n",
    "\n",
    "    # Поворачиваем\n",
    "    df_ca = pd.concat([df_before_ca, df_act_ca])\n",
    "    df_ca = df_ca.set_index(\"period\").transpose()\n",
    "    df_ca = df_ca[[\"Акционный\", \"До\"]]   \n",
    "\n",
    "    return df_ca"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3e2b84",
   "metadata": {},
   "source": [
    "## kg_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "fb6d2003",
   "metadata": {},
   "outputs": [],
   "source": [
    "@log_function_call\n",
    "def kg_metrics(gp_connector, mask, type, version):\n",
    "    # Загружаем \"До\" только для КГ\n",
    "    df_before_kg = gp_connector.gp(f\"\"\"\n",
    "        select * from ba.vt_{mask}_{type}_{version}_total_metrics_prev\n",
    "        where is_ca = 0;\n",
    "    \"\"\")\n",
    "    df_before_kg[\"period\"] = \"До\"\n",
    "\n",
    "    # Загружаем \"Акционный\" только для КГ\n",
    "    df_act_kg = gp_connector.gp(f\"\"\"\n",
    "        select * from ba.vt_{mask}_{type}_{version}_total_metrics_act\n",
    "        where is_ca = 0;\n",
    "    \"\"\")\n",
    "    df_act_kg[\"period\"] = \"Акционный\"\n",
    "\n",
    "    # Поворачиваем\n",
    "    df_kg = pd.concat([df_before_kg, df_act_kg])\n",
    "    df_kg = df_kg.set_index(\"period\").transpose()\n",
    "    df_kg = df_kg[[\"Акционный\", \"До\"]]   # порядок колонок\n",
    "\n",
    "    return df_kg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cfcaaef",
   "metadata": {},
   "source": [
    "## bonuses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "1fb2c310",
   "metadata": {},
   "outputs": [],
   "source": [
    "@log_function_call\n",
    "def bonuses(gp_connector, mask, in_code_ruls, promo_start_date_act, promo_end_date_act):\n",
    "    bon = gp_connector.gp(f\"\"\"\n",
    "    SELECT\n",
    "        sum(addition_point)/100.0   AS add_points\n",
    "    FROM \n",
    "        dm.transaction_rule t\n",
    "    WHERE \n",
    "        rule_code in ('{in_code_ruls}')\n",
    "        and t.created_on between '{promo_start_date_act}':: timestamp and '{promo_end_date_act}'::timestamp + interval '1' day - interval '1' second\n",
    "    \"\"\")\n",
    "    return bon "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0c4cc0",
   "metadata": {},
   "source": [
    "## unique_clients_ca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "87e2d7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "@log_function_call\n",
    "def unique_clients_ca(gp_connector, mask, actn_id):\n",
    "    unique_ca = gp_connector.gp(f\"\"\"\n",
    "    select count(distinct contact_id)\n",
    "    from BA.T_ZIG_SPR_CUS_LFL \n",
    "    where actn_id = {actn_id} and is_cus_lfl = 1 and cus_type = 'REGULAR' and is_ca = 1\n",
    "    \"\"\")\n",
    "    return unique_ca"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34aff3bd",
   "metadata": {},
   "source": [
    "## unique_clients_kg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "a5ad8f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@log_function_call\n",
    "def unique_clients_kg(gp_connector, mask, actn_id):\n",
    "    unique_kg = gp_connector.gp(f\"\"\"\n",
    "    select count(distinct contact_id)\n",
    "    from BA.T_ZIG_SPR_CUS_LFL \n",
    "    where actn_id = {actn_id} and is_cus_lfl = 1 and cus_type = 'REGULAR' and is_ca = 0\n",
    "    \"\"\")\n",
    "    return unique_kg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6026bad6",
   "metadata": {},
   "source": [
    "## loading_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "8ee043a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "@log_function_call\n",
    "def loading_report(gp_connector, promo_start_date_act, promo_end_date_act, actn_name):\n",
    "    #file = 'Шаблон_Расчет эффекта.xlsx'\n",
    "\n",
    "    dt_start = pd.to_datetime(promo_start_date_act)\n",
    "    dt_end   = pd.to_datetime(promo_end_date_act)\n",
    "    actn_length = int((dt_end - dt_start + pd.Timedelta(days=1)).days)\n",
    "\n",
    "    safe_actn_name = actn_name.replace(\"'\", \"''\")\n",
    "    ### Формат-Регион-Тип клиента (доп.РТО)\n",
    "    df_frmt_region_type = gp_connector.gp(f\"\"\"\t--sql\n",
    "    WITH frmt_region_cus_type_metrics AS (\n",
    "    SELECT\n",
    "    frmt_id,\n",
    "    region_id,\n",
    "    cus_type,\n",
    "    is_ca,\n",
    "    is_cus_lfl,\n",
    "    contact_id,\n",
    "        /* Средние траты на 1 клиента в неделю до / вовремя акции */\n",
    "        SUM(CASE WHEN actn_period = 1 THEN opsum_wo_nds /\n",
    "                    NULLIF(cnt_day_wo_cross::float, 0) * 7 END) AS spend_prev,\n",
    "        SUM(CASE WHEN actn_period = 2 THEN opsum_wo_nds /\n",
    "                    NULLIF(cnt_day_wo_cross::float, 0) * 7 END) AS spend_actn,\n",
    "\n",
    "        /* Средние траты без акц-товаров */\n",
    "        SUM(CASE WHEN actn_period = 1 THEN (opsum_wo_nds - COALESCE(opsum_wo_nds_art_actn, 0)) /\n",
    "                    NULLIF(cnt_day_wo_cross::float, 0) * 7 END) AS spend_wo_art_actn_prev,\n",
    "        SUM(CASE WHEN actn_period = 2 THEN (opsum_wo_nds - COALESCE(opsum_wo_nds_art_actn, 0)) /\n",
    "                    NULLIF(cnt_day_wo_cross::float, 0) * 7 END) AS spend_wo_art_actn_actn,\n",
    "\n",
    "        /* Частота */\n",
    "        SUM(CASE WHEN actn_period = 1 THEN cnt_trn /\n",
    "                    NULLIF(cnt_day_wo_cross::float, 0) * 7 END) /\n",
    "        COUNT(DISTINCT CASE WHEN actn_period = 1 THEN contact_id END) AS frq_prev,\n",
    "\n",
    "        SUM(CASE WHEN actn_period = 2 THEN cnt_trn /\n",
    "                    NULLIF(cnt_day_wo_cross::float, 0) * 7 END) /\n",
    "        COUNT(DISTINCT CASE WHEN actn_period = 2 THEN contact_id END) AS frq_actn,\n",
    "\n",
    "        /* Сумма / кол-во транзакций (для среднего чека) */\n",
    "        SUM(CASE WHEN actn_period = 1 THEN opsum_wo_nds /\n",
    "                    NULLIF(cnt_day_wo_cross::float, 0) * 7 ELSE 0 END) AS opsum_wo_nds_week_prev,\n",
    "        SUM(CASE WHEN actn_period = 2 THEN opsum_wo_nds /\n",
    "                    NULLIF(cnt_day_wo_cross::float, 0) * 7 ELSE 0 END) AS opsum_wo_nds_week_actn,\n",
    "        SUM(CASE WHEN actn_period = 1 THEN cnt_trn /\n",
    "                    NULLIF(cnt_day_wo_cross::float, 0) * 7 ELSE 0 END) AS cnt_trn_week_prev,\n",
    "        SUM(CASE WHEN actn_period = 2 THEN cnt_trn /\n",
    "                    NULLIF(cnt_day_wo_cross::float, 0) * 7 ELSE 0 END) AS cnt_trn_week_actn,\n",
    "\n",
    "        /* Маржа (на 1 клиента) */\n",
    "        SUM(CASE WHEN actn_period = 1 THEN (gross_margin_wo_nds_wo_logist * 0.966) /\n",
    "                    NULLIF(cnt_day_wo_cross::float, 0) * 7 END) AS margin_prev,\n",
    "        SUM(CASE WHEN actn_period = 2 THEN (gross_margin_wo_nds_wo_logist * 0.966) /\n",
    "                    NULLIF(cnt_day_wo_cross::float, 0) * 7 END) AS margin_actn,\n",
    "\n",
    "        /* Маржа без акц-товаров */\n",
    "        SUM(CASE WHEN actn_period = 1 THEN ((gross_margin_wo_nds_wo_logist -\n",
    "                    COALESCE(gross_margin_wo_nds_wo_logist_art_actn, 0)) * 0.966) /\n",
    "                    NULLIF(cnt_day_wo_cross::float, 0) * 7 END) AS margin_wo_art_actn_prev,\n",
    "        SUM(CASE WHEN actn_period = 2 THEN ((gross_margin_wo_nds_wo_logist -\n",
    "                    COALESCE(gross_margin_wo_nds_wo_logist_art_actn, 0)) * 0.966) /\n",
    "                    NULLIF(cnt_day_wo_cross::float, 0) * 7 END) AS margin_wo_art_actn_actn,\n",
    "\n",
    "        -- Скидки\n",
    "        SUM(CASE WHEN actn_period = 1 THEN disc END) AS disc_prev,\n",
    "        SUM(CASE WHEN actn_period = 2 THEN disc END) AS disc_actn,\n",
    "\n",
    "        -- Макс. число клиентов (ЦА)\n",
    "        MAX(cnt_cus_total) AS cnt_cus_total\n",
    "    FROM ba.t_zig_actn_margin\n",
    "    WHERE\n",
    "        actn_name = '{actn_name}'\n",
    "        AND stat_test = 1\n",
    "    GROUP BY 1,2,3,4,5,6\n",
    "    )\n",
    "    SELECT\n",
    "    w.frmt,\n",
    "    w.region,\n",
    "    a.cus_type,\n",
    "    a.is_ca,\n",
    "    -- ЦА: cnt_cus_total\n",
    "    MAX(CASE WHEN a.is_ca=1 THEN a.cnt_cus_total END) AS cnt_cus_total,\n",
    "\n",
    "    COUNT(DISTINCT a.contact_id) AS cnt_cus_actn,\n",
    "    COUNT(DISTINCT CASE WHEN a.is_cus_lfl=1 THEN a.contact_id END) AS cnt_cus_lfl,\n",
    "\n",
    "    -- LFL (общие)\n",
    "    AVG(CASE WHEN a.is_cus_lfl=1 THEN spend_prev END) AS lfl_spend_prev,\n",
    "    AVG(CASE WHEN a.is_cus_lfl=1 THEN spend_actn END) AS lfl_spend_actn,\n",
    "\n",
    "    -- REGULAR LFL\n",
    "    AVG(CASE WHEN a.cus_type='REGULAR'  AND a.is_cus_lfl=1 THEN spend_prev END)  AS reg_spend_prev,\n",
    "    AVG(CASE WHEN a.cus_type='REGULAR'  AND a.is_cus_lfl=1 THEN spend_actn END)  AS reg_spend_actn,\n",
    "\n",
    "    -- NEW / RETURNED LFL (акционные траты)\n",
    "    AVG(CASE WHEN a.cus_type='NEW'      AND a.is_cus_lfl=1 THEN spend_actn END)     AS new_spend_actn,\n",
    "    AVG(CASE WHEN a.cus_type='RETURNED' AND a.is_cus_lfl=1 THEN spend_actn END)     AS return_spend_actn,\n",
    "\n",
    "    -- Без акц.товаров\n",
    "    AVG(CASE WHEN a.is_cus_lfl=1 THEN spend_wo_art_actn_actn END)                  AS lfl_spend_wo_art_actn_actn,\n",
    "    AVG(CASE WHEN a.cus_type='REGULAR'  AND a.is_cus_lfl=1 THEN spend_wo_art_actn_prev END)  AS reg_spend_wo_art_actn_prev,\n",
    "    AVG(CASE WHEN a.cus_type='REGULAR'  AND a.is_cus_lfl=1 THEN spend_wo_art_actn_actn END)  AS reg_spend_wo_art_actn_actn,\n",
    "\n",
    "    -- NEW/RETURNED: без акц.товаров (всё во время акции)\n",
    "    AVG(CASE WHEN a.cus_type='NEW'      AND a.is_cus_lfl=1 THEN spend_wo_art_actn_actn END) AS new_spend_wo_art_actn_actn,\n",
    "    AVG(CASE WHEN a.cus_type='RETURNED' AND a.is_cus_lfl=1 THEN spend_wo_art_actn_actn END) AS return_spend_wo_art_actn_actn,\n",
    "\n",
    "    -- Частота покупок (LFL)\n",
    "    AVG(CASE WHEN a.is_cus_lfl=1 THEN frq_actn END) AS lfl_frq_actn,\n",
    "    AVG(CASE WHEN a.cus_type='REGULAR'  AND a.is_cus_lfl=1 THEN frq_prev END) AS reg_frq_prev,\n",
    "    AVG(CASE WHEN a.cus_type='REGULAR'  AND a.is_cus_lfl=1 THEN frq_actn END) AS reg_frq_actn,\n",
    "\n",
    "    -- NEW / RETURNED частота\n",
    "    AVG(CASE WHEN a.cus_type='NEW'      AND a.is_cus_lfl=1 THEN frq_actn END) AS new_frq_actn,\n",
    "    AVG(CASE WHEN a.cus_type='RETURNED' AND a.is_cus_lfl=1 THEN frq_actn END) AS return_frq_actn,\n",
    "\n",
    "    -- Средний чек (LFL)\n",
    "    SUM(CASE WHEN a.is_cus_lfl=1 THEN opsum_wo_nds_week_actn END)\n",
    "    / NULLIF(SUM(CASE WHEN a.is_cus_lfl=1 THEN cnt_trn_week_actn END),0) AS lfl_avg_cheque_actn,\n",
    "    SUM(CASE WHEN a.cus_type='REGULAR' AND a.is_cus_lfl=1 THEN opsum_wo_nds_week_prev END)\n",
    "    / NULLIF(SUM(CASE WHEN a.cus_type='REGULAR' AND a.is_cus_lfl=1 THEN cnt_trn_week_prev END),0) AS reg_avg_cheque_prev,\n",
    "    SUM(CASE WHEN a.cus_type='REGULAR' AND a.is_cus_lfl=1 THEN opsum_wo_nds_week_actn END)\n",
    "    / NULLIF(SUM(CASE WHEN a.cus_type='REGULAR' AND a.is_cus_lfl=1 THEN cnt_trn_week_actn END),0) AS reg_avg_cheque_actn,\n",
    "\n",
    "    -- NEW / RETURNED средний чек (акционный)\n",
    "    SUM(CASE WHEN a.cus_type='NEW'      AND a.is_cus_lfl=1 THEN opsum_wo_nds_week_actn END)\n",
    "    / NULLIF(SUM(CASE WHEN a.cus_type='NEW'      AND a.is_cus_lfl=1 THEN cnt_trn_week_actn END),0) AS new_avg_cheque_actn,\n",
    "    SUM(CASE WHEN a.cus_type='RETURNED' AND a.is_cus_lfl=1 THEN opsum_wo_nds_week_actn END)\n",
    "    / NULLIF(SUM(CASE WHEN a.cus_type='RETURNED' AND a.is_cus_lfl=1 THEN cnt_trn_week_actn END),0) AS return_avg_cheque_actn,\n",
    "\n",
    "    -- Маржа (LFL)\n",
    "    AVG(CASE WHEN a.is_cus_lfl=1 THEN margin_actn END)              AS lfl_margin_actn,\n",
    "    AVG(CASE WHEN a.cus_type='REGULAR'  AND a.is_cus_lfl=1 THEN margin_prev END)  AS reg_margin_prev,\n",
    "    AVG(CASE WHEN a.cus_type='REGULAR'  AND a.is_cus_lfl=1 THEN margin_actn END)  AS reg_margin_actn,\n",
    "\n",
    "    -- NEW / RETURNED маржа (акционная)\n",
    "    AVG(CASE WHEN a.cus_type='NEW'      AND a.is_cus_lfl=1 THEN margin_actn END)  AS new_margin_actn,\n",
    "    AVG(CASE WHEN a.cus_type='RETURNED' AND a.is_cus_lfl=1 THEN margin_actn END)  AS return_margin_actn,\n",
    "\n",
    "    -- Маржа без акц.товаров\n",
    "    AVG(CASE WHEN a.is_cus_lfl=1 THEN margin_wo_art_actn_actn END)                        AS lfl_margin_wo_art_actn_actn,\n",
    "    AVG(CASE WHEN a.cus_type='REGULAR'  AND a.is_cus_lfl=1 THEN margin_wo_art_actn_prev END)  AS reg_margin_wo_art_actn_prev,\n",
    "    AVG(CASE WHEN a.cus_type='REGULAR'  AND a.is_cus_lfl=1 THEN margin_wo_art_actn_actn END)  AS reg_margin_wo_art_actn_actn,\n",
    "\n",
    "    AVG(CASE WHEN a.cus_type='NEW'      AND a.is_cus_lfl=1 THEN margin_wo_art_actn_actn END) AS new_margin_wo_art_actn_actn,\n",
    "    AVG(CASE WHEN a.cus_type='RETURNED' AND a.is_cus_lfl=1 THEN margin_wo_art_actn_actn END) AS return_margin_wo_art_actn_actn,\n",
    "\n",
    "    -- Сумма скидок\n",
    "    SUM(a.disc_prev) AS disc_prev,\n",
    "    SUM(a.disc_actn) AS disc_actn,\n",
    "\n",
    "    -- (Если нужно) суммарные поля для расчёта маржинальности\n",
    "    SUM(spend_prev)  AS opsum_prev,\n",
    "    SUM(spend_actn)  AS opsum_actn,\n",
    "    SUM(margin_prev) AS opsum_margin_prev,\n",
    "    SUM(margin_actn) AS opsum_margin_actn,\n",
    "\n",
    "    -- Оборот (Формат+Регион), только для ЦА\n",
    "    MAX(CASE WHEN a.is_ca=1 THEN f.opsum_frmt_region END) AS opsum_frmt_region\n",
    "    FROM frmt_region_cus_type_metrics a\n",
    "    JOIN (\n",
    "    SELECT DISTINCT frmt_id, frmt, region_id, region\n",
    "    FROM dm.whs\n",
    "    ) w\n",
    "    ON w.frmt_id = a.frmt_id\n",
    "    AND w.region_id = a.region_id\n",
    "    JOIN ba.t_zig_opsum_frmt_region f\n",
    "    ON f.actn_name = '{actn_name}'\n",
    "    AND f.frmt_id = a.frmt_id\n",
    "    AND f.region_id = a.region_id\n",
    "    GROUP BY\n",
    "    w.frmt,\n",
    "    w.region,\n",
    "    a.cus_type,\n",
    "    a.is_ca\n",
    "    ORDER BY\n",
    "    w.frmt,\n",
    "    w.region,\n",
    "    a.cus_type,\n",
    "    a.is_ca\n",
    "    ;\"\"\")\n",
    "\n",
    "    df_frmt_region_type.head(4)\n",
    "    # Объединение ЦА и КГ по frmt и region\n",
    "    def get_incr(df, metric_actn, metric_prev, incr_name):\n",
    "        ca = df.query('is_ca == 1 and cus_type == \"REGULAR\"')[[\"frmt\", \"region\", metric_actn, metric_prev]]\n",
    "        kg = df.query('is_ca == 0 and cus_type == \"REGULAR\"')[[\"frmt\", \"region\", metric_actn, metric_prev]]\n",
    "\n",
    "        ca = ca.rename(columns={metric_actn: metric_actn + '_ca', metric_prev: metric_prev + '_ca'})\n",
    "        kg = kg.rename(columns={metric_actn: metric_actn + '_kg', metric_prev: metric_prev + '_kg'})\n",
    "\n",
    "        merged = ca.merge(kg, on=['frmt', 'region'], how='inner')\n",
    "\n",
    "        merged[incr_name] = (\n",
    "            (merged[metric_actn + '_ca'] / merged[metric_prev + '_ca']) /\n",
    "            (merged[metric_actn + '_kg'] / merged[metric_prev + '_kg']) - 1\n",
    "        )\n",
    "\n",
    "        return merged[['frmt', 'region', incr_name]]\n",
    "\n",
    "    # Считаем все приросты\n",
    "    incr_metrics = [\n",
    "        ('reg_spend_actn', 'reg_spend_prev', 'incr_spend'),\n",
    "        ('reg_frq_actn', 'reg_frq_prev', 'incr_frq'),\n",
    "        ('reg_avg_cheque_actn', 'reg_avg_cheque_prev', 'incr_avg_cheque'),\n",
    "        ('reg_spend_wo_art_actn_actn', 'reg_spend_wo_art_actn_prev', 'incr_wo_art_spend'),\n",
    "        ('reg_margin_actn', 'reg_margin_prev', 'incr_margin'),\n",
    "        ('reg_margin_wo_art_actn_actn', 'reg_margin_wo_art_actn_prev', 'incr_wo_art_margin')\n",
    "    ]\n",
    "\n",
    "    ca_reg = 'is_ca == 1 and cus_type == \"REGULAR\"'\n",
    "    kg_reg = 'is_ca == 0 and cus_type == \"REGULAR\"'\n",
    "\n",
    "    df_incr = df_frmt_region_type[['frmt', 'region']].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "    for metric_actn, metric_prev, incr_name in incr_metrics:\n",
    "        df_temp = get_incr(df_frmt_region_type, metric_actn, metric_prev, incr_name)\n",
    "        df_incr = df_incr.merge(df_temp, on=['frmt', 'region'], how='left')\n",
    "\n",
    "    # Добавляем приросты обратно\n",
    "\n",
    "    df_frmt_region_type_new = df_frmt_region_type.merge(df_incr, on=['frmt', 'region'], how='left')\n",
    "\n",
    "    # Зануляем приросты для КГ\n",
    "    cols_incr = [x[2] for x in incr_metrics]\n",
    "    df_frmt_region_type_new.loc[df_frmt_region_type_new['is_ca'] == 0, cols_incr] = None\n",
    "\n",
    "    # Далее считаем доп.приросты\n",
    "\n",
    "    for incr_col, actn_col, prev_col, new_col in [\n",
    "        ('incr_spend', 'reg_spend_actn', 'lfl_spend_actn', 'add_incr_spend'),\n",
    "        ('incr_frq', 'reg_frq_actn', 'lfl_frq_actn', 'add_incr_frq'),\n",
    "        ('incr_avg_cheque', 'reg_avg_cheque_actn', 'lfl_avg_cheque_actn', 'add_incr_avg_cheque'),\n",
    "        ('incr_wo_art_spend', 'reg_spend_wo_art_actn_actn', 'lfl_spend_wo_art_actn_actn', 'add_incr_wo_art_spend'),\n",
    "        ('incr_margin', 'reg_margin_actn', 'lfl_margin_actn', 'add_incr_margin'),\n",
    "        ('incr_wo_art_margin', 'reg_margin_wo_art_actn_actn', 'lfl_margin_wo_art_actn_actn', 'add_incr_wo_art_margin')]:\n",
    "\n",
    "        df_frmt_region_type_new[new_col] = (\n",
    "            df_frmt_region_type_new[actn_col].combine_first(df_frmt_region_type_new[prev_col])\n",
    "            - df_frmt_region_type_new[actn_col].combine_first(df_frmt_region_type_new[prev_col]) / (df_frmt_region_type_new[incr_col] + 1)\n",
    "        )\n",
    "\n",
    "        # Зануляем для КГ\n",
    "        df_frmt_region_type_new.loc[df_frmt_region_type_new['is_ca'] == 0, new_col] = None\n",
    "\n",
    "    # Расчёт ДОП. РТО и Маржи\n",
    "    for col, add_col in [\n",
    "        ('add_incr_spend', 'add_rto'),\n",
    "        ('add_incr_wo_art_spend', 'add_rto_wo_art_actn'),\n",
    "        ('add_incr_margin', 'add_margin'),\n",
    "        ('add_incr_wo_art_margin', 'add_margin_wo_art')]:\n",
    "\n",
    "        df_frmt_region_type_new[add_col] = (\n",
    "            df_frmt_region_type_new['cnt_cus_actn'] * df_frmt_region_type_new[col] / 7 * actn_length\n",
    "        )\n",
    "\n",
    "    # ДОП.РТО и Маржа по акционным товарам\n",
    "\n",
    "    df_frmt_region_type_new['add_rto_art_actn'] = df_frmt_region_type_new['add_rto'] - df_frmt_region_type_new['add_rto_wo_art_actn']\n",
    "    df_frmt_region_type_new['add_margin_art_actn'] = df_frmt_region_type_new['add_margin'] - df_frmt_region_type_new['add_margin_wo_art']\n",
    "    # Абсолютный прирост числа транзакций за всё время акции\n",
    "    df_frmt_region_type_new['add_cnt_txn'] = (\n",
    "        df_frmt_region_type_new['cnt_cus_actn']      # клиентов, участвовавших в акции\n",
    "        * df_frmt_region_type_new['add_incr_frq']    # доп. транзакций на клиента в неделю\n",
    "        / 7                                          # перевод к 1-му дню\n",
    "        * actn_length                                # × длительность акции (дн.)\n",
    "    )\n",
    "\n",
    "    df_frmt_region_type_new.loc[\n",
    "        df_frmt_region_type_new['is_ca'] == 0,\n",
    "        'add_cnt_txn'\n",
    "    ] = None\n",
    "\n",
    "    df_frmt_region_type_new['impact_rto'] = (\n",
    "    df_frmt_region_type_new['add_rto']\n",
    "    / df_frmt_region_type_new['opsum_frmt_region']\n",
    "    )\n",
    "\n",
    "    global_ca_mask = (df_frmt_region_type_new['is_ca']==1) & (df_frmt_region_type_new['cus_type']=='REGULAR')\n",
    "    df_global_ca = df_frmt_region_type_new[global_ca_mask]\n",
    "\n",
    "    if len(df_global_ca) > 0:\n",
    "        row_ca_reg = df_global_ca.iloc[0]\n",
    "        tmp_incr_avg = row_ca_reg['incr_avg_cheque'] # прирост ср.чека (ЦА vs КГ)\n",
    "        tmp_avg_cheque_a = row_ca_reg['reg_avg_cheque_actn']\n",
    "        tmp_avg_cheque_p = row_ca_reg['reg_avg_cheque_prev']\n",
    "\n",
    "        if tmp_incr_avg is not None and tmp_incr_avg != 0:\n",
    "            # res_4_val = (avg_cheque_actn - avg_cheque_actn/(1+incr)) / avg_cheque_prev\n",
    "            res_4_val = (\n",
    "                tmp_avg_cheque_a\n",
    "                - tmp_avg_cheque_a/(tmp_incr_avg + 1)\n",
    "            ) / tmp_avg_cheque_p\n",
    "        else:\n",
    "            res_4_val = 0.0\n",
    "\n",
    "        tmp_incr_frq = row_ca_reg['incr_frq']  # прирост частоты (ЦА vs КГ)\n",
    "        tmp_frq_actn = row_ca_reg['reg_frq_actn']\n",
    "        tmp_frq_prev = row_ca_reg['reg_frq_prev']\n",
    "\n",
    "        if tmp_incr_frq is not None and tmp_incr_frq != 0:\n",
    "            # res_5_val = (frq_actn - frq_actn/(1+incr_frq)) / frq_prev\n",
    "            res_5_val = (\n",
    "                tmp_frq_actn\n",
    "                - tmp_frq_actn/(tmp_incr_frq + 1)\n",
    "            ) / tmp_frq_prev\n",
    "        else:\n",
    "            res_5_val = 0.0\n",
    "    else:\n",
    "        # Если нет ни одной строки REGULAR & is_ca=1 вообще,\n",
    "        # ставим оба 0 -> влияние на ср.чек/трафик будет 0\n",
    "        res_4_val = 0.0\n",
    "        res_5_val = 0.0\n",
    "\n",
    "\n",
    "    avg_spent = (\n",
    "        (df_frmt_region_type_new['reg_spend_prev'] + df_frmt_region_type_new['reg_spend_actn'])\n",
    "        / 2\n",
    "        / 7\n",
    "    )\n",
    "\n",
    "\n",
    "    # Влияние на РТО (ср.чек)\n",
    "    df_frmt_region_type_new['impact_avg_txn'] = (\n",
    "        df_frmt_region_type_new['add_incr_avg_cheque']\n",
    "        * df_frmt_region_type_new['cnt_cus_actn']\n",
    "        / 7\n",
    "        * actn_length\n",
    "    ) / df_frmt_region_type_new['opsum_frmt_region']\n",
    "\n",
    "    # Влияние на РТО (трафик)\n",
    "    df_frmt_region_type_new['impact_cnt_txn'] = (\n",
    "        df_frmt_region_type_new['add_incr_frq']\n",
    "        * df_frmt_region_type_new['cnt_cus_actn']\n",
    "        / 7\n",
    "        * actn_length\n",
    "    ) / df_frmt_region_type_new['opsum_frmt_region']\n",
    "\n",
    "\n",
    "    df_frmt_region_type_new['margin_ratio_prev'] = (\n",
    "        df_frmt_region_type_new['opsum_margin_prev']\n",
    "        / df_frmt_region_type_new['opsum_prev']\n",
    "    )\n",
    "\n",
    "    df_frmt_region_type_new['margin_ratio_actn'] = (\n",
    "        df_frmt_region_type_new['opsum_margin_actn']\n",
    "        / df_frmt_region_type_new['opsum_actn']\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "    def unify_columns(df, reg_col, new_col, ret_col):\n",
    "        \"\"\"\n",
    "        Склеить 3 колонки (REGULAR, NEW, RETURNED) в одну.\n",
    "        Возвращаем название новой колонки.\n",
    "        \"\"\"\n",
    "        univ_col = reg_col.replace('reg_', '') + '_univ'\n",
    "\n",
    "        df[univ_col] = (\n",
    "            df[reg_col]\n",
    "            .combine_first(df[new_col])\n",
    "            .combine_first(df[ret_col])\n",
    "        )\n",
    "        return univ_col\n",
    "\n",
    "    col_groups = [\n",
    "        ('reg_spend_actn', 'new_spend_actn', 'return_spend_actn', 'reg_spend_actn'),\n",
    "        ('reg_frq_actn', 'new_frq_actn', 'return_frq_actn', 'reg_frq_actn'),\n",
    "        ('reg_avg_cheque_actn','new_avg_cheque_actn','return_avg_cheque_actn','reg_avg_cheque_actn'),\n",
    "        ('reg_margin_actn','new_margin_actn','return_margin_actn','reg_margin_actn'),\n",
    "        ('reg_spend_wo_art_actn_actn','new_spend_wo_art_actn_actn','return_spend_wo_art_actn_actn','reg_spend_wo_art_actn_actn'),\n",
    "        ('reg_margin_wo_art_actn_actn','new_margin_wo_art_actn_actn','return_margin_wo_art_actn_actn','reg_margin_wo_art_actn_actn')\n",
    "    ]\n",
    "\n",
    "    for (reg_col, new_col, ret_col, final_col) in col_groups:\n",
    "        # Проверим, есть ли эти колонки в df (чтобы не упасть)\n",
    "        if all(c in df_frmt_region_type_new.columns for c in [reg_col, new_col, ret_col]):\n",
    "            # 1. Склеиваем\n",
    "            univ_col = unify_columns(df_frmt_region_type_new, reg_col, new_col, ret_col)\n",
    "\n",
    "            # 2. Переименовываем univ_col -> final_col (например, spend_actn_univ -> reg_spend_actn)\n",
    "            # но перед этим удалим final_col, если вдруг был, чтобы не конфликтовать\n",
    "            if final_col in df_frmt_region_type_new.columns:\n",
    "                df_frmt_region_type_new.drop(columns=[final_col], inplace=True)\n",
    "\n",
    "            df_frmt_region_type_new.rename(columns={univ_col: final_col}, inplace=True)\n",
    "\n",
    "            # 3. Удаляем исходные (new_col, ret_col), чтобы не мешались\n",
    "            df_frmt_region_type_new.drop(columns=[new_col, ret_col], inplace=True, errors='ignore')\n",
    "        else:\n",
    "            print(f\"Пропускаем объединение для {reg_col}, {new_col}, {ret_col} — не все колонки найдены в df.\")\n",
    "\n",
    "    cols_for_export = [\n",
    "        'frmt','region','cus_type','is_ca',\n",
    "        'cnt_cus_actn','cnt_cus_lfl',\n",
    "        'reg_spend_prev','reg_spend_actn','incr_spend',\n",
    "        'reg_frq_prev','reg_frq_actn','incr_frq',\n",
    "        'reg_avg_cheque_prev','reg_avg_cheque_actn','incr_avg_cheque',\n",
    "        'add_rto', 'add_cnt_txn', 'add_rto_wo_art_actn','add_rto_art_actn',\n",
    "        'add_margin','add_margin_wo_art','add_margin_art_actn',\n",
    "        'impact_rto','impact_avg_txn','impact_cnt_txn',\n",
    "        'opsum_frmt_region',\n",
    "        'margin_ratio_prev','margin_ratio_actn'\n",
    "    ]\n",
    "\n",
    "    df_frmt_region_cus_exp = df_frmt_region_type_new[cols_for_export].copy()\n",
    "\n",
    "    ind_kg = df_frmt_region_cus_exp.query('is_ca == 0').index\n",
    "    df_frmt_region_cus_exp.loc[ind_kg, [\n",
    "        'add_cnt_txn',\n",
    "        'incr_spend','incr_frq','incr_avg_cheque',\n",
    "        'add_rto','add_rto_wo_art_actn','add_rto_art_actn',\n",
    "        'add_margin','add_margin_wo_art','add_margin_art_actn',\n",
    "        'impact_rto','impact_avg_txn','impact_cnt_txn',\n",
    "        'opsum_frmt_region'\n",
    "    ]] = None\n",
    "\n",
    "\n",
    "    df_frmt_region_cus_exp['is_ca'].replace({0:'КГ',1:'ЦА'}, inplace=True)\n",
    "\n",
    "\n",
    "    df_frmt_region_cus_exp = df_frmt_region_cus_exp.set_index(\n",
    "        ['frmt','region','cus_type','is_ca']\n",
    "    ).transpose()\n",
    "    ### Сводная Тотал\n",
    "    df_total = gp_connector.gp(f\"\"\"\t--sql\n",
    "    with frmt_region_cus_type_metrics as (\n",
    "        select\n",
    "            frmt_id,\n",
    "            region_id,\n",
    "            cus_type,\n",
    "            is_ca,\n",
    "            is_cus_lfl,\n",
    "            contact_id,\n",
    "            sum(case when actn_period = 1 then opsum_wo_nds / cnt_day_wo_cross::float * 7 end)                          as spend_prev,\n",
    "            sum(case when actn_period = 2 then opsum_wo_nds / cnt_day_wo_cross::float * 7 end)                          as spend_actn,\n",
    "            sum(case when actn_period = 1 then (opsum_wo_nds - coalesce(opsum_wo_nds_art_actn, 0)) / cnt_day_wo_cross::float * 7 end) as spend_wo_art_actn_prev,\n",
    "            sum(case when actn_period = 2 then (opsum_wo_nds - coalesce(opsum_wo_nds_art_actn, 0)) / cnt_day_wo_cross::float * 7 end) as spend_wo_art_actn_actn,\n",
    "            sum(case when actn_period = 1 then cnt_trn / cnt_day_wo_cross::float * 7 end) / \n",
    "            count(distinct(case when actn_period = 1 then contact_id end)) \t\t\t\t                                as frq_prev,\n",
    "            sum(case when actn_period = 2 then cnt_trn / cnt_day_wo_cross::float * 7 end) / \n",
    "            count(distinct(case when actn_period = 2 then contact_id end)) \t\t\t\t                                as frq_actn,\n",
    "            sum(case when actn_period = 1 then opsum_wo_nds / cnt_day_wo_cross::float * 7 else 0 end)                   as opsum_wo_nds_week_prev,\n",
    "            sum(case when actn_period = 2 then opsum_wo_nds / cnt_day_wo_cross::float * 7 else 0 end)                   as opsum_wo_nds_week_actn,\n",
    "            sum(case when actn_period = 1 then cnt_trn / cnt_day_wo_cross::float * 7 else 0 end)                        as cnt_trn_week_prev,\n",
    "            sum(case when actn_period = 2 then cnt_trn / cnt_day_wo_cross::float * 7 else 0 end)                        as cnt_trn_week_actn,\n",
    "            sum(case when actn_period = 1 then (gross_margin_wo_nds_wo_logist*0.966) / cnt_day_wo_cross::float * 7 end) as margin_prev,\n",
    "            sum(case when actn_period = 2 then (gross_margin_wo_nds_wo_logist*0.966) / cnt_day_wo_cross::float * 7 end) as margin_actn,\n",
    "            sum(case when actn_period = 1 then ((gross_margin_wo_nds_wo_logist - \n",
    "                            coalesce(gross_margin_wo_nds_wo_logist_art_actn, 0)) *0.966) / cnt_day_wo_cross::float * 7 end) as margin_wo_art_actn_prev,\n",
    "            sum(case when actn_period = 2 then ((gross_margin_wo_nds_wo_logist - \n",
    "                            coalesce(gross_margin_wo_nds_wo_logist_art_actn, 0)) *0.966) / cnt_day_wo_cross::float * 7 end) as margin_wo_art_actn_actn,\n",
    "            sum(case when actn_period = 1 then disc end)                                                                as disc_prev,\n",
    "            sum(case when actn_period = 2 then disc end)                                                                as disc_actn,\n",
    "            max(cnt_cus_total)                                                                                          as cnt_cus_total\n",
    "        from ba.t_zig_actn_margin\n",
    "        where\n",
    "            actn_name = '{actn_name}'\n",
    "            and stat_test = 1\n",
    "        group by 1,2,3,4,5,6\n",
    "        ), opsum_total as (\n",
    "        select sum(opsum_frmt_region) as opsum_frmt_region\n",
    "        from ba.t_zig_opsum_frmt_region\n",
    "        where actn_name = '{actn_name}'\n",
    "        )\n",
    "    select\n",
    "        a.is_ca,\n",
    "        max(case when a.is_ca = 1 then cnt_cus_total end)                                                   as cnt_cus_total,\n",
    "        count(distinct a.contact_id)                                                                        as cnt_cus_actn,\n",
    "        count(distinct case when a.is_cus_lfl = 1 then a.contact_id end)                                    as cnt_cus_lfl,\n",
    "        avg(case when a.cus_type = 'REGULAR' and a.is_cus_lfl = 1 then spend_prev end)                      as reg_spend_prev,\n",
    "        avg(case when a.cus_type = 'REGULAR' and a.is_cus_lfl = 1 then spend_actn end)                      as reg_spend_actn,\n",
    "        avg(case when a.cus_type = 'REGULAR' and a.is_cus_lfl = 1 then frq_prev end)                        as reg_frq_prev,\n",
    "        avg(case when a.cus_type = 'REGULAR' and a.is_cus_lfl = 1 then frq_actn end)                        as reg_frq_actn,\n",
    "        sum(case when a.cus_type = 'REGULAR' and a.is_cus_lfl = 1 then opsum_wo_nds_week_prev end) /\n",
    "        sum(case when a.cus_type = 'REGULAR' and a.is_cus_lfl = 1 then cnt_trn_week_prev end)               as reg_avg_cheque_prev,\n",
    "        sum(case when a.cus_type = 'REGULAR' and a.is_cus_lfl = 1 then opsum_wo_nds_week_actn end) /\n",
    "        sum(case when a.cus_type = 'REGULAR' and a.is_cus_lfl = 1 then cnt_trn_week_actn end)               as reg_avg_cheque_actn,\n",
    "        sum(case when a.is_cus_lfl = 1 then opsum_wo_nds_week_actn end) /\n",
    "        avg(case when a.cus_type = 'REGULAR' and a.is_cus_lfl = 1 then margin_prev end)                     as reg_margin_prev,\n",
    "        avg(case when a.cus_type = 'REGULAR' and a.is_cus_lfl = 1 then margin_actn end)                     as reg_margin_actn,\n",
    "        sum(disc_prev)                                                                                      as disc_prev,\n",
    "        sum(disc_actn)                                                                                      as disc_actn,\n",
    "        sum(spend_prev)                                                                                     as opsum_prev,\n",
    "        sum(spend_actn)                                                                                     as opsum_actn,\n",
    "        sum(margin_prev)                                                                                    as opsum_margin_prev,\n",
    "        sum(margin_actn)                                                                                    as opsum_margin_actn,\n",
    "        max(case when a.is_ca = 1 then f.opsum_frmt_region end)                                             as opsum_frmt_region\n",
    "    from frmt_region_cus_type_metrics a\n",
    "    join (select distinct frmt_id, frmt, region_id, region from dm.whs) w on w.frmt_id = a.frmt_id and w.region_id = a.region_id\n",
    "    join opsum_total f on 1=1\n",
    "    group by 1\n",
    "    order by 1\n",
    "    ;\"\"\")\n",
    "\n",
    "    df_total.head(4)\n",
    "    oborot_ap = gp_connector.gp(f\"\"\"\n",
    "    with stat as (\n",
    "    select distinct frmt_id, region_id\n",
    "    from ba.t_zig_actn_margin\n",
    "    where 1=1\n",
    "    and actn_name = '{actn_name}'\n",
    "    and stat_test = 1\n",
    "    )\n",
    "\n",
    "    select sum(opsum_frmt_region) as opsum_frmt_region\n",
    "    from ba.t_zig_opsum_frmt_region r\n",
    "    join stat s on s.frmt_id = r.frmt_id and s.region_id = r.region_id\n",
    "    where actn_name = '{actn_name}'\n",
    "    \"\"\")['opsum_frmt_region'][0]\n",
    "\n",
    "    df_total['opsum_frmt_region'] = oborot_ap\n",
    "\n",
    "    # Зануляем оборот АП для КГ\n",
    "    ind = df_total.query('is_ca == 0').index\n",
    "    df_total.loc[ind, ['opsum_frmt_region']] = None\n",
    "    # Чистый прирост Трат\n",
    "    df_11 = df_total.query('is_ca == 1')['reg_spend_actn'] / df_total.query('is_ca == 1')['reg_spend_prev']\n",
    "    df_12 = df_total.query('is_ca == 0')['reg_spend_actn'] / df_total.query('is_ca == 0')['reg_spend_prev']\n",
    "    res_1 = df_11.reset_index(drop=True) / df_12.reset_index(drop=True) - 1\n",
    "    res_1.name = 'incr_spend'\n",
    "\n",
    "    # Чистый прирост Частоты\n",
    "    df_21 = df_total.query('is_ca == 1')['reg_frq_actn'] / df_total.query('is_ca == 1')['reg_frq_prev']\n",
    "    df_22 = df_total.query('is_ca == 0')['reg_frq_actn'] / df_total.query('is_ca == 0')['reg_frq_prev']\n",
    "    res_2 = df_21.reset_index(drop=True) / df_22.reset_index(drop=True) - 1\n",
    "    res_2.name = 'incr_frq'\n",
    "\n",
    "    # Чистый прирост Ср.чек\n",
    "    df_31 = df_total.query('is_ca == 1')['reg_avg_cheque_actn'] / df_total.query('is_ca == 1')['reg_avg_cheque_prev']\n",
    "    df_32 = df_total.query('is_ca == 0')['reg_avg_cheque_actn'] / df_total.query('is_ca == 0')['reg_avg_cheque_prev']\n",
    "    res_3 = df_31.reset_index(drop=True) / df_32.reset_index(drop=True) - 1\n",
    "    res_3.name = 'incr_avg_cheque'\n",
    "    df_incr = pd.concat([res_1, res_2], axis=1)\n",
    "    df_incr = pd.concat([df_incr, res_3], axis=1)\n",
    "    df_incr\n",
    "    # Добавляю приросты в Таблицу\n",
    "    df_total = df_total.merge(df_incr, how='cross')\n",
    "    # Добавляю Доп.РТО и Доп.маржу в Таблицу\n",
    "    add_rto = df_frmt_region_type_new.groupby('is_ca')[['add_rto', 'add_rto_wo_art_actn', 'add_rto_art_actn', 'add_margin', 'add_margin_wo_art', 'add_margin_art_actn', 'add_cnt_txn']].sum()\n",
    "    df_total = pd.concat([df_total, add_rto], axis=1)\n",
    "\n",
    "    avg_spent = (df_total.reg_spend_actn + df_total.reg_spend_prev) / 2 / 7\n",
    "\n",
    "    # Рассчитываю влияние на РТО\n",
    "    df_total['impact_rto'] = df_total['add_rto'] / df_total['opsum_frmt_region']\n",
    "\n",
    "    # Рассчитываю влияние на Ср.чек\n",
    "    #res_4 = (df_total.query('is_ca == 1')['reg_spend_actn'] - df_total.query('is_ca == 1')['reg_spend_actn'] / (res_3.values + 1)) / df_total.query('is_ca == 1')['reg_spend_prev']\n",
    "    res_4 = (df_total.query('is_ca == 1')['reg_avg_cheque_actn'] - df_total.query('is_ca == 1')['reg_avg_cheque_actn'] / (res_3.values + 1)) / df_total.query('is_ca == 1')['reg_avg_cheque_prev']\n",
    "    df_total['impact_avg_txn'] = (avg_spent * df_total.cnt_cus_actn * actn_length * res_4.values) / df_total.opsum_frmt_region\n",
    "\n",
    "    # Рассчитываю влияние на Трафик\n",
    "    res_5 = (df_total.query('is_ca == 1')['reg_frq_actn'] - df_total.query('is_ca == 1')['reg_frq_actn'] / (res_2.values + 1)) / df_total.query('is_ca == 1')['reg_frq_prev']\n",
    "    df_total['impact_cnt_txn'] = (avg_spent * df_total.cnt_cus_actn * actn_length * res_5.values) / df_total.opsum_frmt_region\n",
    "\n",
    "    # Маржинальность\n",
    "    df_total['margin_ratio_prev'] = df_total.opsum_margin_prev / df_total.opsum_prev\n",
    "    df_total['margin_ratio_actn'] = df_total.opsum_margin_actn / df_total.opsum_actn\n",
    "    df_total_exp = df_total[[\n",
    "        'is_ca', 'cnt_cus_total', 'cnt_cus_actn', 'cnt_cus_lfl',\n",
    "        'reg_spend_prev', 'reg_spend_actn', 'incr_spend', \n",
    "        'reg_frq_prev', 'reg_frq_actn', 'incr_frq',\n",
    "        'reg_avg_cheque_prev', 'reg_avg_cheque_actn', 'incr_avg_cheque',\n",
    "        'add_rto', 'add_cnt_txn', 'add_rto_wo_art_actn', 'add_rto_art_actn',\n",
    "        'add_margin', 'add_margin_wo_art', 'add_margin_art_actn',\n",
    "        'impact_rto', 'impact_avg_txn', 'impact_cnt_txn',\n",
    "        'opsum_frmt_region', 'margin_ratio_prev', 'margin_ratio_actn'\n",
    "    ]]\n",
    "    # Зануляю приросты для КГ\n",
    "    # Зануляю приросты для КГ\n",
    "    ind = df_total_exp.query('is_ca == 0').index\n",
    "    df_total_exp.loc[ind, ['add_cnt_txn', 'incr_spend', 'incr_frq', 'incr_avg_cheque', 'add_rto', 'add_rto_wo_art_actn', 'add_rto_art_actn', 'add_margin',\n",
    "                'add_margin_wo_art', 'add_margin_art_actn', 'impact_rto', 'impact_avg_txn', 'impact_cnt_txn', 'opsum_frmt_region']] = None\n",
    "\n",
    "    df_total_exp['is_ca'].replace({0:'КГ', 1:'ЦА'}, inplace=True)\n",
    "    df_total_exp = df_total_exp.set_index('is_ca').transpose()\n",
    "    df_total_exp\n",
    "    \n",
    "    # 1) Формируем компактный блок для v1: Доп.РТО, Доп.Маржа, Маржинальность (во время)\n",
    "    need_rows = ['add_rto', 'add_margin', 'margin_ratio_actn']\n",
    "    exist_rows = [r for r in need_rows if r in df_total_exp.index]\n",
    "\n",
    "    compact = df_total_exp.loc[exist_rows].copy()\n",
    "\n",
    "    # Добиваем до 6 строк под шаблон B6:C11\n",
    "    while compact.shape[0] < 6:\n",
    "        compact.loc[f'_pad_{compact.shape[0]+1}'] = [None, None]\n",
    "\n",
    "    # Возвращаем ТОЛЬКО компактный блок 6×2 (ЦА/КГ в двух столбцах)\n",
    "    result = {\n",
    "        \"compact_block\": compact.values,\n",
    "        \"add_rto\": {},\n",
    "        \"add_margin\": {},\n",
    "        \"margin_ratio_actn\": {},\n",
    "    }\n",
    "\n",
    "    def _row_to_dict(row_name):\n",
    "        if row_name in df_total_exp.index:\n",
    "            row = df_total_exp.loc[row_name]\n",
    "            return {\n",
    "                col: (None if pd.isna(val) else float(val))\n",
    "                for col, val in row.items()\n",
    "            }\n",
    "        return {}\n",
    "\n",
    "    result[\"add_rto\"] = _row_to_dict(\"add_rto\")\n",
    "    result[\"add_margin\"] = _row_to_dict(\"add_margin\")\n",
    "    result[\"margin_ratio_actn\"] = _row_to_dict(\"margin_ratio_actn\")\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4da5f56",
   "metadata": {},
   "source": [
    "## pick_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "9da2bfdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _pick_metrics_block(df, rows_wanted=None, n_rows=6):\n",
    "    \"\"\"\n",
    "    df: DataFrame с колонками ['Акционный','До'] и индексом-метриками.\n",
    "    \"\"\"\n",
    "    if rows_wanted is None:\n",
    "        rows_wanted = [\n",
    "            'reg_spend_actn','reg_spend_prev',\n",
    "            'reg_frq_actn','reg_frq_prev',\n",
    "            'reg_avg_cheque_actn','reg_avg_cheque_prev',\n",
    "            'reg_margin_actn','reg_margin_prev',\n",
    "            'cnt_cus_actn','cnt_cus_lfl'\n",
    "        ]\n",
    "    rows = [r for r in rows_wanted if r in df.index]\n",
    "\n",
    "    if len(rows) < n_rows:\n",
    "        # добавим первые встречные строки с числовыми значениями\n",
    "        for idx, s in df.iterrows():\n",
    "            if idx in rows:\n",
    "                continue\n",
    "            try:\n",
    "                is_num = pd.api.types.is_numeric_dtype(s.dtype) or pd.api.types.is_float_dtype(s.dtype)\n",
    "            except Exception:\n",
    "                is_num = False\n",
    "            if is_num:\n",
    "                rows.append(idx)\n",
    "                if len(rows) >= n_rows:\n",
    "                    break\n",
    "\n",
    "    block = df.loc[rows[:n_rows], ['Акционный','До']].copy()\n",
    "    while block.shape[0] < n_rows:\n",
    "        block.loc[f'_pad_{block.shape[0]+1}'] = [None, None]\n",
    "    return block.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41e5537",
   "metadata": {},
   "source": [
    "## prepare_v2_v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "54605cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_v2_v3_payload(gp_connector, mask, type, in_code_ruls,\n",
    "                          promo_start_date_act, promo_end_date_act, actn_id,\n",
    "                          version=None):\n",
    "    # Метрики (пробуем с передачей версий, иначе — старый вызов)\n",
    "    try:\n",
    "        if version is not None:\n",
    "            df_ca = ca_metrics(gp_connector, mask, type, version)\n",
    "            df_kg = kg_metrics(gp_connector, mask, type, version)\n",
    "        else:\n",
    "            raise TypeError\n",
    "    except TypeError:\n",
    "        df_ca = ca_metrics(gp_connector, mask, type)\n",
    "        df_kg = kg_metrics(gp_connector, mask, type)\n",
    "\n",
    "    ca_block = _pick_metrics_block(df_ca, n_rows=6)   # 6×2\n",
    "    kg_block = _pick_metrics_block(df_kg, n_rows=6)   # 6×2\n",
    "\n",
    "    # Бонусы — нормализуем список кодов под IN (...)\n",
    "    bon_df = gp_connector.gp(f\"\"\"\n",
    "        SELECT sum(addition_point)/100.0 AS add_points\n",
    "        FROM dm.transaction_rule t\n",
    "        WHERE rule_code IN ('{in_code_ruls}')\n",
    "          AND t.created_on BETWEEN '{promo_start_date_act}'::timestamp\n",
    "                               AND '{promo_end_date_act}'::timestamp + interval '1 day' - interval '1 second'\n",
    "    \"\"\")\n",
    "    bon = float(bon_df.iloc[0, 0]) if not bon_df.empty else 0.0\n",
    "\n",
    "    # Уники (фильтр по is_ca уже есть в самих функциях)\n",
    "    u_ca_df = unique_clients_ca(gp_connector, mask, actn_id)\n",
    "    u_kg_df = unique_clients_kg(gp_connector, mask, actn_id)\n",
    "    uniq_ca = int(u_ca_df.iloc[0, 0]) if not u_ca_df.empty else 0\n",
    "    uniq_kg = int(u_kg_df.iloc[0, 0]) if not u_kg_df.empty else 0\n",
    "\n",
    "    return ca_block, kg_block, bon, uniq_ca, uniq_kg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8950ec51",
   "metadata": {},
   "source": [
    "## edit_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "4a814f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def edit_file_batch(file_name, sheet_name, writes):\n",
    "    \"\"\"\n",
    "    writes: список кортежей (cell_top_left, value, write_index, write_header)\n",
    "    value — 2D-массив/df или скаляр.\n",
    "    \"\"\"\n",
    "    import xlwings as xw\n",
    "    import time, gc\n",
    "\n",
    "    app = None\n",
    "    wb = None\n",
    "    try:\n",
    "        app = xw.App(visible=False, add_book=False)\n",
    "        app.display_alerts = False\n",
    "        app.screen_updating = False\n",
    "\n",
    "        wb = app.books.open(file_name, update_links=False, read_only=False)\n",
    "        sh = wb.sheets[sheet_name]  # бросит KeyError, если листа нет\n",
    "\n",
    "        for cell, value, idx, hdr in writes:\n",
    "            sh.range(cell).options(index=bool(idx), header=bool(hdr)).value = value\n",
    "\n",
    "        wb.save()\n",
    "    finally:\n",
    "        try:\n",
    "            if wb is not None:\n",
    "                wb.close()\n",
    "        except Exception as e:\n",
    "            logging.warning(f\"wb.close() error: {e}\")\n",
    "        try:\n",
    "            if app is not None:\n",
    "                app.quit()\n",
    "        except Exception as e:\n",
    "            logging.warning(f\"app.quit() error: {e}\")\n",
    "        # подчистка COM-прокси\n",
    "        try: del sh\n",
    "        except Exception: pass\n",
    "        try: del wb\n",
    "        except Exception: pass\n",
    "        try: del app\n",
    "        except Exception: pass\n",
    "        gc.collect()\n",
    "        time.sleep(0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2bc7a82",
   "metadata": {},
   "source": [
    "# Функции обработки акций"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "91c9e2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_action(gp_connector, type, version, file_name):\n",
    "\n",
    "    \"\"\"\n",
    "    Обрабатывает одну акцию по уникальной маске.\n",
    "    \"\"\"\n",
    "    # Получаем параметры акции из таблицы helper_action по маске\n",
    "    df_action = gp_connector.gp(f\"\"\"\n",
    "        SELECT mask,\n",
    "        actn_name,\n",
    "        actn_type,\n",
    "        is_processed,\n",
    "        is_kg_needed,\n",
    "        lengthprev,\n",
    "        lengthpost,\n",
    "        promo_start_date_act,\n",
    "        promo_end_date_act,\n",
    "        promo_start_date_prev,\n",
    "        promo_end_date_prev,\n",
    "        type_art_group_level, \n",
    "        art_grp_lvl_name,\n",
    "        code_act,\n",
    "        code_prev,\n",
    "        version,\n",
    "        type, \n",
    "        in_code_ruls\n",
    "    FROM BA.helper_category\n",
    "    WHERE type = '{type}' and version = {version}\n",
    "    \"\"\")\n",
    "    if df_action.empty:\n",
    "        logging.warning(f\"[process_action][type = {type}] Акция не найдена в helper_category.\")\n",
    "        return\n",
    "    mask                  = df_action['mask'].iloc[0]\n",
    "    actn_name             = df_action['actn_name'].iloc[0]\n",
    "    actn_type             = df_action['actn_type'].iloc[0]\n",
    "    lengthprev            = df_action['lengthprev'].iloc[0]\n",
    "    lengthpost            = df_action['lengthpost'].iloc[0]\n",
    "    promo_start_date_act  = str(df_action['promo_start_date_act'].iloc[0])\n",
    "    promo_end_date_act    = str(df_action['promo_end_date_act'].iloc[0])\n",
    "    promo_start_date_prev = str(df_action['promo_start_date_prev'].iloc[0])\n",
    "    promo_end_date_prev   = str(df_action['promo_end_date_prev'].iloc[0])\n",
    "    type_art_group_level  = df_action['type_art_group_level'].iloc[0]\n",
    "    art_grp_lvl_2_name    = df_action['art_grp_lvl_name'].iloc[0]\n",
    "    code_act              = df_action['code_act'].iloc[0]\n",
    "    code_prev             = df_action['code_prev'].iloc[0]\n",
    "    version               = df_action['version'].iloc[0]\n",
    "    type                  = df_action['type'].iloc[0]\n",
    "    in_code_ruls          = df_action['in_code_ruls'].iloc[0]\n",
    "\n",
    "    logging.info(f\"[process_action][type = {type}] Начинаем обработку акции '{actn_name}'.\")\n",
    "\n",
    "    # # Получаем числовой идентификатор акции из таблицы vt_{mask}_spr_actn\n",
    "    # df_spr = gp_connector.gp(f\"\"\"\n",
    "    #     SELECT actn_id,\n",
    "    #         actn_grp,\n",
    "    #         actn_length,\n",
    "    #         date_start,\n",
    "    #         date_end,\n",
    "    #         date_st_pre,\n",
    "    #         date_end_last\n",
    "    #     FROM ba.vt_{mask}_spr_actn\n",
    "    #     WHERE actn_name = '{actn_name}'\n",
    "    # \"\"\")\n",
    "    # if df_spr.empty:\n",
    "    #     logging.warning(f\"[process_action][mask = {mask}] Запись в vt_{mask}_spr_actn не найдена.\")\n",
    "    #     return\n",
    "\n",
    "    # actn_id    = df_spr['actn_id'].iloc[0]\n",
    "    # lengthActn = df_spr['actn_length'].iloc[0]\n",
    "    # DateStart  = str(df_spr['date_start'].iloc[0])\n",
    "    # DateEnd    = str(df_spr['date_end'].iloc[0])\n",
    "    # DateStPre  = str(df_spr['date_st_pre'].iloc[0])\n",
    "    # DateEndLast= str(df_spr['date_end_last'].iloc[0])\n",
    "\n",
    "    # logging.info(f\"[process_action][mask = {mask}] n_KG = {n_KG}. Формируем контрольные группы с n_KG = {n_KG}.\")\n",
    "\n",
    "    # Выполнение всех шагов последовательно\n",
    "    try:\n",
    "        create_whs(gp_connector, mask)\n",
    "        logging.info(\"Шаг 1 (whs) выполнен успешно.\")\n",
    "\n",
    "        create_cus_ruls(gp_connector, mask, art_grp_lvl_2_name, type_art_group_level, promo_start_date_act, promo_end_date_act, actn_name, type, version, code_act, code_prev, promo_start_date_prev, promo_end_date_prev)\n",
    "        logging.info(\"Шаг 2 (cus_ruls) выполнен успешно.\")\n",
    "\n",
    "        n_KG = create_kg(gp_connector, mask, actn_name, art_grp_lvl_2_name, promo_start_date_act, promo_end_date_act, type, code_act, code_prev, promo_start_date_prev, promo_end_date_prev)\n",
    "        logging.info(\"Шаг 3 (kg) выполнен успешно.\")\n",
    "\n",
    "        create_spr_actn(gp_connector, mask, actn_type, actn_name, lengthprev, lengthpost)\n",
    "        logging.info(\"Шаг 4 (spr_actn) выполнен успешно.\")\n",
    "\n",
    "        actn_id = gp_connector.gp(f\"\"\"SELECT Actn_id FROM ba.vt_{mask}_spr_actn WHERE actn_name = '{actn_name}';\"\"\").actn_id[0]\n",
    "        lengthActn = gp_connector.gp(f\"\"\"SELECT Actn_Length FROM ba.vt_{mask}_spr_actn WHERE actn_name = '{actn_name}';\"\"\").actn_length[0]\n",
    "        DateStart = str(gp_connector.gp(f\"\"\"SELECT DATE_START FROM ba.vt_{mask}_spr_actn WHERE actn_name = '{actn_name}';\"\"\").date_start[0])\n",
    "        DateEnd = str(gp_connector.gp(f\"\"\"SELECT DATE_END FROM ba.vt_{mask}_spr_actn WHERE actn_name = '{actn_name}';\"\"\").date_end[0])\n",
    "        DateStPre = str(gp_connector.gp(f\"\"\"SELECT Date_St_Pre FROM ba.vt_{mask}_spr_actn WHERE actn_name = '{actn_name}';\"\"\").date_st_pre[0])\n",
    "        DateEndLast = str(gp_connector.gp(f\"\"\"SELECT Date_End_Last FROM ba.vt_{mask}_spr_actn WHERE actn_name = '{actn_name}';\"\"\").date_end_last[0])\n",
    "\n",
    "        cutoff = create_days(gp_connector, mask, actn_id, DateStPre, DateEndLast)\n",
    "        logging.info(\"Шаг 5 (days) выполнен успешно.\")\n",
    "\n",
    "        create_days_cross(gp_connector, mask, cutoff, actn_id)\n",
    "        logging.info(\"Шаг 6 (days_cross) выполнен успешно.\")\n",
    "\n",
    "        frod(gp_connector, mask)\n",
    "        logging.info(\"Шаг - (frod) выполнен успешно.\")\n",
    "\n",
    "        create_trn_0(gp_connector, mask, actn_id, lengthprev)\n",
    "        logging.info(\"Шаг 7 (create_trn_0) выполнен успешно.\")\n",
    "\n",
    "        create_trn_0_v2(gp_connector, mask, actn_id, lengthActn)\n",
    "        logging.info(\"Шаг 8 (create_trn_0_v2) выполнен успешно.\")\n",
    "\n",
    "        create_agg(gp_connector, mask, DateStart)\n",
    "        logging.info(\"Шаг 9 (create_agg) выполнен успешно.\")\n",
    "\n",
    "        process_clear_and_aggregate(gp_connector, mask)\n",
    "        logging.info(\"Шаг 10 (process_clear_and_aggregate) выполнен успешно.\")\n",
    "\n",
    "        reg_new_returned(gp_connector, mask, promo_start_date_act)\n",
    "        logging.info(\"Шаг 11 (reg_new_returned) выполнен успешно.\")\n",
    "\n",
    "        clear_reg(gp_connector, mask, actn_id, actn_name, lengthprev, lengthActn)\n",
    "        logging.info(\"Шаг 12 (clear_reg) выполнен успешно.\")\n",
    "\n",
    "        dna(gp_connector, mask, lengthActn)\n",
    "        logging.info(\"Шаг 13 (dna) выполнен успешно.\")\n",
    "\n",
    "        kg_for_ca(gp_connector, mask, n_KG)\n",
    "        logging.info(\"Шаг 14 (kg_for_ca) выполнен успешно.\")\n",
    "\n",
    "        cnt_actn(gp_connector, mask, DateStPre, DateStart, DateEnd, actn_id)\n",
    "        logging.info(\"Шаг 14 (cnt_actn) выполнен успешно.\")\n",
    "\n",
    "        dynamic_gr20(gp_connector, mask, actn_id)\n",
    "        logging.info(\"Шаг 16 (dynamic_gr20) выполнен успешно.\")\n",
    "\n",
    "        gr20_transp(gp_connector, mask)\n",
    "        logging.info(\"Шаг 17 (gr20_transp) выполнен успешно.\")\n",
    "\n",
    "        age_and_active_virt(gp_connector, mask)\n",
    "        logging.info(\"Шаг 18 (age_and_active_virt) выполнен успешно.\")\n",
    "\n",
    "        itog(gp_connector, mask, lengthActn)\n",
    "        logging.info(\"Шаг 19 (itog) выполнен успешно.\")\n",
    "\n",
    "        psm(gp_connector, mask, actn_name, actn_id)\n",
    "        logging.info(\"Шаг 20 (psm) выполнен успешно.\")\n",
    "\n",
    "        if version == 1:\n",
    "            margin(gp_connector, mask, actn_name, promo_start_date_act, promo_end_date_act, in_code_ruls, actn_id, DateStart, DateEnd, DateStPre, DateEndLast, lengthprev, lengthpost, lengthActn)\n",
    "            logging.info(\"Шаг 21 (margin) выполнен успешно.\")\n",
    "\n",
    "            oborot_rto(gp_connector, mask, promo_start_date_act, promo_end_date_act, actn_name)\n",
    "            logging.info(\"Шаг 22 (oborot_rto) выполнен успешно.\")\n",
    "\n",
    "            metrics_act(gp_connector, mask, type, actn_id, promo_start_date_act, promo_end_date_act, version)\n",
    "            logging.info(\"Шаг 24 (metrics_act) выполнен успешно.\")\n",
    "\n",
    "            metrics_prev(gp_connector, mask, type, actn_id, promo_start_date_prev, promo_end_date_prev, version)\n",
    "            logging.info(\"Шаг 25 (metrics_prev) выполнен успешно.\")\n",
    "\n",
    "            df_ca = ca_metrics(gp_connector, mask, type, version)\n",
    "            logging.info(\"Шаг 25 (ca_metrics) выполнен успешно.\")\n",
    "\n",
    "            df_kg = kg_metrics(gp_connector, mask, type, version)\n",
    "            logging.info(\"Шаг 25 (kg_metrics) выполнен успешно.\")\n",
    "\n",
    "            bonus_df = bonuses(gp_connector, mask, in_code_ruls, promo_start_date_act, promo_end_date_act)\n",
    "            logging.info(\"Шаг 25 (bonuses) выполнен успешно.\")\n",
    "\n",
    "            uniq_ca_df = unique_clients_ca(gp_connector, mask, actn_id)\n",
    "            logging.info(\"Шаг 25 (unique_clients_ca) выполнен успешно.\")\n",
    "\n",
    "            uniq_kg_df = unique_clients_kg(gp_connector, mask, actn_id)\n",
    "            logging.info(\"Шаг 25 (unique_clients_kg) выполнен успешно.\")\n",
    "\n",
    "            report_payload = loading_report(gp_connector, promo_start_date_act, promo_end_date_act, actn_name)\n",
    "            logging.info(\"Шаг 24 (loading_report) выполнен успешно.\")\n",
    "\n",
    "            ca_block = _pick_metrics_block(df_ca, n_rows=6)\n",
    "            kg_block = _pick_metrics_block(df_kg, n_rows=6)\n",
    "\n",
    "            bonus_value = 0.0\n",
    "            if not bonus_df.empty:\n",
    "                raw_bonus = bonus_df.iloc[0, 0]\n",
    "                bonus_value = 0.0 if pd.isna(raw_bonus) else float(raw_bonus)\n",
    "\n",
    "            uniq_ca = 0\n",
    "            if not uniq_ca_df.empty:\n",
    "                raw_uniq_ca = uniq_ca_df.iloc[0, 0]\n",
    "                uniq_ca = 0 if pd.isna(raw_uniq_ca) else int(raw_uniq_ca)\n",
    "\n",
    "            uniq_kg = 0\n",
    "            if not uniq_kg_df.empty:\n",
    "                raw_uniq_kg = uniq_kg_df.iloc[0, 0]\n",
    "                uniq_kg = 0 if pd.isna(raw_uniq_kg) else int(raw_uniq_kg)\n",
    "\n",
    "            margin_map = report_payload.get(\"margin_ratio_actn\", {}) if isinstance(report_payload, dict) else {}\n",
    "            add_rto_map = report_payload.get(\"add_rto\", {}) if isinstance(report_payload, dict) else {}\n",
    "            add_margin_map = report_payload.get(\"add_margin\", {}) if isinstance(report_payload, dict) else {}\n",
    "\n",
    "            def _to_float_or_none(value):\n",
    "                if value is None or pd.isna(value):\n",
    "                    return None\n",
    "                return float(value)\n",
    "\n",
    "            margin_ca = _to_float_or_none(margin_map.get('ЦА'))\n",
    "            margin_kg = _to_float_or_none(margin_map.get('КГ'))\n",
    "            add_rto_ca = _to_float_or_none(add_rto_map.get('ЦА'))\n",
    "            add_margin_ca = _to_float_or_none(add_margin_map.get('ЦА'))\n",
    "\n",
    "            edit_file_batch(\n",
    "                file_name,\n",
    "                sheet_name=\"ЦА и КГ регулярные на клиента\",\n",
    "                writes=[\n",
    "                    (\"B6\", ca_block, False, False),\n",
    "                    (\"E6\", kg_block, False, False),\n",
    "                    (\"B12\", uniq_ca, False, False),\n",
    "                    (\"E12\", uniq_kg, False, False),\n",
    "                    (\"B13\", margin_ca, False, False),\n",
    "                    (\"E13\", margin_kg, False, False),\n",
    "                    (\"B14\", bonus_value, False, False),\n",
    "                    (\"B15\", add_rto_ca, False, False),\n",
    "                    (\"B16\", add_margin_ca, False, False),\n",
    "                ]\n",
    "            )\n",
    "\n",
    "\n",
    "            delete_tables(gp_connector, mask)\n",
    "            logging.info(\"Шаг 23 (delete_tables) выполнен успешно.\")\n",
    "  \n",
    "        else:\n",
    "            metrics_act(gp_connector, mask, type, actn_id, promo_start_date_act, promo_end_date_act, version)\n",
    "\n",
    "            metrics_prev(gp_connector, mask, type, actn_id, promo_start_date_prev, promo_end_date_prev, version)\n",
    "\n",
    "            ca_block, kg_block, _bonus, uniq_ca, uniq_kg = prepare_v2_v3_payload(\n",
    "                gp_connector, mask, type, in_code_ruls, promo_start_date_act, promo_end_date_act, actn_id, version=version\n",
    "            )\n",
    "            left  = 'B24' if version == 2 else 'B37'\n",
    "            right = 'E24' if version == 2 else 'E37'\n",
    "            uniq_ca_cell = 'B30' if version == 2 else 'B43'\n",
    "            uniq_kg_cell = 'E30' if version == 2 else 'E43'\n",
    "            edit_file_batch(\n",
    "                file_name,\n",
    "                sheet_name=\"ЦА и КГ регулярные на клиента\",\n",
    "                writes=[\n",
    "                    (left,  ca_block, False, False),  # 6×2 ЦА\n",
    "                    (right, kg_block, False, False),  # 6×2 КГ\n",
    "                    (uniq_ca_cell, uniq_ca, False, False),\n",
    "                    (uniq_kg_cell, uniq_kg, False, False),\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            delete_tables(gp_connector, mask)\n",
    "            logging.info(\"Шаг 21 (delete_tables) выполнен успешно.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"[process_action][mask = {mask}] Ошибка при обработке: {e}\")\n",
    "        raise e\n",
    "\n",
    "    logging.info(f\"[process_action][mask = {mask}] Обработка акции '{actn_name}' завершена успешно.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95929bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_all_actions(gp_connector):\n",
    "    logging.info(\"[run_all_actions] Начинаем обработку всех акций без повторных попыток.\")\n",
    "\n",
    "    # Берём сразу type+version (+month для имени файла)\n",
    "    df_actions = gp_connector.gp(\"\"\"\n",
    "        SELECT type,\n",
    "               version,\n",
    "               EXTRACT(month from promo_start_date_act)::int AS month\n",
    "        FROM BA.helper_category\n",
    "        WHERE is_processed = FALSE\n",
    "        ORDER BY type, version;\n",
    "    \"\"\")\n",
    "\n",
    "    if df_actions.empty:\n",
    "        logging.info(\"[run_all_actions] Нет новых акций для обработки (is_processed = FALSE).\")\n",
    "        return\n",
    "\n",
    "    original_file = 'Анализ Пива_шаблон.xlsx'\n",
    "\n",
    "    # Один файл на (type, month); внутри — только те версии, что реально ждут обработки\n",
    "    for (current_type, current_month), grp in df_actions.groupby(['type', 'month']):\n",
    "        file_name = f\"Анализ_{current_type}_{int(current_month)}.xlsx\"\n",
    "        shutil.copy2(original_file, file_name)\n",
    "\n",
    "        for version in sorted(grp['version'].unique()):\n",
    "            # Доп. защита от повторов/гонок: перепроверка флага прямо перед запуском\n",
    "            flag = gp_connector.gp(f\"\"\"\n",
    "                SELECT is_processed\n",
    "                FROM BA.helper_category\n",
    "                WHERE type = '{current_type}' AND version = {int(version)}\n",
    "                LIMIT 1\n",
    "            \"\"\")\n",
    "            if not flag.empty and bool(flag['is_processed'].iloc[0]):\n",
    "                logging.info(f\"[run_all_actions][{current_type} v{version}] Уже обработана, пропускаю.\")\n",
    "                continue\n",
    "\n",
    "            process_action(gp_connector, current_type, int(version), file_name)\n",
    "\n",
    "            gp_connector.execute_query(f\"\"\"\n",
    "                UPDATE BA.helper_category\n",
    "                SET is_processed = TRUE\n",
    "                WHERE type = '{current_type}' AND version = {int(version)};\n",
    "            \"\"\")\n",
    "            logging.info(f\"[run_all_actions][type={current_type}, version={version}] Отмечена как обработанная.\")\n",
    "\n",
    "    logging.info(\"[run_all_actions] Обработка всех акций завершена.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "1ae5d0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def main():\n",
    "#     \"\"\"\n",
    "#     Главная функция запуска автоматической обработки акций.\n",
    "#     При запуске устанавливается подключение к базе данных, запускается цикл обработки,\n",
    "#     а по завершении соединение закрывается.\n",
    "#     \"\"\"\n",
    "#     logging.info(\"=== Запуск автоматической обработки акций ===\")\n",
    "#     try:\n",
    "#         logging.info(\"Подключаемся к базе данных GreenPlum.\")\n",
    "#         logging.info(\"Запускаем обработку всех акций через run_all_actions.\")\n",
    "#         run_all_actions(gp_connector)\n",
    "#     except Exception as e:\n",
    "#         logging.error(f\"Ошибка в main(): {e}\")\n",
    "#         raise e\n",
    "#     finally:\n",
    "#         logging.info(\"Закрываем соединение с базой данных.\")\n",
    "#         try:\n",
    "#             gp_connector.close()\n",
    "#         except Exception as close_error:\n",
    "#             logging.error(f\"Ошибка при закрытии соединения: {close_error}\")\n",
    "#     logging.info(\"=== Автоматическая обработка акций завершена ===\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "63aa8f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_close_resources(gp_connector, *, kill_excel=False):\n",
    "    # Закрываем БД-коннектор без падения\n",
    "    try:\n",
    "        if hasattr(gp_connector, \"close\"):\n",
    "            gp_connector.close()\n",
    "    except Exception as e:\n",
    "        logging.warning(f\"Ошибка при закрытии gp_connector: {e}\")\n",
    "    try:\n",
    "        if hasattr(gp_connector, \"engine\") and gp_connector.engine:\n",
    "            gp_connector.engine.dispose()\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # Мягкая попытка закрыть Excel-приложения без обращения к xw.apps\n",
    "    try:\n",
    "        import xlwings as xw\n",
    "        # создаём скрытое приложение и сразу закрываем — это безопасно,\n",
    "        # и часто корректно снимает COM-хвосты\n",
    "        app = xw.App(visible=False, add_book=False)\n",
    "        try:\n",
    "            app.quit()\n",
    "        except Exception:\n",
    "            pass\n",
    "        del app\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # Жёсткая чистка (опционально)\n",
    "    if kill_excel:\n",
    "        try:\n",
    "            import subprocess, os\n",
    "            subprocess.run(\n",
    "                [\"taskkill\", \"/F\", \"/IM\", \"EXCEL.EXE\", \"/T\"],\n",
    "                stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL, check=False\n",
    "            )\n",
    "        except Exception:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "8d68e6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    logging.info(\"=== Запуск автоматической обработки акций ===\")\n",
    "    try:\n",
    "        logging.info(\"Подключаемся к базе данных GreenPlum.\")\n",
    "        logging.info(\"Запускаем обработку всех акций через run_all_actions.\")\n",
    "        run_all_actions(gp_connector)\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Ошибка в main(): {e}\")\n",
    "        raise\n",
    "    finally:\n",
    "        logging.info(\"Закрываем соединения/ресурсы.\")\n",
    "        safe_close_resources(gp_connector, kill_excel=False)   # при необходимости поставишь True\n",
    "    logging.info(\"=== Автоматическая обработка акций завершена ===\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "602cd9bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-15 14:55:29,017 - INFO - === Запуск автоматической обработки акций ===\n",
      "2025-09-15 14:55:29,019 - INFO - Подключаемся к базе данных GreenPlum.\n",
      "2025-09-15 14:55:29,020 - INFO - Запускаем обработку всех акций через run_all_actions.\n",
      "2025-09-15 14:55:29,021 - INFO - [run_all_actions] Начинаем обработку всех акций без повторных попыток.\n",
      "2025-09-15 14:55:32,458 - INFO - [process_action][type = kolbasa] Начинаем обработку акции 'ЛК_Колбасы1_июль25_тест'.\n",
      "2025-09-15 14:55:32,459 - INFO - Начало выполнения функции create_whs с args=(<Connector_package.db_connector.GreenPlumConnector object at 0x00000230FDDB34D0>, 'pva_kolbasa_1'), kwargs={}\n",
      "2025-09-15 14:55:33,356 - INFO - Функция create_whs завершена успешно.\n",
      "2025-09-15 14:55:33,360 - INFO - Шаг 1 (whs) выполнен успешно.\n",
      "2025-09-15 14:55:33,362 - INFO - Начало выполнения функции create_cus_ruls с args=(<Connector_package.db_connector.GreenPlumConnector object at 0x00000230FDDB34D0>, 'pva_kolbasa_1', 'Вареные колбасы; Ветчина; Копченые колбасные изделия; Сыровяленые колбасы; Сырокопченые колбасы', 'lvl2', '2025-07-01', '2025-07-31', 'ЛК_Колбасы1_июль25_тест', 'kolbasa', 1, 'f_cat_jul25_kolbasa', 'f_cat_jun25_kolbasa', '2025-06-01', '2025-06-30'), kwargs={}\n",
      "2025-09-15 15:05:06,069 - INFO - Функция create_cus_ruls завершена успешно.\n",
      "2025-09-15 15:05:06,076 - INFO - Шаг 2 (cus_ruls) выполнен успешно.\n",
      "2025-09-15 15:05:06,078 - INFO - Начало выполнения функции create_kg с args=(<Connector_package.db_connector.GreenPlumConnector object at 0x00000230FDDB34D0>, 'pva_kolbasa_1', 'ЛК_Колбасы1_июль25_тест', 'Вареные колбасы; Ветчина; Копченые колбасные изделия; Сыровяленые колбасы; Сырокопченые колбасы', '2025-07-01', '2025-07-31', 'kolbasa', 'f_cat_jul25_kolbasa', 'f_cat_jun25_kolbasa', '2025-06-01', '2025-06-30'), kwargs={}\n",
      "2025-09-15 15:18:10,092 - ERROR - Операционная ошибка SELECT (попытка 1): (psycopg2.OperationalError) SSL SYSCALL error: EOF detected\n",
      "\n",
      "[SQL: SELECT count(1) FROM BA.T_ZIG_SPR_IDN_ACTN WHERE ACTN_NAME = 'ЛК_Колбасы1_июль25_тест';]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "2025-09-15 15:18:10,094 - INFO - Повторная попытка через 30 секунд...\n",
      "2025-09-15 15:18:43,930 - INFO - Функция create_kg завершена успешно.\n",
      "2025-09-15 15:18:43,931 - INFO - Шаг 3 (kg) выполнен успешно.\n",
      "2025-09-15 15:18:43,932 - INFO - Начало выполнения функции create_spr_actn с args=(<Connector_package.db_connector.GreenPlumConnector object at 0x00000230FDDB34D0>, 'pva_kolbasa_1', 'Механики MAU', 'ЛК_Колбасы1_июль25_тест', 56, 28), kwargs={}\n",
      "2025-09-15 15:18:43,933 - ERROR - Операционная ошибка (попытка 1): SSL SYSCALL error: EOF detected\n",
      "\n",
      "2025-09-15 15:18:43,934 - INFO - Повторная попытка через 30 секунд...\n",
      "2025-09-15 15:19:14,671 - INFO - Успешно подключились к GreenPlum.\n",
      "2025-09-15 15:19:18,650 - INFO - Функция create_spr_actn завершена успешно.\n",
      "2025-09-15 15:19:18,653 - INFO - Шаг 4 (spr_actn) выполнен успешно.\n",
      "2025-09-15 15:19:18,658 - ERROR - Операционная ошибка SELECT (попытка 1): (psycopg2.OperationalError) SSL SYSCALL error: EOF detected\n",
      "\n",
      "[SQL: SELECT Actn_id FROM ba.vt_pva_kolbasa_1_spr_actn WHERE actn_name = 'ЛК_Колбасы1_июль25_тест';]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "2025-09-15 15:19:18,660 - INFO - Повторная попытка через 30 секунд...\n",
      "2025-09-15 15:19:52,137 - INFO - Начало выполнения функции create_days с args=(<Connector_package.db_connector.GreenPlumConnector object at 0x00000230FDDB34D0>, 'pva_kolbasa_1', 2793, '2025-05-06', '2025-08-28'), kwargs={}\n",
      "2025-09-15 15:19:52,593 - ERROR - Операционная ошибка (попытка 1): SSL SYSCALL error: EOF detected\n",
      "\n",
      "2025-09-15 15:19:52,594 - INFO - Повторная попытка через 30 секунд...\n",
      "2025-09-15 15:20:23,548 - INFO - Успешно подключились к GreenPlum.\n",
      "2025-09-15 15:20:25,215 - INFO - Функция create_days завершена успешно.\n",
      "2025-09-15 15:20:25,216 - INFO - Шаг 5 (days) выполнен успешно.\n",
      "2025-09-15 15:20:25,217 - INFO - Начало выполнения функции create_days_cross с args=(<Connector_package.db_connector.GreenPlumConnector object at 0x00000230FDDB34D0>, 'pva_kolbasa_1', 2793, 2793), kwargs={}\n",
      "2025-09-15 15:20:28,824 - ERROR - Операционная ошибка SELECT (попытка 1): (psycopg2.OperationalError) SSL SYSCALL error: EOF detected\n",
      "\n",
      "[SQL: SELECT * FROM ba.vt_pva_kolbasa_1_actn_duble WHERE ACTN_ID = 2793;]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "2025-09-15 15:20:28,826 - INFO - Повторная попытка через 30 секунд...\n",
      "2025-09-15 15:21:00,358 - ERROR - Операционная ошибка (попытка 1): SSL SYSCALL error: EOF detected\n",
      "\n",
      "2025-09-15 15:21:00,360 - INFO - Повторная попытка через 30 секунд...\n",
      "2025-09-15 15:21:31,220 - INFO - Успешно подключились к GreenPlum.\n",
      "2025-09-15 15:21:45,115 - INFO - Функция create_days_cross завершена успешно.\n",
      "2025-09-15 15:21:45,117 - INFO - Шаг 6 (days_cross) выполнен успешно.\n",
      "2025-09-15 15:21:45,118 - INFO - Начало выполнения функции frod с args=(<Connector_package.db_connector.GreenPlumConnector object at 0x00000230FDDB34D0>, 'pva_kolbasa_1'), kwargs={}\n",
      "2025-09-15 15:21:59,849 - INFO - Функция frod завершена успешно.\n",
      "2025-09-15 15:21:59,853 - INFO - Шаг - (frod) выполнен успешно.\n",
      "2025-09-15 15:21:59,854 - INFO - Начало выполнения функции create_trn_0 с args=(<Connector_package.db_connector.GreenPlumConnector object at 0x00000230FDDB34D0>, 'pva_kolbasa_1', 2793, 56), kwargs={}\n",
      "2025-09-15 15:21:59,857 - ERROR - Операционная ошибка SELECT (попытка 1): (psycopg2.OperationalError) SSL SYSCALL error: EOF detected\n",
      "\n",
      "[SQL: \n",
      "            select\n",
      "                    month_id\n",
      "                    ,min(day_id) as min_dt\n",
      "                    ,max(day_id) as max_dt\n",
      "            from\n",
      "                    ba.vt_pva_kolbasa_1_days\n",
      "                where\n",
      "                    actn_id = 2793 \n",
      "                    and actn_period = 1\n",
      "                group by 1 \n",
      "                order by 1\n",
      "            ;]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "2025-09-15 15:21:59,859 - INFO - Повторная попытка через 30 секунд...\n",
      "2025-09-15 15:22:31,165 - ERROR - Операционная ошибка (попытка 1): SSL SYSCALL error: EOF detected\n",
      "\n",
      "2025-09-15 15:22:31,167 - INFO - Повторная попытка через 30 секунд...\n",
      "2025-09-15 15:23:01,898 - INFO - Успешно подключились к GreenPlum.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "211b9d6fd29945f9a1ff3952ff98e34a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-15 15:25:19,286 - INFO - Функция create_trn_0 завершена успешно.\n",
      "2025-09-15 15:25:19,289 - INFO - Шаг 7 (create_trn_0) выполнен успешно.\n",
      "2025-09-15 15:25:19,290 - INFO - Начало выполнения функции create_trn_0_v2 с args=(<Connector_package.db_connector.GreenPlumConnector object at 0x00000230FDDB34D0>, 'pva_kolbasa_1', 2793, 31), kwargs={}\n",
      "2025-09-15 15:25:19,295 - ERROR - Операционная ошибка SELECT (попытка 1): (psycopg2.OperationalError) SSL SYSCALL error: EOF detected\n",
      "\n",
      "[SQL: \n",
      "            select\n",
      "                    month_id\n",
      "                    ,min(day_id) as min_dt\n",
      "                    ,max(day_id) as max_dt\n",
      "            from\n",
      "                    ba.vt_pva_kolbasa_1_days\n",
      "                where\n",
      "                    actn_id = 2793 \n",
      "                    and actn_period = 2\n",
      "                group by 1 \n",
      "                order by 1\n",
      "            ;]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "2025-09-15 15:25:19,296 - INFO - Повторная попытка через 30 секунд...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbc539ec87b24d42aee1d87d38516292",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-15 15:25:50,663 - ERROR - Операционная ошибка (попытка 1): SSL SYSCALL error: EOF detected\n",
      "\n",
      "2025-09-15 15:25:50,665 - INFO - Повторная попытка через 30 секунд...\n",
      "2025-09-15 15:26:21,408 - INFO - Успешно подключились к GreenPlum.\n",
      "2025-09-15 15:28:10,437 - INFO - Функция create_trn_0_v2 завершена успешно.\n",
      "2025-09-15 15:28:10,438 - INFO - Шаг 8 (create_trn_0_v2) выполнен успешно.\n",
      "2025-09-15 15:28:10,438 - INFO - Начало выполнения функции create_agg с args=(<Connector_package.db_connector.GreenPlumConnector object at 0x00000230FDDB34D0>, 'pva_kolbasa_1', '2025-07-01'), kwargs={}\n",
      "2025-09-15 15:28:16,666 - ERROR - Операционная ошибка SELECT (попытка 1): (psycopg2.OperationalError) SSL SYSCALL error: EOF detected\n",
      "\n",
      "[SQL: \n",
      "        SELECT is_kg_needed\n",
      "        FROM BA.helper_category\n",
      "        WHERE mask = 'pva_kolbasa_1'\n",
      "    ]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "2025-09-15 15:28:16,667 - INFO - Повторная попытка через 30 секунд...\n",
      "2025-09-15 15:28:47,952 - INFO - [create_agg][mask=pva_kolbasa_1] Начинаем создание таблицы ba.vt_pva_kolbasa_1_trn_1...\n",
      "2025-09-15 15:28:47,955 - ERROR - Операционная ошибка (попытка 1): SSL SYSCALL error: EOF detected\n",
      "\n",
      "2025-09-15 15:28:47,956 - INFO - Повторная попытка через 30 секунд...\n",
      "2025-09-15 15:29:18,571 - INFO - Успешно подключились к GreenPlum.\n",
      "2025-09-15 15:33:05,391 - ERROR - Операционная ошибка SELECT (попытка 1): (psycopg2.OperationalError) SSL SYSCALL error: EOF detected\n",
      "\n",
      "[SQL: \n",
      "        SELECT ACTN_PERIOD, COUNT(DISTINCT CONTACT_ID) AS cnt_cont\n",
      "        FROM ba.vt_pva_kolbasa_1_trn_1\n",
      "        GROUP BY ACTN_PERIOD\n",
      "        ORDER BY ACTN_PERIOD\n",
      "    ]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "2025-09-15 15:33:05,393 - INFO - Повторная попытка через 30 секунд...\n",
      "2025-09-15 15:33:37,970 - INFO - [create_agg][mask=pva_kolbasa_1] Кол-во уникальных клиентов по периодам:\n",
      "   actn_period  cnt_cont\n",
      "0            1  39721112\n",
      "1            2  35891143\n",
      "2025-09-15 15:33:38,996 - INFO - [create_agg][mask=pva_kolbasa_1] Агрегация транзакций (trn_1) завершена.\n",
      "2025-09-15 15:33:38,998 - INFO - Функция create_agg завершена успешно.\n",
      "2025-09-15 15:33:38,999 - INFO - Шаг 9 (create_agg) выполнен успешно.\n",
      "2025-09-15 15:33:39,000 - INFO - Начало выполнения функции process_clear_and_aggregate с args=(<Connector_package.db_connector.GreenPlumConnector object at 0x00000230FDDB34D0>, 'pva_kolbasa_1'), kwargs={}\n",
      "2025-09-15 15:33:39,001 - ERROR - Операционная ошибка (попытка 1): SSL SYSCALL error: EOF detected\n",
      "\n",
      "2025-09-15 15:33:39,003 - INFO - Повторная попытка через 30 секунд...\n",
      "2025-09-15 15:34:09,735 - INFO - Успешно подключились к GreenPlum.\n",
      "2025-09-15 15:34:45,727 - INFO - Функция process_clear_and_aggregate завершена успешно.\n",
      "2025-09-15 15:34:45,731 - INFO - Шаг 10 (process_clear_and_aggregate) выполнен успешно.\n",
      "2025-09-15 15:34:45,733 - INFO - Начало выполнения функции reg_new_returned с args=(<Connector_package.db_connector.GreenPlumConnector object at 0x00000230FDDB34D0>, 'pva_kolbasa_1', '2025-07-01'), kwargs={}\n",
      "2025-09-15 15:34:56,736 - INFO - Функция reg_new_returned завершена успешно.\n",
      "2025-09-15 15:34:56,738 - INFO - Шаг 11 (reg_new_returned) выполнен успешно.\n",
      "2025-09-15 15:34:56,738 - INFO - Начало выполнения функции clear_reg с args=(<Connector_package.db_connector.GreenPlumConnector object at 0x00000230FDDB34D0>, 'pva_kolbasa_1', 2793, 'ЛК_Колбасы1_июль25_тест', 56, 31), kwargs={}\n",
      "2025-09-15 15:35:10,307 - INFO - Функция clear_reg завершена успешно.\n",
      "2025-09-15 15:35:10,308 - INFO - Шаг 12 (clear_reg) выполнен успешно.\n",
      "2025-09-15 15:35:10,309 - INFO - Начало выполнения функции dna с args=(<Connector_package.db_connector.GreenPlumConnector object at 0x00000230FDDB34D0>, 'pva_kolbasa_1', 31), kwargs={}\n",
      "2025-09-15 15:35:14,609 - INFO - Функция dna завершена успешно.\n",
      "2025-09-15 15:35:14,610 - INFO - Шаг 13 (dna) выполнен успешно.\n",
      "2025-09-15 15:35:14,611 - INFO - Начало выполнения функции kg_for_ca с args=(<Connector_package.db_connector.GreenPlumConnector object at 0x00000230FDDB34D0>, 'pva_kolbasa_1', 2), kwargs={}\n",
      "2025-09-15 15:35:46,502 - INFO - Функция kg_for_ca завершена успешно.\n",
      "2025-09-15 15:35:46,503 - INFO - Шаг 14 (kg_for_ca) выполнен успешно.\n",
      "2025-09-15 15:35:46,505 - INFO - Начало выполнения функции cnt_actn с args=(<Connector_package.db_connector.GreenPlumConnector object at 0x00000230FDDB34D0>, 'pva_kolbasa_1', '2025-05-06', '2025-07-01', '2025-07-31', 2793), kwargs={}\n",
      "2025-09-15 15:35:53,743 - INFO - Функция cnt_actn завершена успешно.\n",
      "2025-09-15 15:35:53,747 - INFO - Шаг 14 (cnt_actn) выполнен успешно.\n",
      "2025-09-15 15:35:53,748 - INFO - Начало выполнения функции dynamic_gr20 с args=(<Connector_package.db_connector.GreenPlumConnector object at 0x00000230FDDB34D0>, 'pva_kolbasa_1', 2793), kwargs={}\n",
      "2025-09-15 15:35:53,751 - ERROR - Операционная ошибка SELECT (попытка 1): (psycopg2.OperationalError) SSL SYSCALL error: EOF detected\n",
      "\n",
      "[SQL: \n",
      "           select\n",
      "                month_id\n",
      "                ,min(day_id) as min_dt\n",
      "                ,max(day_id) as max_dt\n",
      "           from\n",
      "                ba.vt_pva_kolbasa_1_days\n",
      "            where\n",
      "                actn_id = 2793 \n",
      "                and actn_period = 1\n",
      "            group by 1 \n",
      "            order by 1\n",
      "        ;]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "2025-09-15 15:35:53,752 - INFO - Повторная попытка через 30 секунд...\n",
      "2025-09-15 15:36:24,975 - ERROR - Операционная ошибка (попытка 1): SSL SYSCALL error: EOF detected\n",
      "\n",
      "2025-09-15 15:36:24,978 - INFO - Повторная попытка через 30 секунд...\n",
      "2025-09-15 15:36:55,681 - INFO - Успешно подключились к GreenPlum.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d0b1176999e4110bc17fa92f35fea78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-15 15:38:59,338 - INFO - Функция dynamic_gr20 завершена успешно.\n",
      "2025-09-15 15:38:59,341 - INFO - Шаг 16 (dynamic_gr20) выполнен успешно.\n",
      "2025-09-15 15:38:59,342 - INFO - Начало выполнения функции gr20_transp с args=(<Connector_package.db_connector.GreenPlumConnector object at 0x00000230FDDB34D0>, 'pva_kolbasa_1'), kwargs={}\n",
      "2025-09-15 15:39:06,110 - INFO - Функция gr20_transp завершена успешно.\n",
      "2025-09-15 15:39:06,111 - INFO - Шаг 17 (gr20_transp) выполнен успешно.\n",
      "2025-09-15 15:39:06,111 - INFO - Начало выполнения функции age_and_active_virt с args=(<Connector_package.db_connector.GreenPlumConnector object at 0x00000230FDDB34D0>, 'pva_kolbasa_1'), kwargs={}\n",
      "2025-09-15 15:39:14,513 - INFO - Функция age_and_active_virt завершена успешно.\n",
      "2025-09-15 15:39:14,518 - INFO - Шаг 18 (age_and_active_virt) выполнен успешно.\n",
      "2025-09-15 15:39:14,520 - INFO - Начало выполнения функции itog с args=(<Connector_package.db_connector.GreenPlumConnector object at 0x00000230FDDB34D0>, 'pva_kolbasa_1', 31), kwargs={}\n",
      "2025-09-15 15:39:19,645 - INFO - Функция itog завершена успешно.\n",
      "2025-09-15 15:39:19,650 - INFO - Шаг 19 (itog) выполнен успешно.\n",
      "2025-09-15 15:39:19,653 - INFO - Начало выполнения функции psm с args=(<Connector_package.db_connector.GreenPlumConnector object at 0x00000230FDDB34D0>, 'pva_kolbasa_1', 'ЛК_Колбасы1_июль25_тест', 2793), kwargs={}\n",
      "2025-09-15 15:39:19,656 - ERROR - Операционная ошибка SELECT (попытка 1): (psycopg2.OperationalError) SSL SYSCALL error: EOF detected\n",
      "\n",
      "[SQL: select distinct FRMT_ID, REGION_ID from ba.vt_pva_kolbasa_1_cus_profile order by FRMT_ID desc;]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "2025-09-15 15:39:19,658 - INFO - Повторная попытка через 30 секунд...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Доля мэтчинга ЛФЛ ЦА/КГ:\n",
      "\n",
      "Загрузка данных frmt_id=104, region_id=180 батчами...\n",
      "Загружено всего строк: 100000, в текущем батче: 17693\n",
      "104 180 [94.62783172]\n",
      "\n",
      "Загрузка данных frmt_id=104, region_id=247 батчами...\n",
      "Загружено всего строк: 100000, в текущем батче: 14312\n",
      "104 247 [95.09202454]\n",
      "\n",
      "Загрузка данных frmt_id=104, region_id=275 батчами...\n",
      "Загружено всего строк: 100000, в текущем батче: 15151\n",
      "104 275 [93.79310345]\n",
      "\n",
      "Загрузка данных frmt_id=104, region_id=227 батчами...\n",
      "Загружено всего строк: 100000, в текущем батче: 19795\n",
      "104 227 [95.1372549]\n",
      "\n",
      "Загрузка данных frmt_id=104, region_id=197 батчами...\n",
      "Загружено всего строк: 100000, в текущем батче: 9965\n",
      "104 197 [92.46861925]\n",
      "\n",
      "Загрузка данных frmt_id=104, region_id=280 батчами...\n",
      "Загружено всего строк: 100000, в текущем батче: 28367\n",
      "104 280 [96.28022319]\n",
      "\n",
      "Загрузка данных frmt_id=104, region_id=284 батчами...\n",
      "Загружено всего строк: 100000, в текущем батче: 19825\n",
      "104 284 [95.31615925]\n",
      "\n",
      "Загрузка данных frmt_id=104, region_id=173 батчами...\n",
      "Загружено всего строк: 100000, в текущем батче: 16011\n",
      "104 173 [94.91916859]\n",
      "\n",
      "Загрузка данных frmt_id=3, region_id=180 батчами...\n",
      "Загружено всего строк: 100000, в текущем батче: 100000\n",
      "Загружено всего строк: 200000, в текущем батче: 100000\n",
      "Загружено всего строк: 300000, в текущем батче: 100000\n",
      "Загружено всего строк: 400000, в текущем батче: 100000\n",
      "Загружено всего строк: 500000, в текущем батче: 100000\n",
      "Загружено всего строк: 600000, в текущем батче: 100000\n",
      "Загружено всего строк: 700000, в текущем батче: 14018\n",
      "3 180 [92.72045994]\n",
      "\n",
      "Загрузка данных frmt_id=3, region_id=247 батчами...\n",
      "Загружено всего строк: 100000, в текущем батче: 100000\n",
      "Загружено всего строк: 200000, в текущем батче: 100000\n",
      "Загружено всего строк: 300000, в текущем батче: 9599\n",
      "3 247 [95.05621693]\n",
      "\n",
      "Загрузка данных frmt_id=3, region_id=275 батчами...\n",
      "Загружено всего строк: 100000, в текущем батче: 100000\n",
      "Загружено всего строк: 200000, в текущем батче: 100000\n",
      "Загружено всего строк: 300000, в текущем батче: 100000\n",
      "Загружено всего строк: 400000, в текущем батче: 100000\n",
      "Загружено всего строк: 500000, в текущем батче: 100000\n",
      "Загружено всего строк: 600000, в текущем батче: 100000\n",
      "Загружено всего строк: 700000, в текущем батче: 74161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-15 15:48:29,376 - ERROR - Операционная ошибка SELECT (попытка 1): (psycopg2.OperationalError) SSL SYSCALL error: EOF detected\n",
      "\n",
      "[SQL: \n",
      "                    SELECT * FROM ba.vt_pva_kolbasa_1_cus_profile \n",
      "                    WHERE frmt_id = '3' AND region_id = '227'\n",
      "                    LIMIT 100000 OFFSET 0\n",
      "                ]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "2025-09-15 15:48:29,377 - INFO - Повторная попытка через 30 секунд...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 275 [93.26728429]\n",
      "\n",
      "Загрузка данных frmt_id=3, region_id=227 батчами...\n",
      "Загружено всего строк: 100000, в текущем батче: 100000\n",
      "Загружено всего строк: 200000, в текущем батче: 100000\n",
      "Загружено всего строк: 300000, в текущем батче: 100000\n",
      "Загружено всего строк: 400000, в текущем батче: 100000\n",
      "Загружено всего строк: 500000, в текущем батче: 100000\n",
      "Загружено всего строк: 600000, в текущем батче: 38441\n",
      "3 227 [92.13347921]\n",
      "\n",
      "Загрузка данных frmt_id=3, region_id=197 батчами...\n",
      "Загружено всего строк: 100000, в текущем батче: 100000\n",
      "Загружено всего строк: 200000, в текущем батче: 100000\n",
      "Загружено всего строк: 300000, в текущем батче: 45570\n",
      "3 197 [92.77518824]\n",
      "\n",
      "Загрузка данных frmt_id=3, region_id=280 батчами...\n",
      "Загружено всего строк: 100000, в текущем батче: 100000\n",
      "Загружено всего строк: 200000, в текущем батче: 100000\n",
      "Загружено всего строк: 300000, в текущем батче: 100000\n",
      "Загружено всего строк: 400000, в текущем батче: 100000\n",
      "Загружено всего строк: 500000, в текущем батче: 100000\n",
      "Загружено всего строк: 600000, в текущем батче: 100000\n",
      "Загружено всего строк: 700000, в текущем батче: 3444\n",
      "3 280 [95.26600023]\n",
      "\n",
      "Загрузка данных frmt_id=3, region_id=284 батчами...\n",
      "Загружено всего строк: 100000, в текущем батче: 100000\n",
      "Загружено всего строк: 200000, в текущем батче: 100000\n",
      "Загружено всего строк: 300000, в текущем батче: 100000\n",
      "Загружено всего строк: 400000, в текущем батче: 100000\n",
      "Загружено всего строк: 500000, в текущем батче: 100000\n",
      "Загружено всего строк: 600000, в текущем батче: 100000\n",
      "Загружено всего строк: 700000, в текущем батче: 91434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-15 15:59:42,794 - ERROR - Операционная ошибка SELECT (попытка 1): (psycopg2.OperationalError) SSL SYSCALL error: EOF detected\n",
      "\n",
      "[SQL: \n",
      "                    SELECT * FROM ba.vt_pva_kolbasa_1_cus_profile \n",
      "                    WHERE frmt_id = '3' AND region_id = '173'\n",
      "                    LIMIT 100000 OFFSET 0\n",
      "                ]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "2025-09-15 15:59:42,795 - INFO - Повторная попытка через 30 секунд...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 284 [93.76830208]\n",
      "\n",
      "Загрузка данных frmt_id=3, region_id=173 батчами...\n",
      "Загружено всего строк: 100000, в текущем батче: 100000\n",
      "Загружено всего строк: 200000, в текущем батче: 100000\n",
      "Загружено всего строк: 300000, в текущем батче: 38099\n",
      "3 173 [92.40050663]\n",
      "\n",
      "Загрузка данных frmt_id=2, region_id=180 батчами...\n",
      "Загружено всего строк: 100000, в текущем батче: 100000\n",
      "Загружено всего строк: 200000, в текущем батче: 100000\n",
      "Загружено всего строк: 300000, в текущем батче: 100000\n",
      "Загружено всего строк: 400000, в текущем батче: 100000\n",
      "Загружено всего строк: 500000, в текущем батче: 95454\n",
      "2 180 [89.08802494]\n",
      "\n",
      "Загрузка данных frmt_id=2, region_id=247 батчами...\n",
      "Загружено всего строк: 100000, в текущем батче: 100000\n",
      "Загружено всего строк: 200000, в текущем батче: 13685\n",
      "2 247 [92.06821873]\n",
      "\n",
      "Загрузка данных frmt_id=2, region_id=275 батчами...\n",
      "Загружено всего строк: 100000, в текущем батче: 100000\n",
      "Загружено всего строк: 200000, в текущем батче: 100000\n",
      "Загружено всего строк: 300000, в текущем батче: 100000\n",
      "Загружено всего строк: 400000, в текущем батче: 100000\n",
      "Загружено всего строк: 500000, в текущем батче: 92377\n",
      "2 275 [90.63974445]\n",
      "\n",
      "Загрузка данных frmt_id=2, region_id=227 батчами...\n",
      "Загружено всего строк: 100000, в текущем батче: 100000\n",
      "Загружено всего строк: 200000, в текущем батче: 85148\n",
      "2 227 [93.2648907]\n",
      "\n",
      "Загрузка данных frmt_id=2, region_id=197 батчами...\n",
      "Загружено всего строк: 100000, в текущем батче: 100000\n",
      "Загружено всего строк: 200000, в текущем батче: 100000\n",
      "Загружено всего строк: 300000, в текущем батче: 125\n",
      "2 197 [90.95161807]\n",
      "\n",
      "Загрузка данных frmt_id=2, region_id=280 батчами...\n",
      "Загружено всего строк: 100000, в текущем батче: 100000\n",
      "Загружено всего строк: 200000, в текущем батче: 58800\n",
      "2 280 [91.4271556]\n",
      "\n",
      "Загрузка данных frmt_id=2, region_id=284 батчами...\n",
      "Загружено всего строк: 100000, в текущем батче: 100000\n",
      "Загружено всего строк: 200000, в текущем батче: 100000\n",
      "Загружено всего строк: 300000, в текущем батче: 69982\n",
      "2 284 [92.28270162]\n",
      "\n",
      "Загрузка данных frmt_id=2, region_id=173 батчами...\n",
      "Загружено всего строк: 100000, в текущем батче: 80648\n",
      "2 173 [91.71067371]\n",
      "\n",
      "Загрузка данных frmt_id=1, region_id=180 батчами...\n",
      "Загружено всего строк: 100000, в текущем батче: 100000\n",
      "Загружено всего строк: 200000, в текущем батче: 100000\n",
      "Загружено всего строк: 300000, в текущем батче: 100000\n",
      "Загружено всего строк: 400000, в текущем батче: 39002\n",
      "1 180 [52.80510809]\n",
      "\n",
      "Загрузка данных frmt_id=1, region_id=247 батчами...\n",
      "Загружено всего строк: 100000, в текущем батче: 100000\n",
      "Загружено всего строк: 200000, в текущем батче: 100000\n",
      "Загружено всего строк: 300000, в текущем батче: 40631\n",
      "1 247 [54.21451167]\n",
      "\n",
      "Загрузка данных frmt_id=1, region_id=275 батчами...\n",
      "Загружено всего строк: 100000, в текущем батче: 100000\n",
      "Загружено всего строк: 200000, в текущем батче: 100000\n",
      "Загружено всего строк: 300000, в текущем батче: 100000\n",
      "Загружено всего строк: 400000, в текущем батче: 100000\n",
      "Загружено всего строк: 500000, в текущем батче: 100000\n",
      "Загружено всего строк: 600000, в текущем батче: 60966\n",
      "1 275 [52.24634778]\n",
      "\n",
      "Загрузка данных frmt_id=1, region_id=227 батчами...\n",
      "Загружено всего строк: 100000, в текущем батче: 100000\n",
      "Загружено всего строк: 200000, в текущем батче: 100000\n",
      "Загружено всего строк: 300000, в текущем батче: 100000\n",
      "Загружено всего строк: 400000, в текущем батче: 10642\n",
      "1 227 [50.84380853]\n",
      "\n",
      "Загрузка данных frmt_id=1, region_id=197 батчами...\n",
      "Загружено всего строк: 100000, в текущем батче: 100000\n",
      "Загружено всего строк: 200000, в текущем батче: 97577\n",
      "1 197 [54.37692787]\n",
      "\n",
      "Загрузка данных frmt_id=1, region_id=280 батчами...\n",
      "Загружено всего строк: 100000, в текущем батче: 100000\n",
      "Загружено всего строк: 200000, в текущем батче: 100000\n",
      "Загружено всего строк: 300000, в текущем батче: 100000\n",
      "Загружено всего строк: 400000, в текущем батче: 100000\n",
      "Загружено всего строк: 500000, в текущем батче: 31650\n",
      "1 280 [50.50087244]\n",
      "\n",
      "Загрузка данных frmt_id=1, region_id=284 батчами...\n",
      "Загружено всего строк: 100000, в текущем батче: 100000\n",
      "Загружено всего строк: 200000, в текущем батче: 100000\n",
      "Загружено всего строк: 300000, в текущем батче: 100000\n",
      "Загружено всего строк: 400000, в текущем батче: 100000\n",
      "Загружено всего строк: 500000, в текущем батче: 65886\n",
      "1 284 [51.28900338]\n",
      "\n",
      "Загрузка данных frmt_id=1, region_id=173 батчами...\n",
      "Загружено всего строк: 100000, в текущем батче: 100000\n",
      "Загружено всего строк: 200000, в текущем батче: 100000\n",
      "Загружено всего строк: 300000, в текущем батче: 79460\n",
      "1 173 [53.52421016]\n",
      "Процесс завершен.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-15 16:27:50,000 - ERROR - Операционная ошибка (попытка 1): SSL SYSCALL error: EOF detected\n",
      "\n",
      "2025-09-15 16:27:50,001 - INFO - Повторная попытка через 30 секунд...\n",
      "2025-09-15 16:28:20,742 - INFO - Успешно подключились к GreenPlum.\n",
      "2025-09-15 16:28:21,490 - INFO - Успешно вставлено 32 строк в таблицу ba.vt_pva_kolbasa_1_stat_temp за 0.358 сек.\n",
      "2025-09-15 16:28:22,073 - ERROR - Операционная ошибка SELECT (попытка 1): (psycopg2.OperationalError) SSL SYSCALL error: EOF detected\n",
      "\n",
      "[SQL: SELECT count(1) FROM BA.T_ZIG_STAT_TEST_PSM where ACTN_NAME = 'ЛК_Колбасы1_июль25_тест';]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "2025-09-15 16:28:22,076 - INFO - Повторная попытка через 30 секунд...\n",
      "2025-09-15 16:28:53,236 - ERROR - Операционная ошибка (попытка 1): SSL SYSCALL error: EOF detected\n",
      "\n",
      "2025-09-15 16:28:53,237 - INFO - Повторная попытка через 30 секунд...\n",
      "2025-09-15 16:29:23,986 - INFO - Успешно подключились к GreenPlum.\n",
      "2025-09-15 16:29:43,469 - INFO - Успешно вставлено 1652046 строк в таблицу ba.vt_pva_kolbasa_1_cus_temp за 15.085 сек.\n",
      "2025-09-15 16:29:52,335 - INFO - Функция psm завершена успешно.\n",
      "2025-09-15 16:29:52,338 - INFO - Шаг 20 (psm) выполнен успешно.\n",
      "2025-09-15 16:29:52,340 - INFO - Начало выполнения функции margin с args=(<Connector_package.db_connector.GreenPlumConnector object at 0x00000230FDDB34D0>, 'pva_kolbasa_1', 'ЛК_Колбасы1_июль25_тест', '2025-07-01', '2025-07-31', 'FC_jul25_S_5', 2793, '2025-07-01', '2025-07-31', '2025-05-06', '2025-08-28', 56, 28, 31), kwargs={}\n",
      "2025-09-15 16:29:52,345 - ERROR - Операционная ошибка SELECT (попытка 1): (psycopg2.OperationalError) SSL SYSCALL error: EOF detected\n",
      "\n",
      "[SQL:  --sql\n",
      "    SELECT\n",
      "        MONTH_ID\n",
      "        ,min(DAY_ID) as min_dt\n",
      "        ,max(DAY_ID) as max_dt\n",
      "    FROM ba.vt_pva_kolbasa_1_days \n",
      "    WHERE ACTN_NAME = 'ЛК_Колбасы1_июль25_тест'\n",
      "        and ACTN_PERIOD IN (1,2,3)\n",
      "    group by MONTH_ID\n",
      "    order by MONTH_ID\n",
      "    ;]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "2025-09-15 16:29:52,347 - INFO - Повторная попытка через 30 секунд...\n",
      "2025-09-15 16:30:23,777 - ERROR - Операционная ошибка (попытка 1): SSL SYSCALL error: EOF detected\n",
      "\n",
      "2025-09-15 16:30:23,782 - INFO - Повторная попытка через 30 секунд...\n",
      "2025-09-15 16:30:54,356 - INFO - Успешно подключились к GreenPlum.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07fd85feddd74ae084e6c68f54f3d413",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Создаем пустую таблицу для параметров расчета маржи.\n",
      "Создаем таблицу с налогами на товары.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f5b7cd436f14b88a162594185e33a88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Собираем строки из таблицы с чеками за период c 2025-05-06 по 2025-05-31.\n",
      "Cобираем строки из AUM за период c 2025-05-06 по 2025-05-31.\n",
      "Предобработка строк из AUM за период c 2025-05-06 по 2025-05-31.\n",
      "Заполняем таблицу параметров для расчета маржи за период c 2025-05-06 по 2025-05-31.\n",
      "***********************************\n",
      "Собираем строки из таблицы с чеками за период c 2025-06-01 по 2025-06-30.\n",
      "Cобираем строки из AUM за период c 2025-06-01 по 2025-06-30.\n",
      "Предобработка строк из AUM за период c 2025-06-01 по 2025-06-30.\n",
      "Заполняем таблицу параметров для расчета маржи за период c 2025-06-01 по 2025-06-30.\n",
      "***********************************\n",
      "Собираем строки из таблицы с чеками за период c 2025-07-01 по 2025-07-31.\n",
      "Cобираем строки из AUM за период c 2025-07-01 по 2025-07-31.\n",
      "Предобработка строк из AUM за период c 2025-07-01 по 2025-07-31.\n",
      "Заполняем таблицу параметров для расчета маржи за период c 2025-07-01 по 2025-07-31.\n",
      "***********************************\n",
      "Собираем строки из таблицы с чеками за период c 2025-08-01 по 2025-08-28.\n",
      "Cобираем строки из AUM за период c 2025-08-01 по 2025-08-28.\n",
      "Предобработка строк из AUM за период c 2025-08-01 по 2025-08-28.\n",
      "Заполняем таблицу параметров для расчета маржи за период c 2025-08-01 по 2025-08-28.\n",
      "***********************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-15 17:02:00,310 - INFO - in_code_ruls: FC_jul25_S_5, rule_code_filter: rule_code IN ('FC_jul25_S_5')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df9fb9c1a11c43a8a2cb92d476e9b856",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-15 17:09:26,221 - ERROR - Операционная ошибка SELECT (попытка 1): (psycopg2.OperationalError) SSL SYSCALL error: EOF detected\n",
      "\n",
      "[SQL: select GRP from ba.vt_pva_kolbasa_1_dataset_cus group by GRP order by GRP;]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "2025-09-15 17:09:26,224 - INFO - Повторная попытка через 30 секунд...\n",
      "2025-09-15 17:09:57,694 - ERROR - Операционная ошибка (попытка 1): SSL SYSCALL error: EOF detected\n",
      "\n",
      "2025-09-15 17:09:57,696 - INFO - Повторная попытка через 30 секунд...\n",
      "2025-09-15 17:10:28,166 - INFO - Успешно подключились к GreenPlum.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e00a4a31d1184ccf9cc8a8657ecdd715",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-15 17:12:37,522 - INFO - Функция margin завершена успешно.\n",
      "2025-09-15 17:12:37,525 - INFO - Шаг 21 (margin) выполнен успешно.\n",
      "2025-09-15 17:12:37,527 - INFO - Начало выполнения функции oborot_rto с args=(<Connector_package.db_connector.GreenPlumConnector object at 0x00000230FDDB34D0>, 'pva_kolbasa_1', '2025-07-01', '2025-07-31', 'ЛК_Колбасы1_июль25_тест'), kwargs={}\n",
      "2025-09-15 17:12:37,530 - ERROR - Операционная ошибка SELECT (попытка 1): (psycopg2.OperationalError) SSL SYSCALL error: EOF detected\n",
      "\n",
      "[SQL: \n",
      "\tSELECT\n",
      "\t\tcode\n",
      "\tFROM\n",
      "\t\tdm.WHS w\n",
      "\tJOIN\n",
      "\t\tba.vt_pva_kolbasa_1_whs ww \n",
      "\t\ton ww.orgunit_id = w.orgunit_id\n",
      "\t;\n",
      "\t]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "2025-09-15 17:12:37,531 - INFO - Повторная попытка через 30 секунд...\n",
      "E:\\users\\meshchaninov_av\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\Connector_package\\db_connector.py:277: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql_query(script, connect_td)\n",
      "2025-09-15 17:13:50,147 - ERROR - Операционная ошибка (попытка 1): SSL SYSCALL error: EOF detected\n",
      "\n",
      "2025-09-15 17:13:50,149 - INFO - Повторная попытка через 30 секунд...\n",
      "2025-09-15 17:14:20,681 - INFO - Успешно подключились к GreenPlum.\n",
      "2025-09-15 17:14:21,365 - INFO - Успешно вставлено 32 строк в таблицу ba.vt_pva_kolbasa_1_opsum_temp за 0.295 сек.\n",
      "2025-09-15 17:14:21,951 - ERROR - Операционная ошибка SELECT (попытка 1): (psycopg2.OperationalError) SSL SYSCALL error: EOF detected\n",
      "\n",
      "[SQL: \n",
      "\tSELECT\n",
      "\t\tactn_name\n",
      "\t\t,frmt_id\n",
      "\t\t,region_id\n",
      "\t\t,opsum_frmt_region\n",
      "\tFROM \n",
      "\t\tBA.T_ZIG_OPSUM_FRMT_REGION\n",
      "\tWHERE\n",
      "\t\tACTN_NAME = 'ЛК_Колбасы1_июль25_тест'\n",
      "\t;]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "2025-09-15 17:14:21,954 - INFO - Повторная попытка через 30 секунд...\n",
      "2025-09-15 17:14:52,778 - INFO - Функция oborot_rto завершена успешно.\n",
      "2025-09-15 17:14:52,780 - INFO - Шаг 22 (oborot_rto) выполнен успешно.\n",
      "2025-09-15 17:14:52,781 - INFO - Начало выполнения функции metrics_act с args=(<Connector_package.db_connector.GreenPlumConnector object at 0x00000230FDDB34D0>, 'pva_kolbasa_1', 'kolbasa', 2793, '2025-07-01', '2025-07-31', 1), kwargs={}\n",
      "2025-09-15 17:14:52,783 - ERROR - Операционная ошибка (попытка 1): SSL SYSCALL error: EOF detected\n",
      "\n",
      "2025-09-15 17:14:52,786 - INFO - Повторная попытка через 30 секунд...\n",
      "2025-09-15 17:15:23,323 - INFO - Успешно подключились к GreenPlum.\n",
      "2025-09-15 17:26:22,467 - INFO - Функция metrics_act завершена успешно.\n",
      "2025-09-15 17:26:22,470 - INFO - Шаг 24 (metrics_act) выполнен успешно.\n",
      "2025-09-15 17:26:22,471 - INFO - Начало выполнения функции metrics_prev с args=(<Connector_package.db_connector.GreenPlumConnector object at 0x00000230FDDB34D0>, 'pva_kolbasa_1', 'kolbasa', 2793, '2025-06-01', '2025-06-30', 1), kwargs={}\n",
      "2025-09-15 17:37:59,275 - INFO - Функция metrics_prev завершена успешно.\n",
      "2025-09-15 17:37:59,277 - INFO - Шаг 25 (metrics_prev) выполнен успешно.\n",
      "2025-09-15 17:37:59,279 - INFO - Начало выполнения функции ca_metrics с args=(<Connector_package.db_connector.GreenPlumConnector object at 0x00000230FDDB34D0>, 'pva_kolbasa_1', 'kolbasa', 1), kwargs={}\n",
      "2025-09-15 17:37:59,282 - ERROR - Операционная ошибка SELECT (попытка 1): (psycopg2.OperationalError) SSL SYSCALL error: EOF detected\n",
      "\n",
      "[SQL: \n",
      "        select * from ba.vt_pva_kolbasa_1_kolbasa_1_total_metrics_prev\n",
      "        where is_ca = 1;\n",
      "    ]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "2025-09-15 17:37:59,284 - INFO - Повторная попытка через 30 секунд...\n",
      "2025-09-15 17:38:30,478 - INFO - Функция ca_metrics завершена успешно.\n",
      "2025-09-15 17:38:30,479 - INFO - Шаг 25 (ca_metrics) выполнен успешно.\n",
      "2025-09-15 17:38:30,481 - INFO - Начало выполнения функции kg_metrics с args=(<Connector_package.db_connector.GreenPlumConnector object at 0x00000230FDDB34D0>, 'pva_kolbasa_1', 'kolbasa', 1), kwargs={}\n",
      "2025-09-15 17:38:31,183 - INFO - Функция kg_metrics завершена успешно.\n",
      "2025-09-15 17:38:31,184 - INFO - Шаг 25 (kg_metrics) выполнен успешно.\n",
      "2025-09-15 17:38:31,184 - INFO - Начало выполнения функции bonuses с args=(<Connector_package.db_connector.GreenPlumConnector object at 0x00000230FDDB34D0>, 'pva_kolbasa_1', 'FC_jul25_S_5', '2025-07-01', '2025-07-31'), kwargs={}\n",
      "2025-09-15 17:38:37,217 - INFO - Функция bonuses завершена успешно.\n",
      "2025-09-15 17:38:37,218 - INFO - Шаг 25 (bonuses) выполнен успешно.\n",
      "2025-09-15 17:38:37,220 - INFO - Начало выполнения функции unique_clients_ca с args=(<Connector_package.db_connector.GreenPlumConnector object at 0x00000230FDDB34D0>, 'pva_kolbasa_1', 2793), kwargs={}\n",
      "2025-09-15 17:38:42,651 - INFO - Функция unique_clients_ca завершена успешно.\n",
      "2025-09-15 17:38:42,652 - INFO - Шаг 25 (unique_clients_ca) выполнен успешно.\n",
      "2025-09-15 17:38:42,654 - INFO - Начало выполнения функции unique_clients_kg с args=(<Connector_package.db_connector.GreenPlumConnector object at 0x00000230FDDB34D0>, 'pva_kolbasa_1', 2793), kwargs={}\n",
      "2025-09-15 17:38:48,052 - INFO - Функция unique_clients_kg завершена успешно.\n",
      "2025-09-15 17:38:48,056 - INFO - Шаг 25 (unique_clients_kg) выполнен успешно.\n",
      "2025-09-15 17:38:48,057 - INFO - Начало выполнения функции loading_report с args=(<Connector_package.db_connector.GreenPlumConnector object at 0x00000230FDDB34D0>, '2025-07-01', '2025-07-31', 'ЛК_Колбасы1_июль25_тест'), kwargs={}\n",
      "e:\\users\\meshchaninov_av\\AppData\\Local\\Temp\\ipykernel_15804\\206227070.py:420: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_frmt_region_cus_exp['is_ca'].replace({0:'КГ',1:'ЦА'}, inplace=True)\n",
      "e:\\users\\meshchaninov_av\\AppData\\Local\\Temp\\ipykernel_15804\\206227070.py:577: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_total_exp['is_ca'].replace({0:'КГ', 1:'ЦА'}, inplace=True)\n",
      "e:\\users\\meshchaninov_av\\AppData\\Local\\Temp\\ipykernel_15804\\206227070.py:577: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_total_exp['is_ca'].replace({0:'КГ', 1:'ЦА'}, inplace=True)\n",
      "e:\\users\\meshchaninov_av\\AppData\\Local\\Temp\\ipykernel_15804\\206227070.py:589: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  compact.loc[f'_pad_{compact.shape[0]+1}'] = [None, None]\n",
      "e:\\users\\meshchaninov_av\\AppData\\Local\\Temp\\ipykernel_15804\\206227070.py:589: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  compact.loc[f'_pad_{compact.shape[0]+1}'] = [None, None]\n",
      "2025-09-15 17:39:57,751 - INFO - Функция loading_report завершена успешно.\n",
      "2025-09-15 17:39:57,752 - INFO - Шаг 24 (loading_report) выполнен успешно.\n",
      "2025-09-15 17:39:59,312 - INFO - Начало выполнения функции delete_tables с args=(<Connector_package.db_connector.GreenPlumConnector object at 0x00000230FDDB34D0>, 'pva_kolbasa_1'), kwargs={}\n",
      "2025-09-15 17:40:01,139 - ERROR - Операционная ошибка (попытка 1): SSL SYSCALL error: EOF detected\n",
      "\n",
      "2025-09-15 17:40:01,139 - INFO - Повторная попытка через 30 секунд...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Кол-во таблиц до фильтрации: 60\n",
      "Кол-во таблиц после фильтрации: 56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-15 17:40:31,613 - INFO - Успешно подключились к GreenPlum.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Таблица ba.tmp_pva_kolbasa_1_kolbasa_articles удалена\n",
      "Таблица ba.vt_pva_kolbasa_1_cus_ruls удалена\n",
      "Таблица ba.tmp_pva_kolbasa_1_kolbasa_buyers_act удалена\n",
      "Таблица ba.tmp_pva_kolbasa_1_kolbasa_offer_accept_act удалена\n",
      "Таблица ba.tmp_pva_kolbasa_1_kolbasa_offer_accept_prev удалена\n",
      "Таблица ba.vt_pva_kolbasa_1_cus_ctrl удалена\n",
      "Таблица ba.pva_kolbasa_1_ca_and_kg удалена\n",
      "Таблица ba.vt_pva_kolbasa_1_promo_week удалена\n",
      "Таблица ba.vt_pva_kolbasa_1_actn_duble удалена\n",
      "Таблица ba.vt_pva_kolbasa_1_frod удалена\n",
      "Таблица ba.vt_pva_kolbasa_1_trn_0 удалена\n",
      "Таблица ba.vt_pva_kolbasa_1_trn_1 удалена\n",
      "Таблица ba.vt_pva_kolbasa_1_ca_clear удалена\n",
      "Таблица ba.vt_pva_kolbasa_1_cus_clear удалена\n",
      "Таблица ba.vt_pva_kolbasa_1_trn удалена\n",
      "Таблица ba.vt_pva_kolbasa_1_cus_type удалена\n",
      "Таблица ba.vt_pva_kolbasa_1_cus_reg удалена\n",
      "Таблица ba.vt_pva_kolbasa_1_ca_frmt удалена\n",
      "Таблица ba.vt_pva_kolbasa_1_kg_frmt удалена\n",
      "Таблица ba.vt_pva_kolbasa_1_ca_frmt_grp удалена\n",
      "Таблица ba.vt_pva_kolbasa_1_kg_lfl_frmt удалена\n",
      "Таблица ba.vt_pva_kolbasa_1_ca_lfl_frmt удалена\n",
      "Таблица ba.vt_pva_kolbasa_1_ca_cg удалена\n",
      "Таблица ba.vt_pva_kolbasa_1_cnt_actn удалена\n",
      "Таблица ba.vt_pva_kolbasa_1_cus_gr_0 удалена\n",
      "Таблица ba.vt_pva_kolbasa_1_cus_gr удалена\n",
      "Таблица ba.vt_pva_kolbasa_1_cus_gr_transp удалена\n",
      "Таблица ba.vt_pva_kolbasa_1_cus_gender удалена\n",
      "Таблица ba.vt_pva_kolbasa_1_cus_virt удалена\n",
      "Таблица ba.vt_pva_kolbasa_1_cus_profile удалена\n",
      "Таблица ba.vt_pva_kolbasa_1_stat_temp удалена\n",
      "Таблица ba.vt_pva_kolbasa_1_cus_temp удалена\n",
      "Таблица ba.vt_pva_kolbasa_1_cus удалена\n",
      "Таблица ba.vt_pva_kolbasa_1_trn_prd удалена\n",
      "Таблица ba.vt_pva_kolbasa_1_trn_clear удалена\n",
      "Таблица ba.vt_pva_kolbasa_1_aum удалена\n",
      "Таблица ba.vt_pva_kolbasa_1_vat_vatrate удалена\n",
      "Таблица ba.vt_pva_kolbasa_1_cbi_aum удалена\n",
      "Таблица ba.vt_pva_kolbasa_1_aum_pre_calc удалена\n",
      "Таблица ba.vt_pva_kolbasa_1_bonuses удалена\n",
      "Таблица ba.vt_pva_kolbasa_1_trn_ruls удалена\n",
      "Таблица ba.vt_pva_kolbasa_1_trn_ruls_clear удалена\n",
      "Таблица ba.vt_pva_kolbasa_1_dataset удалена\n",
      "Таблица ba.vt_pva_kolbasa_1_aum_temp удалена\n",
      "Таблица ba.vt_pva_kolbasa_1_trn_temp удалена\n",
      "Таблица ba.vt_pva_kolbasa_1_dataset_cus удалена\n",
      "Таблица ba.vt_pva_kolbasa_1_dataset_agg удалена\n",
      "Таблица ba.vt_pva_kolbasa_1_cus_margin удалена\n",
      "Таблица ba.vt_pva_kolbasa_1_opsum_temp удалена\n",
      "Таблица ba.tmp_pva_kolbasa_1_kolbasa_1_cheques_act удалена\n",
      "Таблица ba.tmp_pva_kolbasa_1_kolbasa_1_cheques_act_contacts удалена\n",
      "Таблица ba.vt_pva_kolbasa_1_kolbasa_1_total_metrics_act удалена\n",
      "Таблица ba.tmp_pva_kolbasa_1_kolbasa_1_2793_contact удалена\n",
      "Таблица ba.tmp_pva_kolbasa_1_kolbasa_1_cheques_prev удалена\n",
      "Таблица ba.tmp_pva_kolbasa_1_kolbasa_1_cheques_prev_contacts удалена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-15 17:40:52,744 - INFO - Функция delete_tables завершена успешно.\n",
      "2025-09-15 17:40:52,746 - INFO - Шаг 23 (delete_tables) выполнен успешно.\n",
      "2025-09-15 17:40:52,747 - INFO - [process_action][mask = pva_kolbasa_1] Обработка акции 'ЛК_Колбасы1_июль25_тест' завершена успешно.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Таблица ba.vt_pva_kolbasa_1_kolbasa_1_total_metrics_prev удалена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-15 17:40:53,048 - INFO - [run_all_actions][type=kolbasa, version=1] Отмечена как обработанная.\n",
      "2025-09-15 17:40:53,050 - ERROR - Операционная ошибка SELECT (попытка 1): (psycopg2.OperationalError) SSL SYSCALL error: EOF detected\n",
      "\n",
      "[SQL: \n",
      "                SELECT is_processed\n",
      "                FROM BA.helper_category\n",
      "                WHERE type = 'kolbasa' AND version = 2\n",
      "                LIMIT 1\n",
      "            ]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "2025-09-15 17:40:53,052 - INFO - Повторная попытка через 30 секунд...\n",
      "2025-09-15 17:41:24,103 - INFO - [process_action][type = kolbasa] Начинаем обработку акции 'ЛК_Колбасы2_июль25_тест'.\n",
      "2025-09-15 17:41:24,104 - INFO - Начало выполнения функции create_whs с args=(<Connector_package.db_connector.GreenPlumConnector object at 0x00000230FDDB34D0>, 'pva_kolbasa_2'), kwargs={}\n",
      "2025-09-15 17:41:24,105 - ERROR - Операционная ошибка (попытка 1): SSL SYSCALL error: EOF detected\n",
      "\n",
      "2025-09-15 17:41:24,106 - INFO - Повторная попытка через 30 секунд...\n",
      "2025-09-15 17:41:54,602 - INFO - Успешно подключились к GreenPlum.\n",
      "2025-09-15 17:41:55,442 - INFO - Функция create_whs завершена успешно.\n",
      "2025-09-15 17:41:55,445 - INFO - Шаг 1 (whs) выполнен успешно.\n",
      "2025-09-15 17:41:55,447 - INFO - Начало выполнения функции create_cus_ruls с args=(<Connector_package.db_connector.GreenPlumConnector object at 0x00000230FDDB34D0>, 'pva_kolbasa_2', 'Вареные колбасы; Ветчина; Копченые колбасные изделия; Сыровяленые колбасы; Сырокопченые колбасы', 'lvl2', '2025-07-01', '2025-07-31', 'ЛК_Колбасы2_июль25_тест', 'kolbasa', 2, 'f_cat_jul25_kolbasa', 'f_cat_jun25_kolbasa', '2025-06-01', '2025-06-30'), kwargs={}\n",
      "2025-09-15 17:41:55,902 - ERROR - Операционная ошибка SELECT (попытка 1): (psycopg2.OperationalError) SSL SYSCALL error: EOF detected\n",
      "\n",
      "[SQL: SELECT COUNT(*) FROM ba.tmp_pva_kolbasa_2_kolbasa_articles;]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "2025-09-15 17:41:55,905 - INFO - Повторная попытка через 30 секунд...\n",
      "2025-09-15 17:42:26,828 - ERROR - Операционная ошибка (попытка 1): SSL SYSCALL error: EOF detected\n",
      "\n",
      "2025-09-15 17:42:26,830 - INFO - Повторная попытка через 30 секунд...\n",
      "2025-09-15 17:42:57,367 - INFO - Успешно подключились к GreenPlum.\n",
      "2025-09-15 17:52:37,610 - INFO - Функция create_cus_ruls завершена успешно.\n",
      "2025-09-15 17:52:37,611 - INFO - Шаг 2 (cus_ruls) выполнен успешно.\n",
      "2025-09-15 17:52:37,612 - INFO - Начало выполнения функции create_kg с args=(<Connector_package.db_connector.GreenPlumConnector object at 0x00000230FDDB34D0>, 'pva_kolbasa_2', 'ЛК_Колбасы2_июль25_тест', 'Вареные колбасы; Ветчина; Копченые колбасные изделия; Сыровяленые колбасы; Сырокопченые колбасы', '2025-07-01', '2025-07-31', 'kolbasa', 'f_cat_jul25_kolbasa', 'f_cat_jun25_kolbasa', '2025-06-01', '2025-06-30'), kwargs={}\n",
      "2025-09-15 18:05:03,919 - ERROR - Операционная ошибка SELECT (попытка 1): (psycopg2.OperationalError) SSL SYSCALL error: EOF detected\n",
      "\n",
      "[SQL: SELECT count(1) FROM BA.T_ZIG_SPR_IDN_ACTN WHERE ACTN_NAME = 'ЛК_Колбасы2_июль25_тест';]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "2025-09-15 18:05:03,922 - INFO - Повторная попытка через 30 секунд...\n",
      "2025-09-15 18:05:36,591 - INFO - Функция create_kg завершена успешно.\n",
      "2025-09-15 18:05:36,593 - INFO - Шаг 3 (kg) выполнен успешно.\n",
      "2025-09-15 18:05:36,593 - INFO - Начало выполнения функции create_spr_actn с args=(<Connector_package.db_connector.GreenPlumConnector object at 0x00000230FDDB34D0>, 'pva_kolbasa_2', 'Механики MAU', 'ЛК_Колбасы2_июль25_тест', 56, 28), kwargs={}\n",
      "2025-09-15 18:05:36,595 - ERROR - Операционная ошибка (попытка 1): SSL SYSCALL error: EOF detected\n",
      "\n",
      "2025-09-15 18:05:36,596 - INFO - Повторная попытка через 30 секунд...\n",
      "2025-09-15 18:06:07,037 - INFO - Успешно подключились к GreenPlum.\n",
      "2025-09-15 18:06:09,372 - INFO - Функция create_spr_actn завершена успешно.\n",
      "2025-09-15 18:06:09,374 - INFO - Шаг 4 (spr_actn) выполнен успешно.\n",
      "2025-09-15 18:06:09,376 - ERROR - Операционная ошибка SELECT (попытка 1): (psycopg2.OperationalError) SSL SYSCALL error: EOF detected\n",
      "\n",
      "[SQL: SELECT Actn_id FROM ba.vt_pva_kolbasa_2_spr_actn WHERE actn_name = 'ЛК_Колбасы2_июль25_тест';]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "2025-09-15 18:06:09,376 - INFO - Повторная попытка через 30 секунд...\n",
      "2025-09-15 18:06:41,725 - INFO - Начало выполнения функции create_days с args=(<Connector_package.db_connector.GreenPlumConnector object at 0x00000230FDDB34D0>, 'pva_kolbasa_2', 2820, '2025-05-06', '2025-08-28'), kwargs={}\n",
      "2025-09-15 18:06:41,992 - ERROR - Операционная ошибка (попытка 1): SSL SYSCALL error: EOF detected\n",
      "\n",
      "2025-09-15 18:06:41,993 - INFO - Повторная попытка через 30 секунд...\n",
      "2025-09-15 18:07:12,485 - INFO - Успешно подключились к GreenPlum.\n",
      "2025-09-15 18:07:13,681 - INFO - Функция create_days завершена успешно.\n",
      "2025-09-15 18:07:13,682 - INFO - Шаг 5 (days) выполнен успешно.\n",
      "2025-09-15 18:07:13,683 - INFO - Начало выполнения функции create_days_cross с args=(<Connector_package.db_connector.GreenPlumConnector object at 0x00000230FDDB34D0>, 'pva_kolbasa_2', 2820, 2820), kwargs={}\n",
      "2025-09-15 18:07:16,426 - ERROR - Операционная ошибка SELECT (попытка 1): (psycopg2.OperationalError) SSL SYSCALL error: EOF detected\n",
      "\n",
      "[SQL: SELECT * FROM ba.vt_pva_kolbasa_2_actn_duble WHERE ACTN_ID = 2820;]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "2025-09-15 18:07:16,430 - INFO - Повторная попытка через 30 секунд...\n",
      "2025-09-15 18:07:47,637 - ERROR - Операционная ошибка (попытка 1): SSL SYSCALL error: EOF detected\n",
      "\n",
      "2025-09-15 18:07:47,639 - INFO - Повторная попытка через 30 секунд...\n",
      "2025-09-15 18:08:18,101 - INFO - Успешно подключились к GreenPlum.\n",
      "2025-09-15 18:08:29,891 - INFO - Функция create_days_cross завершена успешно.\n",
      "2025-09-15 18:08:29,892 - INFO - Шаг 6 (days_cross) выполнен успешно.\n",
      "2025-09-15 18:08:29,893 - INFO - Начало выполнения функции frod с args=(<Connector_package.db_connector.GreenPlumConnector object at 0x00000230FDDB34D0>, 'pva_kolbasa_2'), kwargs={}\n",
      "2025-09-15 18:08:46,310 - INFO - Функция frod завершена успешно.\n",
      "2025-09-15 18:08:46,313 - INFO - Шаг - (frod) выполнен успешно.\n",
      "2025-09-15 18:08:46,315 - INFO - Начало выполнения функции create_trn_0 с args=(<Connector_package.db_connector.GreenPlumConnector object at 0x00000230FDDB34D0>, 'pva_kolbasa_2', 2820, 56), kwargs={}\n",
      "2025-09-15 18:08:46,317 - ERROR - Операционная ошибка SELECT (попытка 1): (psycopg2.OperationalError) SSL SYSCALL error: EOF detected\n",
      "\n",
      "[SQL: \n",
      "            select\n",
      "                    month_id\n",
      "                    ,min(day_id) as min_dt\n",
      "                    ,max(day_id) as max_dt\n",
      "            from\n",
      "                    ba.vt_pva_kolbasa_2_days\n",
      "                where\n",
      "                    actn_id = 2820 \n",
      "                    and actn_period = 1\n",
      "                group by 1 \n",
      "                order by 1\n",
      "            ;]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "2025-09-15 18:08:46,318 - INFO - Повторная попытка через 30 секунд...\n",
      "2025-09-15 18:09:17,333 - ERROR - Операционная ошибка (попытка 1): SSL SYSCALL error: EOF detected\n",
      "\n",
      "2025-09-15 18:09:17,334 - INFO - Повторная попытка через 30 секунд...\n",
      "2025-09-15 18:09:47,794 - INFO - Успешно подключились к GreenPlum.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8c938acabf3447993f86ee015c9bfba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-15 18:11:41,572 - INFO - Функция create_trn_0 завершена успешно.\n",
      "2025-09-15 18:11:41,574 - INFO - Шаг 7 (create_trn_0) выполнен успешно.\n",
      "2025-09-15 18:11:41,576 - INFO - Начало выполнения функции create_trn_0_v2 с args=(<Connector_package.db_connector.GreenPlumConnector object at 0x00000230FDDB34D0>, 'pva_kolbasa_2', 2820, 31), kwargs={}\n",
      "2025-09-15 18:11:41,579 - ERROR - Операционная ошибка SELECT (попытка 1): (psycopg2.OperationalError) SSL SYSCALL error: EOF detected\n",
      "\n",
      "[SQL: \n",
      "            select\n",
      "                    month_id\n",
      "                    ,min(day_id) as min_dt\n",
      "                    ,max(day_id) as max_dt\n",
      "            from\n",
      "                    ba.vt_pva_kolbasa_2_days\n",
      "                where\n",
      "                    actn_id = 2820 \n",
      "                    and actn_period = 2\n",
      "                group by 1 \n",
      "                order by 1\n",
      "            ;]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "2025-09-15 18:11:41,580 - INFO - Повторная попытка через 30 секунд...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c061fce5d7274d848b029c6e9f79ad2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-15 18:12:12,408 - ERROR - Операционная ошибка (попытка 1): SSL SYSCALL error: EOF detected\n",
      "\n",
      "2025-09-15 18:12:12,409 - INFO - Повторная попытка через 30 секунд...\n",
      "2025-09-15 18:12:42,839 - INFO - Успешно подключились к GreenPlum.\n",
      "2025-09-15 18:13:42,792 - INFO - Функция create_trn_0_v2 завершена успешно.\n",
      "2025-09-15 18:13:42,794 - INFO - Шаг 8 (create_trn_0_v2) выполнен успешно.\n",
      "2025-09-15 18:13:42,796 - INFO - Начало выполнения функции create_agg с args=(<Connector_package.db_connector.GreenPlumConnector object at 0x00000230FDDB34D0>, 'pva_kolbasa_2', '2025-07-01'), kwargs={}\n",
      "2025-09-15 18:13:46,464 - ERROR - Операционная ошибка SELECT (попытка 1): (psycopg2.OperationalError) SSL SYSCALL error: EOF detected\n",
      "\n",
      "[SQL: \n",
      "        SELECT is_kg_needed\n",
      "        FROM BA.helper_category\n",
      "        WHERE mask = 'pva_kolbasa_2'\n",
      "    ]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "2025-09-15 18:13:46,467 - INFO - Повторная попытка через 30 секунд...\n",
      "2025-09-15 18:14:17,208 - INFO - [create_agg][mask=pva_kolbasa_2] Начинаем создание таблицы ba.vt_pva_kolbasa_2_trn_1...\n",
      "2025-09-15 18:14:17,211 - ERROR - Операционная ошибка (попытка 1): SSL SYSCALL error: EOF detected\n",
      "\n",
      "2025-09-15 18:14:17,212 - INFO - Повторная попытка через 30 секунд...\n",
      "2025-09-15 18:14:47,638 - INFO - Успешно подключились к GreenPlum.\n",
      "2025-09-15 18:18:39,551 - ERROR - Операционная ошибка SELECT (попытка 1): (psycopg2.OperationalError) SSL SYSCALL error: EOF detected\n",
      "\n",
      "[SQL: \n",
      "        SELECT ACTN_PERIOD, COUNT(DISTINCT CONTACT_ID) AS cnt_cont\n",
      "        FROM ba.vt_pva_kolbasa_2_trn_1\n",
      "        GROUP BY ACTN_PERIOD\n",
      "        ORDER BY ACTN_PERIOD\n",
      "    ]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "2025-09-15 18:18:39,554 - INFO - Повторная попытка через 30 секунд...\n",
      "2025-09-15 18:19:12,329 - INFO - [create_agg][mask=pva_kolbasa_2] Кол-во уникальных клиентов по периодам:\n",
      "   actn_period  cnt_cont\n",
      "0            1  39721112\n",
      "1            2  35891143\n",
      "2025-09-15 18:19:13,261 - INFO - [create_agg][mask=pva_kolbasa_2] Агрегация транзакций (trn_1) завершена.\n",
      "2025-09-15 18:19:13,262 - INFO - Функция create_agg завершена успешно.\n",
      "2025-09-15 18:19:13,263 - INFO - Шаг 9 (create_agg) выполнен успешно.\n",
      "2025-09-15 18:19:13,264 - INFO - Начало выполнения функции process_clear_and_aggregate с args=(<Connector_package.db_connector.GreenPlumConnector object at 0x00000230FDDB34D0>, 'pva_kolbasa_2'), kwargs={}\n",
      "2025-09-15 18:19:13,266 - ERROR - Операционная ошибка (попытка 1): SSL SYSCALL error: EOF detected\n",
      "\n",
      "2025-09-15 18:19:13,267 - INFO - Повторная попытка через 30 секунд...\n",
      "2025-09-15 18:19:43,687 - INFO - Успешно подключились к GreenPlum.\n",
      "2025-09-15 18:19:59,383 - INFO - Функция process_clear_and_aggregate завершена успешно.\n",
      "2025-09-15 18:19:59,385 - INFO - Шаг 10 (process_clear_and_aggregate) выполнен успешно.\n",
      "2025-09-15 18:19:59,386 - INFO - Начало выполнения функции reg_new_returned с args=(<Connector_package.db_connector.GreenPlumConnector object at 0x00000230FDDB34D0>, 'pva_kolbasa_2', '2025-07-01'), kwargs={}\n",
      "2025-09-15 18:20:04,965 - INFO - Функция reg_new_returned завершена успешно.\n",
      "2025-09-15 18:20:04,966 - INFO - Шаг 11 (reg_new_returned) выполнен успешно.\n",
      "2025-09-15 18:20:04,967 - INFO - Начало выполнения функции clear_reg с args=(<Connector_package.db_connector.GreenPlumConnector object at 0x00000230FDDB34D0>, 'pva_kolbasa_2', 2820, 'ЛК_Колбасы2_июль25_тест', 56, 31), kwargs={}\n",
      "2025-09-15 18:20:11,807 - INFO - Функция clear_reg завершена успешно.\n",
      "2025-09-15 18:20:11,808 - INFO - Шаг 12 (clear_reg) выполнен успешно.\n",
      "2025-09-15 18:20:11,809 - INFO - Начало выполнения функции dna с args=(<Connector_package.db_connector.GreenPlumConnector object at 0x00000230FDDB34D0>, 'pva_kolbasa_2', 31), kwargs={}\n",
      "2025-09-15 18:20:13,962 - INFO - Функция dna завершена успешно.\n",
      "2025-09-15 18:20:13,965 - INFO - Шаг 13 (dna) выполнен успешно.\n",
      "2025-09-15 18:20:13,966 - INFO - Начало выполнения функции kg_for_ca с args=(<Connector_package.db_connector.GreenPlumConnector object at 0x00000230FDDB34D0>, 'pva_kolbasa_2', 10), kwargs={}\n",
      "2025-09-15 18:20:32,630 - INFO - Функция kg_for_ca завершена успешно.\n",
      "2025-09-15 18:20:32,632 - INFO - Шаг 14 (kg_for_ca) выполнен успешно.\n",
      "2025-09-15 18:20:32,634 - INFO - Начало выполнения функции cnt_actn с args=(<Connector_package.db_connector.GreenPlumConnector object at 0x00000230FDDB34D0>, 'pva_kolbasa_2', '2025-05-06', '2025-07-01', '2025-07-31', 2820), kwargs={}\n",
      "2025-09-15 18:20:37,773 - INFO - Функция cnt_actn завершена успешно.\n",
      "2025-09-15 18:20:37,774 - INFO - Шаг 14 (cnt_actn) выполнен успешно.\n",
      "2025-09-15 18:20:37,774 - INFO - Начало выполнения функции dynamic_gr20 с args=(<Connector_package.db_connector.GreenPlumConnector object at 0x00000230FDDB34D0>, 'pva_kolbasa_2', 2820), kwargs={}\n",
      "2025-09-15 18:20:37,777 - ERROR - Операционная ошибка SELECT (попытка 1): (psycopg2.OperationalError) SSL SYSCALL error: EOF detected\n",
      "\n",
      "[SQL: \n",
      "           select\n",
      "                month_id\n",
      "                ,min(day_id) as min_dt\n",
      "                ,max(day_id) as max_dt\n",
      "           from\n",
      "                ba.vt_pva_kolbasa_2_days\n",
      "            where\n",
      "                actn_id = 2820 \n",
      "                and actn_period = 1\n",
      "            group by 1 \n",
      "            order by 1\n",
      "        ;]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "2025-09-15 18:20:37,778 - INFO - Повторная попытка через 30 секунд...\n",
      "2025-09-15 18:21:08,853 - ERROR - Операционная ошибка (попытка 1): SSL SYSCALL error: EOF detected\n",
      "\n",
      "2025-09-15 18:21:08,858 - INFO - Повторная попытка через 30 секунд...\n",
      "2025-09-15 18:21:39,304 - INFO - Успешно подключились к GreenPlum.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b0f9bccb2014362989ca49dff7e54a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-15 18:24:19,190 - INFO - Функция dynamic_gr20 завершена успешно.\n",
      "2025-09-15 18:24:19,193 - INFO - Шаг 16 (dynamic_gr20) выполнен успешно.\n",
      "2025-09-15 18:24:19,194 - INFO - Начало выполнения функции gr20_transp с args=(<Connector_package.db_connector.GreenPlumConnector object at 0x00000230FDDB34D0>, 'pva_kolbasa_2'), kwargs={}\n",
      "2025-09-15 18:24:26,748 - INFO - Функция gr20_transp завершена успешно.\n",
      "2025-09-15 18:24:26,752 - INFO - Шаг 17 (gr20_transp) выполнен успешно.\n",
      "2025-09-15 18:24:26,754 - INFO - Начало выполнения функции age_and_active_virt с args=(<Connector_package.db_connector.GreenPlumConnector object at 0x00000230FDDB34D0>, 'pva_kolbasa_2'), kwargs={}\n",
      "2025-09-15 18:24:34,341 - INFO - Функция age_and_active_virt завершена успешно.\n",
      "2025-09-15 18:24:34,342 - INFO - Шаг 18 (age_and_active_virt) выполнен успешно.\n",
      "2025-09-15 18:24:34,344 - INFO - Начало выполнения функции itog с args=(<Connector_package.db_connector.GreenPlumConnector object at 0x00000230FDDB34D0>, 'pva_kolbasa_2', 31), kwargs={}\n",
      "2025-09-15 18:24:39,742 - INFO - Функция itog завершена успешно.\n",
      "2025-09-15 18:24:39,745 - INFO - Шаг 19 (itog) выполнен успешно.\n",
      "2025-09-15 18:24:39,748 - INFO - Начало выполнения функции psm с args=(<Connector_package.db_connector.GreenPlumConnector object at 0x00000230FDDB34D0>, 'pva_kolbasa_2', 'ЛК_Колбасы2_июль25_тест', 2820), kwargs={}\n",
      "2025-09-15 18:24:39,751 - ERROR - Операционная ошибка SELECT (попытка 1): (psycopg2.OperationalError) SSL SYSCALL error: EOF detected\n",
      "\n",
      "[SQL: select distinct FRMT_ID, REGION_ID from ba.vt_pva_kolbasa_2_cus_profile order by FRMT_ID desc;]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "2025-09-15 18:24:39,753 - INFO - Повторная попытка через 30 секунд...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Доля мэтчинга ЛФЛ ЦА/КГ:\n",
      "\n",
      "Загрузка данных frmt_id=104, region_id=180 батчами...\n",
      "Загружено всего строк: 100000, в текущем батче: 16407\n",
      "104 180 [96.24853458]\n",
      "\n",
      "Загрузка данных frmt_id=104, region_id=247 батчами...\n",
      "Загружено всего строк: 100000, в текущем батче: 12050\n",
      "104 247 [96.4360587]\n",
      "\n",
      "Загрузка данных frmt_id=104, region_id=275 батчами...\n",
      "Загружено всего строк: 100000, в текущем батче: 13817\n",
      "104 275 [96.75516224]\n",
      "\n",
      "Загрузка данных frmt_id=104, region_id=227 батчами...\n",
      "Загружено всего строк: 100000, в текущем батче: 17511\n",
      "104 227 [97.56097561]\n",
      "\n",
      "Загрузка данных frmt_id=104, region_id=197 батчами...\n",
      "Загружено всего строк: 100000, в текущем батче: 8817\n",
      "104 197 [93.47408829]\n",
      "\n",
      "Загрузка данных frmt_id=104, region_id=280 батчами...\n",
      "Загружено всего строк: 100000, в текущем батче: 25644\n",
      "104 280 [98.11557789]\n",
      "\n",
      "Загрузка данных frmt_id=104, region_id=284 батчами...\n",
      "Загружено всего строк: 100000, в текущем батче: 17577\n",
      "104 284 [97.8021978]\n",
      "\n",
      "Загрузка данных frmt_id=104, region_id=173 батчами...\n",
      "Загружено всего строк: 100000, в текущем батче: 14528\n",
      "104 173 [96.90265487]\n",
      "\n",
      "Загрузка данных frmt_id=3, region_id=180 батчами...\n",
      "Загружено всего строк: 100000, в текущем батче: 100000\n",
      "Загружено всего строк: 200000, в текущем батче: 100000\n",
      "Загружено всего строк: 300000, в текущем батче: 100000\n",
      "Загружено всего строк: 400000, в текущем батче: 100000\n",
      "Загружено всего строк: 500000, в текущем батче: 100000\n",
      "Загружено всего строк: 600000, в текущем батче: 92543\n",
      "3 180 [93.95620438]\n",
      "\n",
      "Загрузка данных frmt_id=3, region_id=247 батчами...\n",
      "Загружено всего строк: 100000, в текущем батче: 100000\n",
      "Загружено всего строк: 200000, в текущем батче: 97313\n",
      "3 247 [98.48748261]\n",
      "\n",
      "Загрузка данных frmt_id=3, region_id=275 батчами...\n",
      "Загружено всего строк: 100000, в текущем батче: 100000\n",
      "Загружено всего строк: 200000, в текущем батче: 100000\n",
      "Загружено всего строк: 300000, в текущем батче: 100000\n",
      "Загружено всего строк: 400000, в текущем батче: 100000\n",
      "Загружено всего строк: 500000, в текущем батче: 100000\n",
      "Загружено всего строк: 600000, в текущем батче: 100000\n",
      "Загружено всего строк: 700000, в текущем батче: 28737\n",
      "3 275 [95.11702568]\n",
      "\n",
      "Загрузка данных frmt_id=3, region_id=227 батчами...\n",
      "Загружено всего строк: 100000, в текущем батче: 100000\n",
      "Загружено всего строк: 200000, в текущем батче: 100000\n",
      "Загружено всего строк: 300000, в текущем батче: 100000\n",
      "Загружено всего строк: 400000, в текущем батче: 100000\n",
      "Загружено всего строк: 500000, в текущем батче: 100000\n",
      "Загружено всего строк: 600000, в текущем батче: 7153\n",
      "3 227 [97.62149348]\n",
      "\n",
      "Загрузка данных frmt_id=3, region_id=197 батчами...\n",
      "Загружено всего строк: 100000, в текущем батче: 100000\n",
      "Загружено всего строк: 200000, в текущем батче: 100000\n",
      "Загружено всего строк: 300000, в текущем батче: 33748\n",
      "3 197 [96.30705897]\n",
      "\n",
      "Загрузка данных frmt_id=3, region_id=280 батчами...\n",
      "Загружено всего строк: 100000, в текущем батче: 100000\n",
      "Загружено всего строк: 200000, в текущем батче: 100000\n",
      "Загружено всего строк: 300000, в текущем батче: 100000\n",
      "Загружено всего строк: 400000, в текущем батче: 100000\n",
      "Загружено всего строк: 500000, в текущем батче: 100000\n",
      "Загружено всего строк: 600000, в текущем батче: 50343\n",
      "3 280 [97.25023705]\n",
      "\n",
      "Загрузка данных frmt_id=3, region_id=284 батчами...\n",
      "Загружено всего строк: 100000, в текущем батче: 100000\n",
      "Загружено всего строк: 200000, в текущем батче: 100000\n",
      "Загружено всего строк: 300000, в текущем батче: 100000\n",
      "Загружено всего строк: 400000, в текущем батче: 100000\n",
      "Загружено всего строк: 500000, в текущем батче: 100000\n",
      "Загружено всего строк: 600000, в текущем батче: 100000\n",
      "Загружено всего строк: 700000, в текущем батче: 52505\n",
      "3 284 [96.70582945]\n",
      "\n",
      "Загрузка данных frmt_id=3, region_id=173 батчами...\n",
      "Загружено всего строк: 100000, в текущем батче: 100000\n",
      "Загружено всего строк: 200000, в текущем батче: 100000\n",
      "Загружено всего строк: 300000, в текущем батче: 16549\n",
      "3 173 [96.86628602]\n",
      "\n",
      "Загрузка данных frmt_id=2, region_id=180 батчами...\n",
      "Загружено всего строк: 100000, в текущем батче: 100000\n",
      "Загружено всего строк: 200000, в текущем батче: 100000\n",
      "Загружено всего строк: 300000, в текущем батче: 100000\n",
      "Загружено всего строк: 400000, в текущем батче: 100000\n",
      "Загружено всего строк: 500000, в текущем батче: 73370\n",
      "2 180 [95.13764548]\n",
      "\n",
      "Загрузка данных frmt_id=2, region_id=247 батчами...\n",
      "Загружено всего строк: 100000, в текущем батче: 97984\n",
      "2 247 [95.83828775]\n",
      "\n",
      "Загрузка данных frmt_id=2, region_id=275 батчами...\n",
      "Загружено всего строк: 100000, в текущем батче: 100000\n",
      "Загружено всего строк: 200000, в текущем батче: 100000\n",
      "Загружено всего строк: 300000, в текущем батче: 100000\n",
      "Загружено всего строк: 400000, в текущем батче: 100000\n",
      "Загружено всего строк: 500000, в текущем батче: 60623\n",
      "2 275 [95.30066671]\n",
      "\n",
      "Загрузка данных frmt_id=2, region_id=227 батчами...\n",
      "Загружено всего строк: 100000, в текущем батче: 100000\n",
      "Загружено всего строк: 200000, в текущем батче: 68642\n",
      "2 227 [94.95334222]\n",
      "\n",
      "Загрузка данных frmt_id=2, region_id=197 батчами...\n",
      "Загружено всего строк: 100000, в текущем батче: 100000\n",
      "Загружено всего строк: 200000, в текущем батче: 86354\n",
      "2 197 [94.77793421]\n",
      "\n",
      "Загрузка данных frmt_id=2, region_id=280 батчами...\n",
      "Загружено всего строк: 100000, в текущем батче: 100000\n",
      "Загружено всего строк: 200000, в текущем батче: 40490\n",
      "2 280 [93.42413279]\n",
      "\n",
      "Загрузка данных frmt_id=2, region_id=284 батчами...\n",
      "Загружено всего строк: 100000, в текущем батче: 100000\n",
      "Загружено всего строк: 200000, в текущем батче: 100000\n",
      "Загружено всего строк: 300000, в текущем батче: 46862\n",
      "2 284 [93.94892439]\n",
      "\n",
      "Загрузка данных frmt_id=2, region_id=173 батчами...\n",
      "Загружено всего строк: 100000, в текущем батче: 68827\n",
      "2 173 [93.82003396]\n",
      "\n",
      "Загрузка данных frmt_id=1, region_id=180 батчами...\n",
      "Загружено всего строк: 100000, в текущем батче: 100000\n",
      "Загружено всего строк: 200000, в текущем батче: 100000\n",
      "Загружено всего строк: 300000, в текущем батче: 100000\n",
      "Загружено всего строк: 400000, в текущем батче: 100000\n",
      "Загружено всего строк: 500000, в текущем батче: 100000\n",
      "Загружено всего строк: 600000, в текущем батче: 41994\n",
      "1 180 [78.38929664]\n",
      "\n",
      "Загрузка данных frmt_id=1, region_id=247 батчами...\n",
      "Загружено всего строк: 100000, в текущем батче: 100000\n",
      "Загружено всего строк: 200000, в текущем батче: 100000\n",
      "Загружено всего строк: 300000, в текущем батче: 100000\n",
      "Загружено всего строк: 400000, в текущем батче: 45929\n",
      "1 247 [81.74558259]\n",
      "\n",
      "Загрузка данных frmt_id=1, region_id=275 батчами...\n",
      "Загружено всего строк: 100000, в текущем батче: 100000\n",
      "Загружено всего строк: 200000, в текущем батче: 100000\n",
      "Загружено всего строк: 300000, в текущем батче: 100000\n",
      "Загружено всего строк: 400000, в текущем батче: 100000\n",
      "Загружено всего строк: 500000, в текущем батче: 100000\n",
      "Загружено всего строк: 600000, в текущем батче: 100000\n",
      "Загружено всего строк: 700000, в текущем батче: 100000\n",
      "Загружено всего строк: 800000, в текущем батче: 100000\n",
      "Загружено всего строк: 900000, в текущем батче: 44740\n",
      "1 275 [80.04040712]\n",
      "\n",
      "Загрузка данных frmt_id=1, region_id=227 батчами...\n",
      "Загружено всего строк: 100000, в текущем батче: 100000\n",
      "Загружено всего строк: 200000, в текущем батче: 100000\n",
      "Загружено всего строк: 300000, в текущем батче: 100000\n",
      "Загружено всего строк: 400000, в текущем батче: 100000\n",
      "Загружено всего строк: 500000, в текущем батче: 70232\n",
      "1 227 [79.3566672]\n",
      "\n",
      "Загрузка данных frmt_id=1, region_id=197 батчами...\n",
      "Загружено всего строк: 100000, в текущем батче: 100000\n",
      "Загружено всего строк: 200000, в текущем батче: 100000\n",
      "Загружено всего строк: 300000, в текущем батче: 100000\n",
      "Загружено всего строк: 400000, в текущем батче: 19510\n",
      "1 197 [81.82093062]\n",
      "\n",
      "Загрузка данных frmt_id=1, region_id=280 батчами...\n",
      "Загружено всего строк: 100000, в текущем батче: 100000\n",
      "Загружено всего строк: 200000, в текущем батче: 100000\n",
      "Загружено всего строк: 300000, в текущем батче: 100000\n",
      "Загружено всего строк: 400000, в текущем батче: 100000\n",
      "Загружено всего строк: 500000, в текущем батче: 100000\n",
      "Загружено всего строк: 600000, в текущем батче: 100000\n",
      "Загружено всего строк: 700000, в текущем батче: 17102\n",
      "1 280 [78.37579955]\n",
      "\n",
      "Загрузка данных frmt_id=1, region_id=284 батчами...\n",
      "Загружено всего строк: 100000, в текущем батче: 100000\n",
      "Загружено всего строк: 200000, в текущем батче: 100000\n",
      "Загружено всего строк: 300000, в текущем батче: 100000\n",
      "Загружено всего строк: 400000, в текущем батче: 100000\n",
      "Загружено всего строк: 500000, в текущем батче: 100000\n",
      "Загружено всего строк: 600000, в текущем батче: 100000\n",
      "Загружено всего строк: 700000, в текущем батче: 98793\n",
      "1 284 [78.25216811]\n",
      "\n",
      "Загрузка данных frmt_id=1, region_id=173 батчами...\n",
      "Загружено всего строк: 100000, в текущем батче: 100000\n",
      "Загружено всего строк: 200000, в текущем батче: 100000\n",
      "Загружено всего строк: 300000, в текущем батче: 100000\n",
      "Загружено всего строк: 400000, в текущем батче: 100000\n",
      "Загружено всего строк: 500000, в текущем батче: 34637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-15 19:04:58,014 - ERROR - Операционная ошибка (попытка 1): SSL SYSCALL error: EOF detected\n",
      "\n",
      "2025-09-15 19:04:58,015 - INFO - Повторная попытка через 30 секунд...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 173 [81.0288216]\n",
      "Процесс завершен.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-15 19:05:28,438 - INFO - Успешно подключились к GreenPlum.\n",
      "2025-09-15 19:05:29,718 - INFO - Успешно вставлено 32 строк в таблицу ba.vt_pva_kolbasa_2_stat_temp за 0.542 сек.\n",
      "2025-09-15 19:05:30,892 - ERROR - Операционная ошибка SELECT (попытка 1): (psycopg2.OperationalError) SSL SYSCALL error: EOF detected\n",
      "\n",
      "[SQL: SELECT count(1) FROM BA.T_ZIG_STAT_TEST_PSM where ACTN_NAME = 'ЛК_Колбасы2_июль25_тест';]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "2025-09-15 19:05:30,893 - INFO - Повторная попытка через 30 секунд...\n",
      "2025-09-15 19:06:01,884 - ERROR - Операционная ошибка (попытка 1): SSL SYSCALL error: EOF detected\n",
      "\n",
      "2025-09-15 19:06:01,885 - INFO - Повторная попытка через 30 секунд...\n",
      "2025-09-15 19:06:32,305 - INFO - Успешно подключились к GreenPlum.\n",
      "2025-09-15 19:06:45,567 - INFO - Успешно вставлено 956782 строк в таблицу ba.vt_pva_kolbasa_2_cus_temp за 11.531 сек.\n",
      "2025-09-15 19:06:56,794 - INFO - Функция psm завершена успешно.\n",
      "2025-09-15 19:06:56,797 - INFO - Шаг 20 (psm) выполнен успешно.\n",
      "2025-09-15 19:06:56,799 - INFO - Начало выполнения функции metrics_act с args=(<Connector_package.db_connector.GreenPlumConnector object at 0x00000230FDDB34D0>, 'pva_kolbasa_2', 'kolbasa', 2820, '2025-07-01', '2025-07-31', 2), kwargs={}\n",
      "2025-09-15 19:16:08,738 - INFO - Функция metrics_act завершена успешно.\n",
      "2025-09-15 19:16:08,744 - INFO - Начало выполнения функции metrics_prev с args=(<Connector_package.db_connector.GreenPlumConnector object at 0x00000230FDDB34D0>, 'pva_kolbasa_2', 'kolbasa', 2820, '2025-06-01', '2025-06-30', 2), kwargs={}\n",
      "2025-09-15 19:24:28,803 - INFO - Функция metrics_prev завершена успешно.\n",
      "2025-09-15 19:24:28,809 - INFO - Начало выполнения функции ca_metrics с args=(<Connector_package.db_connector.GreenPlumConnector object at 0x00000230FDDB34D0>, 'pva_kolbasa_2', 'kolbasa', 2), kwargs={}\n",
      "2025-09-15 19:24:28,812 - ERROR - Операционная ошибка SELECT (попытка 1): (psycopg2.OperationalError) SSL SYSCALL error: EOF detected\n",
      "\n",
      "[SQL: \n",
      "        select * from ba.vt_pva_kolbasa_2_kolbasa_2_total_metrics_prev\n",
      "        where is_ca = 1;\n",
      "    ]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "2025-09-15 19:24:28,815 - INFO - Повторная попытка через 30 секунд...\n",
      "2025-09-15 19:24:59,818 - INFO - Функция ca_metrics завершена успешно.\n",
      "2025-09-15 19:24:59,820 - INFO - Начало выполнения функции kg_metrics с args=(<Connector_package.db_connector.GreenPlumConnector object at 0x00000230FDDB34D0>, 'pva_kolbasa_2', 'kolbasa', 2), kwargs={}\n",
      "2025-09-15 19:25:00,324 - INFO - Функция kg_metrics завершена успешно.\n",
      "2025-09-15 19:25:03,906 - INFO - Начало выполнения функции unique_clients_ca с args=(<Connector_package.db_connector.GreenPlumConnector object at 0x00000230FDDB34D0>, 'pva_kolbasa_2', 2820), kwargs={}\n",
      "2025-09-15 19:25:07,176 - INFO - Функция unique_clients_ca завершена успешно.\n",
      "2025-09-15 19:25:07,179 - INFO - Начало выполнения функции unique_clients_kg с args=(<Connector_package.db_connector.GreenPlumConnector object at 0x00000230FDDB34D0>, 'pva_kolbasa_2', 2820), kwargs={}\n",
      "2025-09-15 19:25:10,371 - INFO - Функция unique_clients_kg завершена успешно.\n",
      "2025-09-15 19:25:12,019 - INFO - Начало выполнения функции delete_tables с args=(<Connector_package.db_connector.GreenPlumConnector object at 0x00000230FDDB34D0>, 'pva_kolbasa_2'), kwargs={}\n",
      "2025-09-15 19:25:13,935 - ERROR - Операционная ошибка (попытка 1): SSL SYSCALL error: EOF detected\n",
      "\n",
      "2025-09-15 19:25:13,936 - INFO - Повторная попытка через 30 секунд...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Кол-во таблиц до фильтрации: 46\n",
      "Кол-во таблиц после фильтрации: 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-15 19:25:44,354 - INFO - Успешно подключились к GreenPlum.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Таблица ba.tmp_pva_kolbasa_2_kolbasa_articles удалена\n",
      "Таблица ba.tmp_pva_kolbasa_2_kolbasa_buyers_act_prev удалена\n",
      "Таблица ba.vt_pva_kolbasa_2_cus_ruls удалена\n",
      "Таблица ba.tmp_pva_kolbasa_2_kolbasa_buyers_act удалена\n",
      "Таблица ba.tmp_pva_kolbasa_2_kolbasa_offer_accept_act удалена\n",
      "Таблица ba.tmp_pva_kolbasa_2_kolbasa_offer_accept_prev удалена\n",
      "Таблица ba.vt_pva_kolbasa_2_cus_ctrl удалена\n",
      "Таблица ba.pva_kolbasa_2_ca_and_kg удалена\n",
      "Таблица ba.vt_pva_kolbasa_2_promo_week удалена\n",
      "Таблица ba.vt_pva_kolbasa_2_actn_duble удалена\n",
      "Таблица ba.vt_pva_kolbasa_2_frod удалена\n",
      "Таблица ba.vt_pva_kolbasa_2_trn_0 удалена\n",
      "Таблица ba.vt_pva_kolbasa_2_trn_1 удалена\n",
      "Таблица ba.vt_pva_kolbasa_2_ca_clear удалена\n",
      "Таблица ba.vt_pva_kolbasa_2_cus_clear удалена\n",
      "Таблица ba.vt_pva_kolbasa_2_trn удалена\n",
      "Таблица ba.vt_pva_kolbasa_2_cus_type удалена\n",
      "Таблица ba.vt_pva_kolbasa_2_cus_reg удалена\n",
      "Таблица ba.vt_pva_kolbasa_2_ca_frmt удалена\n",
      "Таблица ba.vt_pva_kolbasa_2_kg_frmt удалена\n",
      "Таблица ba.vt_pva_kolbasa_2_ca_frmt_grp удалена\n",
      "Таблица ba.vt_pva_kolbasa_2_kg_lfl_frmt удалена\n",
      "Таблица ba.vt_pva_kolbasa_2_ca_lfl_frmt удалена\n",
      "Таблица ba.vt_pva_kolbasa_2_ca_cg удалена\n",
      "Таблица ba.vt_pva_kolbasa_2_cnt_actn удалена\n",
      "Таблица ba.vt_pva_kolbasa_2_cus_gr_0 удалена\n",
      "Таблица ba.vt_pva_kolbasa_2_trn_temp удалена\n",
      "Таблица ba.vt_pva_kolbasa_2_cus_gr удалена\n",
      "Таблица ba.vt_pva_kolbasa_2_cus_gr_transp удалена\n",
      "Таблица ba.vt_pva_kolbasa_2_cus_gender удалена\n",
      "Таблица ba.vt_pva_kolbasa_2_cus_virt удалена\n",
      "Таблица ba.vt_pva_kolbasa_2_cus_profile удалена\n",
      "Таблица ba.vt_pva_kolbasa_2_stat_temp удалена\n",
      "Таблица ba.vt_pva_kolbasa_2_cus_temp удалена\n",
      "Таблица ba.vt_pva_kolbasa_2_cus удалена\n",
      "Таблица ba.tmp_pva_kolbasa_2_kolbasa_2_cheques_act удалена\n",
      "Таблица ba.tmp_pva_kolbasa_2_kolbasa_2_cheques_act_contacts удалена\n",
      "Таблица ba.vt_pva_kolbasa_2_kolbasa_2_total_metrics_act удалена\n",
      "Таблица ba.tmp_pva_kolbasa_2_kolbasa_2_2820_contact удалена\n",
      "Таблица ba.tmp_pva_kolbasa_2_kolbasa_2_cheques_prev удалена\n",
      "Таблица ba.tmp_pva_kolbasa_2_kolbasa_2_cheques_prev_contacts удалена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-15 19:25:52,120 - INFO - Функция delete_tables завершена успешно.\n",
      "2025-09-15 19:25:52,123 - INFO - Шаг 21 (delete_tables) выполнен успешно.\n",
      "2025-09-15 19:25:52,125 - INFO - [process_action][mask = pva_kolbasa_2] Обработка акции 'ЛК_Колбасы2_июль25_тест' завершена успешно.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Таблица ba.vt_pva_kolbasa_2_kolbasa_2_total_metrics_prev удалена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-15 19:25:52,359 - INFO - [run_all_actions][type=kolbasa, version=2] Отмечена как обработанная.\n",
      "2025-09-15 19:25:52,362 - ERROR - Операционная ошибка SELECT (попытка 1): (psycopg2.OperationalError) SSL SYSCALL error: EOF detected\n",
      "\n",
      "[SQL: \n",
      "                SELECT is_processed\n",
      "                FROM BA.helper_category\n",
      "                WHERE type = 'kolbasa' AND version = 3\n",
      "                LIMIT 1\n",
      "            ]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "2025-09-15 19:25:52,365 - INFO - Повторная попытка через 30 секунд...\n",
      "2025-09-15 19:26:23,319 - INFO - [process_action][type = kolbasa] Начинаем обработку акции 'ЛК_Колбасы3_июль25_тест'.\n",
      "2025-09-15 19:26:23,322 - INFO - Начало выполнения функции create_whs с args=(<Connector_package.db_connector.GreenPlumConnector object at 0x00000230FDDB34D0>, 'pva_kolbasa_3'), kwargs={}\n",
      "2025-09-15 19:26:23,324 - ERROR - Операционная ошибка (попытка 1): SSL SYSCALL error: EOF detected\n",
      "\n",
      "2025-09-15 19:26:23,326 - INFO - Повторная попытка через 30 секунд...\n",
      "2025-09-15 19:26:53,737 - INFO - Успешно подключились к GreenPlum.\n",
      "2025-09-15 19:26:54,324 - INFO - Функция create_whs завершена успешно.\n",
      "2025-09-15 19:26:54,325 - INFO - Шаг 1 (whs) выполнен успешно.\n",
      "2025-09-15 19:26:54,326 - INFO - Начало выполнения функции create_cus_ruls с args=(<Connector_package.db_connector.GreenPlumConnector object at 0x00000230FDDB34D0>, 'pva_kolbasa_3', 'Вареные колбасы; Ветчина; Копченые колбасные изделия; Сыровяленые колбасы; Сырокопченые колбасы', 'lvl2', '2025-07-01', '2025-07-31', 'ЛК_Колбасы3_июль25_тест', 'kolbasa', 3, 'f_cat_jul25_kolbasa', 'f_cat_jun25_kolbasa', '2025-06-01', '2025-06-30'), kwargs={}\n",
      "2025-09-15 19:26:54,718 - ERROR - Операционная ошибка SELECT (попытка 1): (psycopg2.OperationalError) SSL SYSCALL error: EOF detected\n",
      "\n",
      "[SQL: SELECT COUNT(*) FROM ba.tmp_pva_kolbasa_3_kolbasa_articles;]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "2025-09-15 19:26:54,719 - INFO - Повторная попытка через 30 секунд...\n",
      "2025-09-15 19:27:25,403 - ERROR - Операционная ошибка (попытка 1): SSL SYSCALL error: EOF detected\n",
      "\n",
      "2025-09-15 19:27:25,406 - INFO - Повторная попытка через 30 секунд...\n",
      "2025-09-15 19:27:55,828 - INFO - Успешно подключились к GreenPlum.\n",
      "2025-09-15 19:34:48,150 - INFO - Функция create_cus_ruls завершена успешно.\n",
      "2025-09-15 19:34:48,153 - INFO - Шаг 2 (cus_ruls) выполнен успешно.\n",
      "2025-09-15 19:34:48,156 - INFO - Начало выполнения функции create_kg с args=(<Connector_package.db_connector.GreenPlumConnector object at 0x00000230FDDB34D0>, 'pva_kolbasa_3', 'ЛК_Колбасы3_июль25_тест', 'Вареные колбасы; Ветчина; Копченые колбасные изделия; Сыровяленые колбасы; Сырокопченые колбасы', '2025-07-01', '2025-07-31', 'kolbasa', 'f_cat_jul25_kolbasa', 'f_cat_jun25_kolbasa', '2025-06-01', '2025-06-30'), kwargs={}\n",
      "2025-09-15 19:41:56,190 - ERROR - Операционная ошибка SELECT (попытка 1): (psycopg2.OperationalError) SSL SYSCALL error: EOF detected\n",
      "\n",
      "[SQL: SELECT count(1) FROM BA.T_ZIG_SPR_IDN_ACTN WHERE ACTN_NAME = 'ЛК_Колбасы3_июль25_тест';]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "2025-09-15 19:41:56,193 - INFO - Повторная попытка через 30 секунд...\n",
      "2025-09-15 19:42:28,284 - INFO - Функция create_kg завершена успешно.\n",
      "2025-09-15 19:42:28,287 - INFO - Шаг 3 (kg) выполнен успешно.\n",
      "2025-09-15 19:42:28,289 - INFO - Начало выполнения функции create_spr_actn с args=(<Connector_package.db_connector.GreenPlumConnector object at 0x00000230FDDB34D0>, 'pva_kolbasa_3', 'Механики MAU', 'ЛК_Колбасы3_июль25_тест', 56, 28), kwargs={}\n",
      "2025-09-15 19:42:28,293 - ERROR - Операционная ошибка (попытка 1): SSL SYSCALL error: EOF detected\n",
      "\n",
      "2025-09-15 19:42:28,296 - INFO - Повторная попытка через 30 секунд...\n",
      "2025-09-15 19:42:58,713 - INFO - Успешно подключились к GreenPlum.\n",
      "2025-09-15 19:43:01,072 - INFO - Функция create_spr_actn завершена успешно.\n",
      "2025-09-15 19:43:01,075 - INFO - Шаг 4 (spr_actn) выполнен успешно.\n",
      "2025-09-15 19:43:01,080 - ERROR - Операционная ошибка SELECT (попытка 1): (psycopg2.OperationalError) SSL SYSCALL error: EOF detected\n",
      "\n",
      "[SQL: SELECT Actn_id FROM ba.vt_pva_kolbasa_3_spr_actn WHERE actn_name = 'ЛК_Колбасы3_июль25_тест';]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "2025-09-15 19:43:01,082 - INFO - Повторная попытка через 30 секунд...\n",
      "2025-09-15 19:43:32,962 - INFO - Начало выполнения функции create_days с args=(<Connector_package.db_connector.GreenPlumConnector object at 0x00000230FDDB34D0>, 'pva_kolbasa_3', 2834, '2025-05-06', '2025-08-28'), kwargs={}\n",
      "2025-09-15 19:43:33,219 - ERROR - Операционная ошибка (попытка 1): SSL SYSCALL error: EOF detected\n",
      "\n",
      "2025-09-15 19:43:33,221 - INFO - Повторная попытка через 30 секунд...\n",
      "2025-09-15 19:44:03,637 - INFO - Успешно подключились к GreenPlum.\n",
      "2025-09-15 19:44:05,094 - INFO - Функция create_days завершена успешно.\n",
      "2025-09-15 19:44:05,096 - INFO - Шаг 5 (days) выполнен успешно.\n",
      "2025-09-15 19:44:05,098 - INFO - Начало выполнения функции create_days_cross с args=(<Connector_package.db_connector.GreenPlumConnector object at 0x00000230FDDB34D0>, 'pva_kolbasa_3', 2834, 2834), kwargs={}\n",
      "2025-09-15 19:44:07,445 - ERROR - Операционная ошибка SELECT (попытка 1): (psycopg2.OperationalError) SSL SYSCALL error: EOF detected\n",
      "\n",
      "[SQL: SELECT * FROM ba.vt_pva_kolbasa_3_actn_duble WHERE ACTN_ID = 2834;]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "2025-09-15 19:44:07,447 - INFO - Повторная попытка через 30 секунд...\n",
      "2025-09-15 19:44:38,227 - ERROR - Операционная ошибка (попытка 1): SSL SYSCALL error: EOF detected\n",
      "\n",
      "2025-09-15 19:44:38,230 - INFO - Повторная попытка через 30 секунд...\n",
      "2025-09-15 19:45:08,643 - INFO - Успешно подключились к GreenPlum.\n",
      "2025-09-15 19:45:18,216 - INFO - Функция create_days_cross завершена успешно.\n",
      "2025-09-15 19:45:18,218 - INFO - Шаг 6 (days_cross) выполнен успешно.\n",
      "2025-09-15 19:45:18,219 - INFO - Начало выполнения функции frod с args=(<Connector_package.db_connector.GreenPlumConnector object at 0x00000230FDDB34D0>, 'pva_kolbasa_3'), kwargs={}\n",
      "2025-09-15 19:45:27,395 - INFO - Функция frod завершена успешно.\n",
      "2025-09-15 19:45:27,396 - INFO - Шаг - (frod) выполнен успешно.\n",
      "2025-09-15 19:45:27,397 - INFO - Начало выполнения функции create_trn_0 с args=(<Connector_package.db_connector.GreenPlumConnector object at 0x00000230FDDB34D0>, 'pva_kolbasa_3', 2834, 56), kwargs={}\n",
      "2025-09-15 19:45:27,399 - ERROR - Операционная ошибка SELECT (попытка 1): (psycopg2.OperationalError) SSL SYSCALL error: EOF detected\n",
      "\n",
      "[SQL: \n",
      "            select\n",
      "                    month_id\n",
      "                    ,min(day_id) as min_dt\n",
      "                    ,max(day_id) as max_dt\n",
      "            from\n",
      "                    ba.vt_pva_kolbasa_3_days\n",
      "                where\n",
      "                    actn_id = 2834 \n",
      "                    and actn_period = 1\n",
      "                group by 1 \n",
      "                order by 1\n",
      "            ;]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "2025-09-15 19:45:27,401 - INFO - Повторная попытка через 30 секунд...\n",
      "2025-09-15 19:45:58,141 - ERROR - Операционная ошибка (попытка 1): SSL SYSCALL error: EOF detected\n",
      "\n",
      "2025-09-15 19:45:58,143 - INFO - Повторная попытка через 30 секунд...\n",
      "2025-09-15 19:46:28,570 - INFO - Успешно подключились к GreenPlum.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4a242144a0e4137bd337ed74b6d98a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-15 19:48:31,181 - INFO - Функция create_trn_0 завершена успешно.\n",
      "2025-09-15 19:48:31,183 - INFO - Шаг 7 (create_trn_0) выполнен успешно.\n",
      "2025-09-15 19:48:31,184 - INFO - Начало выполнения функции create_trn_0_v2 с args=(<Connector_package.db_connector.GreenPlumConnector object at 0x00000230FDDB34D0>, 'pva_kolbasa_3', 2834, 31), kwargs={}\n",
      "2025-09-15 19:48:31,187 - ERROR - Операционная ошибка SELECT (попытка 1): (psycopg2.OperationalError) SSL SYSCALL error: EOF detected\n",
      "\n",
      "[SQL: \n",
      "            select\n",
      "                    month_id\n",
      "                    ,min(day_id) as min_dt\n",
      "                    ,max(day_id) as max_dt\n",
      "            from\n",
      "                    ba.vt_pva_kolbasa_3_days\n",
      "                where\n",
      "                    actn_id = 2834 \n",
      "                    and actn_period = 2\n",
      "                group by 1 \n",
      "                order by 1\n",
      "            ;]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "2025-09-15 19:48:31,188 - INFO - Повторная попытка через 30 секунд...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9fa14f712f449cabe8b0af916a0b022",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-15 19:49:02,212 - ERROR - Операционная ошибка (попытка 1): SSL SYSCALL error: EOF detected\n",
      "\n",
      "2025-09-15 19:49:02,213 - INFO - Повторная попытка через 30 секунд...\n",
      "2025-09-15 19:49:32,655 - INFO - Успешно подключились к GreenPlum.\n",
      "2025-09-15 19:50:36,866 - INFO - Функция create_trn_0_v2 завершена успешно.\n",
      "2025-09-15 19:50:36,868 - INFO - Шаг 8 (create_trn_0_v2) выполнен успешно.\n",
      "2025-09-15 19:50:36,869 - INFO - Начало выполнения функции create_agg с args=(<Connector_package.db_connector.GreenPlumConnector object at 0x00000230FDDB34D0>, 'pva_kolbasa_3', '2025-07-01'), kwargs={}\n",
      "2025-09-15 19:50:40,047 - ERROR - Операционная ошибка SELECT (попытка 1): (psycopg2.OperationalError) SSL SYSCALL error: EOF detected\n",
      "\n",
      "[SQL: \n",
      "        SELECT is_kg_needed\n",
      "        FROM BA.helper_category\n",
      "        WHERE mask = 'pva_kolbasa_3'\n",
      "    ]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "2025-09-15 19:50:40,048 - INFO - Повторная попытка через 30 секунд...\n",
      "2025-09-15 19:51:11,067 - INFO - [create_agg][mask=pva_kolbasa_3] Начинаем создание таблицы ba.vt_pva_kolbasa_3_trn_1...\n",
      "2025-09-15 19:51:11,069 - ERROR - Операционная ошибка (попытка 1): SSL SYSCALL error: EOF detected\n",
      "\n",
      "2025-09-15 19:51:11,071 - INFO - Повторная попытка через 30 секунд...\n",
      "2025-09-15 19:51:41,503 - INFO - Успешно подключились к GreenPlum.\n",
      "2025-09-15 19:55:00,899 - ERROR - Операционная ошибка SELECT (попытка 1): (psycopg2.OperationalError) SSL SYSCALL error: EOF detected\n",
      "\n",
      "[SQL: \n",
      "        SELECT ACTN_PERIOD, COUNT(DISTINCT CONTACT_ID) AS cnt_cont\n",
      "        FROM ba.vt_pva_kolbasa_3_trn_1\n",
      "        GROUP BY ACTN_PERIOD\n",
      "        ORDER BY ACTN_PERIOD\n",
      "    ]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "2025-09-15 19:55:00,901 - INFO - Повторная попытка через 30 секунд...\n",
      "2025-09-15 19:55:32,835 - INFO - [create_agg][mask=pva_kolbasa_3] Кол-во уникальных клиентов по периодам:\n",
      "   actn_period  cnt_cont\n",
      "0            1  39721112\n",
      "1            2  35891143\n",
      "2025-09-15 19:55:33,472 - INFO - [create_agg][mask=pva_kolbasa_3] Агрегация транзакций (trn_1) завершена.\n",
      "2025-09-15 19:55:33,475 - INFO - Функция create_agg завершена успешно.\n",
      "2025-09-15 19:55:33,476 - INFO - Шаг 9 (create_agg) выполнен успешно.\n",
      "2025-09-15 19:55:33,478 - INFO - Начало выполнения функции process_clear_and_aggregate с args=(<Connector_package.db_connector.GreenPlumConnector object at 0x00000230FDDB34D0>, 'pva_kolbasa_3'), kwargs={}\n",
      "2025-09-15 19:55:33,480 - ERROR - Операционная ошибка (попытка 1): SSL SYSCALL error: EOF detected\n",
      "\n",
      "2025-09-15 19:55:33,482 - INFO - Повторная попытка через 30 секунд...\n",
      "2025-09-15 19:56:03,900 - INFO - Успешно подключились к GreenPlum.\n",
      "2025-09-15 19:56:19,735 - INFO - Функция process_clear_and_aggregate завершена успешно.\n",
      "2025-09-15 19:56:19,738 - INFO - Шаг 10 (process_clear_and_aggregate) выполнен успешно.\n",
      "2025-09-15 19:56:19,740 - INFO - Начало выполнения функции reg_new_returned с args=(<Connector_package.db_connector.GreenPlumConnector object at 0x00000230FDDB34D0>, 'pva_kolbasa_3', '2025-07-01'), kwargs={}\n",
      "2025-09-15 19:56:25,868 - INFO - Функция reg_new_returned завершена успешно.\n",
      "2025-09-15 19:56:25,871 - INFO - Шаг 11 (reg_new_returned) выполнен успешно.\n",
      "2025-09-15 19:56:25,873 - INFO - Начало выполнения функции clear_reg с args=(<Connector_package.db_connector.GreenPlumConnector object at 0x00000230FDDB34D0>, 'pva_kolbasa_3', 2834, 'ЛК_Колбасы3_июль25_тест', 56, 31), kwargs={}\n",
      "2025-09-15 19:56:33,245 - INFO - Функция clear_reg завершена успешно.\n",
      "2025-09-15 19:56:33,247 - INFO - Шаг 12 (clear_reg) выполнен успешно.\n",
      "2025-09-15 19:56:33,248 - INFO - Начало выполнения функции dna с args=(<Connector_package.db_connector.GreenPlumConnector object at 0x00000230FDDB34D0>, 'pva_kolbasa_3', 31), kwargs={}\n",
      "2025-09-15 19:56:35,352 - INFO - Функция dna завершена успешно.\n",
      "2025-09-15 19:56:35,355 - INFO - Шаг 13 (dna) выполнен успешно.\n",
      "2025-09-15 19:56:35,357 - INFO - Начало выполнения функции kg_for_ca с args=(<Connector_package.db_connector.GreenPlumConnector object at 0x00000230FDDB34D0>, 'pva_kolbasa_3', 5), kwargs={}\n",
      "2025-09-15 19:56:55,664 - INFO - Функция kg_for_ca завершена успешно.\n",
      "2025-09-15 19:56:55,665 - INFO - Шаг 14 (kg_for_ca) выполнен успешно.\n",
      "2025-09-15 19:56:55,665 - INFO - Начало выполнения функции cnt_actn с args=(<Connector_package.db_connector.GreenPlumConnector object at 0x00000230FDDB34D0>, 'pva_kolbasa_3', '2025-05-06', '2025-07-01', '2025-07-31', 2834), kwargs={}\n",
      "2025-09-15 19:57:00,332 - INFO - Функция cnt_actn завершена успешно.\n",
      "2025-09-15 19:57:00,334 - INFO - Шаг 14 (cnt_actn) выполнен успешно.\n",
      "2025-09-15 19:57:00,336 - INFO - Начало выполнения функции dynamic_gr20 с args=(<Connector_package.db_connector.GreenPlumConnector object at 0x00000230FDDB34D0>, 'pva_kolbasa_3', 2834), kwargs={}\n",
      "2025-09-15 19:57:00,338 - ERROR - Операционная ошибка SELECT (попытка 1): (psycopg2.OperationalError) SSL SYSCALL error: EOF detected\n",
      "\n",
      "[SQL: \n",
      "           select\n",
      "                month_id\n",
      "                ,min(day_id) as min_dt\n",
      "                ,max(day_id) as max_dt\n",
      "           from\n",
      "                ba.vt_pva_kolbasa_3_days\n",
      "            where\n",
      "                actn_id = 2834 \n",
      "                and actn_period = 1\n",
      "            group by 1 \n",
      "            order by 1\n",
      "        ;]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "2025-09-15 19:57:00,340 - INFO - Повторная попытка через 30 секунд...\n",
      "2025-09-15 19:57:31,652 - ERROR - Операционная ошибка (попытка 1): SSL SYSCALL error: EOF detected\n",
      "\n",
      "2025-09-15 19:57:31,655 - INFO - Повторная попытка через 30 секунд...\n",
      "2025-09-15 19:58:02,074 - INFO - Успешно подключились к GreenPlum.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "000789555d4f40a3887d08fc59b21903",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-15 19:59:47,845 - INFO - Функция dynamic_gr20 завершена успешно.\n",
      "2025-09-15 19:59:47,846 - INFO - Шаг 16 (dynamic_gr20) выполнен успешно.\n",
      "2025-09-15 19:59:47,847 - INFO - Начало выполнения функции gr20_transp с args=(<Connector_package.db_connector.GreenPlumConnector object at 0x00000230FDDB34D0>, 'pva_kolbasa_3'), kwargs={}\n",
      "2025-09-15 19:59:53,756 - INFO - Функция gr20_transp завершена успешно.\n",
      "2025-09-15 19:59:53,757 - INFO - Шаг 17 (gr20_transp) выполнен успешно.\n",
      "2025-09-15 19:59:53,758 - INFO - Начало выполнения функции age_and_active_virt с args=(<Connector_package.db_connector.GreenPlumConnector object at 0x00000230FDDB34D0>, 'pva_kolbasa_3'), kwargs={}\n",
      "2025-09-15 20:00:00,678 - INFO - Функция age_and_active_virt завершена успешно.\n",
      "2025-09-15 20:00:00,681 - INFO - Шаг 18 (age_and_active_virt) выполнен успешно.\n",
      "2025-09-15 20:00:00,683 - INFO - Начало выполнения функции itog с args=(<Connector_package.db_connector.GreenPlumConnector object at 0x00000230FDDB34D0>, 'pva_kolbasa_3', 31), kwargs={}\n",
      "2025-09-15 20:00:05,171 - INFO - Функция itog завершена успешно.\n",
      "2025-09-15 20:00:05,172 - INFO - Шаг 19 (itog) выполнен успешно.\n",
      "2025-09-15 20:00:05,173 - INFO - Начало выполнения функции psm с args=(<Connector_package.db_connector.GreenPlumConnector object at 0x00000230FDDB34D0>, 'pva_kolbasa_3', 'ЛК_Колбасы3_июль25_тест', 2834), kwargs={}\n",
      "2025-09-15 20:00:05,175 - ERROR - Операционная ошибка SELECT (попытка 1): (psycopg2.OperationalError) SSL SYSCALL error: EOF detected\n",
      "\n",
      "[SQL: select distinct FRMT_ID, REGION_ID from ba.vt_pva_kolbasa_3_cus_profile order by FRMT_ID desc;]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "2025-09-15 20:00:05,176 - INFO - Повторная попытка через 30 секунд...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Доля мэтчинга ЛФЛ ЦА/КГ:\n",
      "\n",
      "Загрузка данных frmt_id=104, region_id=180 батчами...\n",
      "Загружено всего строк: 100000, в текущем батче: 15698\n",
      "104 180 [99.53198128]\n",
      "\n",
      "Загрузка данных frmt_id=104, region_id=247 батчами...\n",
      "Загружено всего строк: 100000, в текущем батче: 12223\n",
      "104 247 [98.69281046]\n",
      "\n",
      "Загрузка данных frmt_id=104, region_id=275 батчами...\n",
      "Загружено всего строк: 100000, в текущем батче: 13341\n",
      "104 275 [99.12434326]\n",
      "\n",
      "Загрузка данных frmt_id=104, region_id=227 батчами...\n",
      "Загружено всего строк: 100000, в текущем батче: 17160\n",
      "104 227 [99.2920354]\n",
      "\n",
      "Загрузка данных frmt_id=104, region_id=197 батчами...\n",
      "Загружено всего строк: 100000, в текущем батче: 8476\n",
      "104 197 [98.4496124]\n",
      "\n",
      "Загрузка данных frmt_id=104, region_id=280 батчами...\n",
      "Загружено всего строк: 100000, в текущем батче: 24601\n",
      "104 280 [99.34036939]\n",
      "\n",
      "Загрузка данных frmt_id=104, region_id=284 батчами...\n",
      "Загружено всего строк: 100000, в текущем батче: 17393\n",
      "104 284 [99.14236707]\n",
      "\n",
      "Загрузка данных frmt_id=104, region_id=173 батчами...\n",
      "Загружено всего строк: 100000, в текущем батче: 14312\n",
      "104 173 [99.28443649]\n",
      "\n",
      "Загрузка данных frmt_id=3, region_id=180 батчами...\n",
      "Загружено всего строк: 100000, в текущем батче: 100000\n",
      "Загружено всего строк: 200000, в текущем батче: 100000\n",
      "Загружено всего строк: 300000, в текущем батче: 100000\n",
      "Загружено всего строк: 400000, в текущем батче: 100000\n",
      "Загружено всего строк: 500000, в текущем батче: 100000\n",
      "Загружено всего строк: 600000, в текущем батче: 100000\n",
      "Загружено всего строк: 700000, в текущем батче: 7255\n",
      "3 180 [96.35295557]\n",
      "\n",
      "Загрузка данных frmt_id=3, region_id=247 батчами...\n",
      "Загружено всего строк: 100000, в текущем батче: 100000\n",
      "Загружено всего строк: 200000, в текущем батче: 100000\n",
      "Загружено всего строк: 300000, в текущем батче: 6129\n",
      "3 247 [99.0572506]\n",
      "\n",
      "Загрузка данных frmt_id=3, region_id=275 батчами...\n",
      "Загружено всего строк: 100000, в текущем батче: 100000\n",
      "Загружено всего строк: 200000, в текущем батче: 100000\n",
      "Загружено всего строк: 300000, в текущем батче: 100000\n",
      "Загружено всего строк: 400000, в текущем батче: 100000\n",
      "Загружено всего строк: 500000, в текущем батче: 100000\n",
      "Загружено всего строк: 600000, в текущем батче: 100000\n",
      "Загружено всего строк: 700000, в текущем батче: 70858\n",
      "3 275 [96.42892374]\n",
      "\n",
      "Загрузка данных frmt_id=3, region_id=227 батчами...\n",
      "Загружено всего строк: 100000, в текущем батче: 100000\n",
      "Загружено всего строк: 200000, в текущем батче: 100000\n",
      "Загружено всего строк: 300000, в текущем батче: 100000\n",
      "Загружено всего строк: 400000, в текущем батче: 100000\n",
      "Загружено всего строк: 500000, в текущем батче: 100000\n",
      "Загружено всего строк: 600000, в текущем батче: 33610\n",
      "3 227 [98.11989521]\n",
      "\n",
      "Загрузка данных frmt_id=3, region_id=197 батчами...\n",
      "Загружено всего строк: 100000, в текущем батче: 100000\n",
      "Загружено всего строк: 200000, в текущем батче: 100000\n",
      "Загружено всего строк: 300000, в текущем батче: 41884\n",
      "3 197 [98.18540434]\n",
      "\n",
      "Загрузка данных frmt_id=3, region_id=280 батчами...\n",
      "Загружено всего строк: 100000, в текущем батче: 100000\n",
      "Загружено всего строк: 200000, в текущем батче: 100000\n",
      "Загружено всего строк: 300000, в текущем батче: 100000\n",
      "Загружено всего строк: 400000, в текущем батче: 100000\n",
      "Загружено всего строк: 500000, в текущем батче: 100000\n",
      "Загружено всего строк: 600000, в текущем батче: 99576\n",
      "3 280 [98.44047166]\n",
      "\n",
      "Загрузка данных frmt_id=3, region_id=284 батчами...\n",
      "Загружено всего строк: 100000, в текущем батче: 100000\n",
      "Загружено всего строк: 200000, в текущем батче: 100000\n",
      "Загружено всего строк: 300000, в текущем батче: 100000\n",
      "Загружено всего строк: 400000, в текущем батче: 100000\n",
      "Загружено всего строк: 500000, в текущем батче: 100000\n",
      "Загружено всего строк: 600000, в текущем батче: 100000\n",
      "Загружено всего строк: 700000, в текущем батче: 87455\n",
      "3 284 [96.43230801]\n",
      "\n",
      "Загрузка данных frmt_id=3, region_id=173 батчами...\n",
      "Загружено всего строк: 100000, в текущем батче: 100000\n",
      "Загружено всего строк: 200000, в текущем батче: 100000\n",
      "Загружено всего строк: 300000, в текущем батче: 35452\n",
      "3 173 [98.27637006]\n",
      "\n",
      "Загрузка данных frmt_id=2, region_id=180 батчами...\n",
      "Загружено всего строк: 100000, в текущем батче: 100000\n",
      "Загружено всего строк: 200000, в текущем батче: 100000\n",
      "Загружено всего строк: 300000, в текущем батче: 100000\n",
      "Загружено всего строк: 400000, в текущем батче: 100000\n",
      "Загружено всего строк: 500000, в текущем батче: 82579\n",
      "2 180 [98.29397122]\n",
      "\n",
      "Загрузка данных frmt_id=2, region_id=247 батчами...\n",
      "Загружено всего строк: 100000, в текущем батче: 100000\n",
      "Загружено всего строк: 200000, в текущем батче: 4264\n",
      "2 247 [98.14615798]\n",
      "\n",
      "Загрузка данных frmt_id=2, region_id=275 батчами...\n",
      "Загружено всего строк: 100000, в текущем батче: 100000\n",
      "Загружено всего строк: 200000, в текущем батче: 100000\n",
      "Загружено всего строк: 300000, в текущем батче: 100000\n",
      "Загружено всего строк: 400000, в текущем батче: 100000\n",
      "Загружено всего строк: 500000, в текущем батче: 81852\n",
      "2 275 [97.56638494]\n",
      "\n",
      "Загрузка данных frmt_id=2, region_id=227 батчами...\n",
      "Загружено всего строк: 100000, в текущем батче: 100000\n",
      "Загружено всего строк: 200000, в текущем батче: 74325\n",
      "2 227 [98.42490842]\n",
      "\n",
      "Загрузка данных frmt_id=2, region_id=197 батчами...\n",
      "Загружено всего строк: 100000, в текущем батче: 100000\n",
      "Загружено всего строк: 200000, в текущем батче: 89700\n",
      "2 197 [98.38417607]\n",
      "\n",
      "Загрузка данных frmt_id=2, region_id=280 батчами...\n",
      "Загружено всего строк: 100000, в текущем батче: 100000\n",
      "Загружено всего строк: 200000, в текущем батче: 47763\n",
      "2 280 [98.33772552]\n",
      "\n",
      "Загрузка данных frmt_id=2, region_id=284 батчами...\n",
      "Загружено всего строк: 100000, в текущем батче: 100000\n",
      "Загружено всего строк: 200000, в текущем батче: 100000\n",
      "Загружено всего строк: 300000, в текущем батче: 60026\n",
      "2 284 [98.26677597]\n",
      "\n",
      "Загрузка данных frmt_id=2, region_id=173 батчами...\n",
      "Загружено всего строк: 100000, в текущем батче: 72734\n",
      "2 173 [98.45792826]\n",
      "\n",
      "Загрузка данных frmt_id=1, region_id=180 батчами...\n",
      "Загружено всего строк: 100000, в текущем батче: 100000\n",
      "Загружено всего строк: 200000, в текущем батче: 100000\n",
      "Загружено всего строк: 300000, в текущем батче: 100000\n",
      "Загружено всего строк: 400000, в текущем батче: 37129\n",
      "1 180 [80.67314858]\n",
      "\n",
      "Загрузка данных frmt_id=1, region_id=247 батчами...\n",
      "Загружено всего строк: 100000, в текущем батче: 100000\n",
      "Загружено всего строк: 200000, в текущем батче: 100000\n",
      "Загружено всего строк: 300000, в текущем батче: 58502\n",
      "1 247 [81.59202824]\n",
      "\n",
      "Загрузка данных frmt_id=1, region_id=275 батчами...\n",
      "Загружено всего строк: 100000, в текущем батче: 100000\n",
      "Загружено всего строк: 200000, в текущем батче: 100000\n",
      "Загружено всего строк: 300000, в текущем батче: 100000\n",
      "Загружено всего строк: 400000, в текущем батче: 100000\n",
      "Загружено всего строк: 500000, в текущем батче: 100000\n",
      "Загружено всего строк: 600000, в текущем батче: 72724\n",
      "1 275 [78.43545167]\n",
      "\n",
      "Загрузка данных frmt_id=1, region_id=227 батчами...\n",
      "Загружено всего строк: 100000, в текущем батче: 100000\n",
      "Загружено всего строк: 200000, в текущем батче: 100000\n",
      "Загружено всего строк: 300000, в текущем батче: 100000\n",
      "Загружено всего строк: 400000, в текущем батче: 15373\n",
      "1 227 [77.23057122]\n",
      "\n",
      "Загрузка данных frmt_id=1, region_id=197 батчами...\n",
      "Загружено всего строк: 100000, в текущем батче: 100000\n",
      "Загружено всего строк: 200000, в текущем батче: 91049\n",
      "1 197 [83.21428571]\n",
      "\n",
      "Загрузка данных frmt_id=1, region_id=280 батчами...\n",
      "Загружено всего строк: 100000, в текущем батче: 100000\n",
      "Загружено всего строк: 200000, в текущем батче: 100000\n",
      "Загружено всего строк: 300000, в текущем батче: 100000\n",
      "Загружено всего строк: 400000, в текущем батче: 100000\n",
      "Загружено всего строк: 500000, в текущем батче: 59683\n",
      "1 280 [78.47301276]\n",
      "\n",
      "Загрузка данных frmt_id=1, region_id=284 батчами...\n",
      "Загружено всего строк: 100000, в текущем батче: 100000\n",
      "Загружено всего строк: 200000, в текущем батче: 100000\n",
      "Загружено всего строк: 300000, в текущем батче: 100000\n",
      "Загружено всего строк: 400000, в текущем батче: 100000\n",
      "Загружено всего строк: 500000, в текущем батче: 77370\n",
      "1 284 [77.66237676]\n",
      "\n",
      "Загрузка данных frmt_id=1, region_id=173 батчами...\n",
      "Загружено всего строк: 100000, в текущем батче: 100000\n",
      "Загружено всего строк: 200000, в текущем батче: 100000\n",
      "Загружено всего строк: 300000, в текущем батче: 73414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-15 20:38:00,694 - ERROR - Операционная ошибка (попытка 1): SSL SYSCALL error: EOF detected\n",
      "\n",
      "2025-09-15 20:38:00,694 - INFO - Повторная попытка через 30 секунд...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 173 [80.11663853]\n",
      "Процесс завершен.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-15 20:38:31,135 - INFO - Успешно подключились к GreenPlum.\n",
      "2025-09-15 20:38:31,638 - INFO - Успешно вставлено 32 строк в таблицу ba.vt_pva_kolbasa_3_stat_temp за 0.242 сек.\n",
      "2025-09-15 20:38:32,009 - ERROR - Операционная ошибка SELECT (попытка 1): (psycopg2.OperationalError) SSL SYSCALL error: EOF detected\n",
      "\n",
      "[SQL: SELECT count(1) FROM BA.T_ZIG_STAT_TEST_PSM where ACTN_NAME = 'ЛК_Колбасы3_июль25_тест';]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "2025-09-15 20:38:32,010 - INFO - Повторная попытка через 30 секунд...\n",
      "2025-09-15 20:39:02,725 - ERROR - Операционная ошибка (попытка 1): SSL SYSCALL error: EOF detected\n",
      "\n",
      "2025-09-15 20:39:02,726 - INFO - Повторная попытка через 30 секунд...\n",
      "2025-09-15 20:39:33,380 - INFO - Успешно подключились к GreenPlum.\n",
      "2025-09-15 20:39:40,561 - INFO - Успешно вставлено 1099924 строк в таблицу ba.vt_pva_kolbasa_3_cus_temp за 5.266 сек.\n",
      "2025-09-15 20:39:47,394 - INFO - Функция psm завершена успешно.\n",
      "2025-09-15 20:39:47,398 - INFO - Шаг 20 (psm) выполнен успешно.\n",
      "2025-09-15 20:39:47,399 - INFO - Начало выполнения функции metrics_act с args=(<Connector_package.db_connector.GreenPlumConnector object at 0x00000230FDDB34D0>, 'pva_kolbasa_3', 'kolbasa', 2834, '2025-07-01', '2025-07-31', 3), kwargs={}\n",
      "2025-09-15 20:48:19,102 - INFO - Функция metrics_act завершена успешно.\n",
      "2025-09-15 20:48:19,104 - INFO - Начало выполнения функции metrics_prev с args=(<Connector_package.db_connector.GreenPlumConnector object at 0x00000230FDDB34D0>, 'pva_kolbasa_3', 'kolbasa', 2834, '2025-06-01', '2025-06-30', 3), kwargs={}\n",
      "2025-09-15 20:57:05,739 - INFO - Функция metrics_prev завершена успешно.\n",
      "2025-09-15 20:57:05,743 - INFO - Начало выполнения функции ca_metrics с args=(<Connector_package.db_connector.GreenPlumConnector object at 0x00000230FDDB34D0>, 'pva_kolbasa_3', 'kolbasa', 3), kwargs={}\n",
      "2025-09-15 20:57:05,746 - ERROR - Операционная ошибка SELECT (попытка 1): (psycopg2.OperationalError) SSL SYSCALL error: EOF detected\n",
      "\n",
      "[SQL: \n",
      "        select * from ba.vt_pva_kolbasa_3_kolbasa_3_total_metrics_prev\n",
      "        where is_ca = 1;\n",
      "    ]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "2025-09-15 20:57:05,748 - INFO - Повторная попытка через 30 секунд...\n",
      "2025-09-15 20:57:36,688 - INFO - Функция ca_metrics завершена успешно.\n",
      "2025-09-15 20:57:36,689 - INFO - Начало выполнения функции kg_metrics с args=(<Connector_package.db_connector.GreenPlumConnector object at 0x00000230FDDB34D0>, 'pva_kolbasa_3', 'kolbasa', 3), kwargs={}\n",
      "2025-09-15 20:57:37,175 - INFO - Функция kg_metrics завершена успешно.\n",
      "2025-09-15 20:57:41,186 - INFO - Начало выполнения функции unique_clients_ca с args=(<Connector_package.db_connector.GreenPlumConnector object at 0x00000230FDDB34D0>, 'pva_kolbasa_3', 2834), kwargs={}\n",
      "2025-09-15 20:57:44,584 - INFO - Функция unique_clients_ca завершена успешно.\n",
      "2025-09-15 20:57:44,588 - INFO - Начало выполнения функции unique_clients_kg с args=(<Connector_package.db_connector.GreenPlumConnector object at 0x00000230FDDB34D0>, 'pva_kolbasa_3', 2834), kwargs={}\n",
      "2025-09-15 20:57:48,055 - INFO - Функция unique_clients_kg завершена успешно.\n",
      "2025-09-15 20:57:49,589 - INFO - Начало выполнения функции delete_tables с args=(<Connector_package.db_connector.GreenPlumConnector object at 0x00000230FDDB34D0>, 'pva_kolbasa_3'), kwargs={}\n",
      "2025-09-15 20:57:51,986 - ERROR - Операционная ошибка (попытка 1): SSL SYSCALL error: EOF detected\n",
      "\n",
      "2025-09-15 20:57:51,987 - INFO - Повторная попытка через 30 секунд...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Кол-во таблиц до фильтрации: 45\n",
      "Кол-во таблиц после фильтрации: 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-15 20:58:22,405 - INFO - Успешно подключились к GreenPlum.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Таблица ba.tmp_pva_kolbasa_3_kolbasa_articles удалена\n",
      "Таблица ba.vt_pva_kolbasa_3_cus_ruls удалена\n",
      "Таблица ba.tmp_pva_kolbasa_3_kolbasa_buyers_act удалена\n",
      "Таблица ba.tmp_pva_kolbasa_3_kolbasa_offer_accept_act удалена\n",
      "Таблица ba.tmp_pva_kolbasa_3_kolbasa_offer_accept_prev удалена\n",
      "Таблица ba.vt_pva_kolbasa_3_cus_ctrl удалена\n",
      "Таблица ba.pva_kolbasa_3_ca_and_kg удалена\n",
      "Таблица ba.vt_pva_kolbasa_3_promo_week удалена\n",
      "Таблица ba.vt_pva_kolbasa_3_actn_duble удалена\n",
      "Таблица ba.vt_pva_kolbasa_3_frod удалена\n",
      "Таблица ba.vt_pva_kolbasa_3_trn_0 удалена\n",
      "Таблица ba.vt_pva_kolbasa_3_trn_1 удалена\n",
      "Таблица ba.vt_pva_kolbasa_3_ca_clear удалена\n",
      "Таблица ba.vt_pva_kolbasa_3_cus_clear удалена\n",
      "Таблица ba.vt_pva_kolbasa_3_trn удалена\n",
      "Таблица ba.vt_pva_kolbasa_3_cus_type удалена\n",
      "Таблица ba.vt_pva_kolbasa_3_cus_reg удалена\n",
      "Таблица ba.vt_pva_kolbasa_3_ca_frmt удалена\n",
      "Таблица ba.vt_pva_kolbasa_3_kg_frmt удалена\n",
      "Таблица ba.vt_pva_kolbasa_3_ca_frmt_grp удалена\n",
      "Таблица ba.vt_pva_kolbasa_3_kg_lfl_frmt удалена\n",
      "Таблица ba.vt_pva_kolbasa_3_ca_lfl_frmt удалена\n",
      "Таблица ba.vt_pva_kolbasa_3_ca_cg удалена\n",
      "Таблица ba.vt_pva_kolbasa_3_cnt_actn удалена\n",
      "Таблица ba.vt_pva_kolbasa_3_cus_gr_0 удалена\n",
      "Таблица ba.vt_pva_kolbasa_3_trn_temp удалена\n",
      "Таблица ba.vt_pva_kolbasa_3_cus_gr удалена\n",
      "Таблица ba.vt_pva_kolbasa_3_cus_gr_transp удалена\n",
      "Таблица ba.vt_pva_kolbasa_3_cus_gender удалена\n",
      "Таблица ba.vt_pva_kolbasa_3_cus_virt удалена\n",
      "Таблица ba.vt_pva_kolbasa_3_cus_profile удалена\n",
      "Таблица ba.vt_pva_kolbasa_3_stat_temp удалена\n",
      "Таблица ba.vt_pva_kolbasa_3_cus_temp удалена\n",
      "Таблица ba.vt_pva_kolbasa_3_cus удалена\n",
      "Таблица ba.tmp_pva_kolbasa_3_kolbasa_3_cheques_act удалена\n",
      "Таблица ba.tmp_pva_kolbasa_3_kolbasa_3_cheques_act_contacts удалена\n",
      "Таблица ba.vt_pva_kolbasa_3_kolbasa_3_total_metrics_act удалена\n",
      "Таблица ba.tmp_pva_kolbasa_3_kolbasa_3_2834_contact удалена\n",
      "Таблица ba.tmp_pva_kolbasa_3_kolbasa_3_cheques_prev удалена\n",
      "Таблица ba.tmp_pva_kolbasa_3_kolbasa_3_cheques_prev_contacts удалена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-15 20:58:28,900 - INFO - Функция delete_tables завершена успешно.\n",
      "2025-09-15 20:58:28,901 - INFO - Шаг 21 (delete_tables) выполнен успешно.\n",
      "2025-09-15 20:58:28,902 - INFO - [process_action][mask = pva_kolbasa_3] Обработка акции 'ЛК_Колбасы3_июль25_тест' завершена успешно.\n",
      "2025-09-15 20:58:29,064 - INFO - [run_all_actions][type=kolbasa, version=3] Отмечена как обработанная.\n",
      "2025-09-15 20:58:29,066 - INFO - [run_all_actions] Обработка всех акций завершена.\n",
      "2025-09-15 20:58:29,070 - INFO - Закрываем соединения/ресурсы.\n",
      "2025-09-15 20:58:29,073 - INFO - Соединение с базой данных закрыто.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Таблица ba.vt_pva_kolbasa_3_kolbasa_3_total_metrics_prev удалена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-15 20:58:29,981 - INFO - === Автоматическая обработка акций завершена ===\n"
     ]
    }
   ],
   "source": [
    "# Запуск основного процесса\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184a6bd8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}